{
  "Review1": {
    "AdapterBasedFineTuning": "Adapter-Based Fine-Tuning involves inserting trainable adapter modules into the transformer architecture to adapt pre-trained language models (PLMs) to downstream tasks without modifying pre-trained parameters. Adapters are low-rank modules typically consisting of down-projection, non-linear activation, and up-projection layers with residual connections. Examples include Sequential Adapter, Parallel Adapter, AdapterDrop, and CoDA (Condition Adapter), which optimize task-specific parameters while keeping most of the PLM frozen.\n",
    "BiasUpdate": "Bias Update methods fine-tune only the bias terms in the transformer’s attention, feed-forward, and layer normalization layers, along with task-specific classifiers, while freezing other parameters. This approach, exemplified by BitFit and U/S-BitFit, reduces trainable parameters significantly. U/S-BitFit further uses neural architecture search (NAS) and pruning to automatically select parameters for fine-tuning.\n",
    "DeltaWeightMasking": "Delta Weight Masking aims to reduce trainable parameters by masking delta weights (parameter updates) using pruning techniques or optimization approximations. Methods like LT-SFT (Lottery Ticket Sparse Fine-Tuning) and Child-Tuning identify important parameters via criteria such as absolute differences or Fisher information, then use binary masks to update only selected parameters iteratively.\n",
    "HybridFT_AutomaticCombination": "Automatic Combination in Hybrid Fine-Tuning uses structure search or optimization (e.g., Bayesian optimization) to automatically configure combinations of PEFT methods (e.g., adapters, LoRA, BitFit) across transformer layers. Examples include AutoPEFT, which searches for optimal architectures via Bayesian optimization, and S3Delta-M, which performs differentiable delta tuning structure search to find sparse combinations of PEFT techniques.\n",
    "HybridFT_ManualCombination": "Manual Combination in Hybrid Fine-Tuning combines multiple PEFT methods through explicit design. For instance, MAM Adapter merges parallel adapters with prefix-tuning, while Compacter integrates adapters with low-rank hypercomplex multiplication (LPHM) layers. These methods leverage the strengths of different PEFT approaches to enhance performance.\n",
    "LoRA Derivatives": "LoRA Derivatives are improvements based on LoRA (Low-Rank Adaptation), including:\nDynamic Rank Adjustment (e.g., DyLoRA, AdaLoRA), which adapts LoRA’s rank during training.\nQuantization Adaption (e.g., QLoRA, QA-LoRA), which integrates quantization for efficient fine-tuning of large language models (LLMs).\nMulti-Task Fine-Tuning (e.g., LoRAHub, MoELoRA), which combines multiple LoRA modules for cross-task transfer.",
    "LowRankDecomposition": "Low-Rank Decomposition reparameterizes delta weights using low-rank matrices to reduce trainable parameters. Methods like LoRA and KronA (Kronecker Adapter) decompose weight updates into products of smaller matrices (e.g., \\(\\Delta W = W_{down}W_{up}\\) for LoRA), enabling efficient adaptation while preserving model expressiveness.",
    "OtherAdditiveFT": "Other Additive Fine-Tuning methods introduce extra trainable parameters beyond adapters and soft prompts. Examples include:\nLST (Ladder Side-Tuning): Trains a side network with shortcut connections to the pretrained model.\n(IA)³ (Infused Adapter): Scales activations using learned vectors for key, value, and feed-forward layers.\nPASTA (Special Token Adaptation): Modifies special token representations (e.g., [CLS]) with trainable vectors.",
    "PretrainedWeightMasking": "Pretrained Weight Masking uses pruning criteria (e.g., threshold, Fisher information) to create binary masks for pre-trained weights, updating only important parameters. Methods like Threshold-Mask and FISH Mask select weights via metrics (e.g., top-k Fisher information) to reduce fine-tuning parameters.\n",
    "SoftPromptBasedFT": "Soft Prompt-Based Fine-Tuning inserts trainable continuous vectors (soft prompts) into the model’s input or hidden states. Unlike hard prompts, soft prompts are optimized during training. Examples include Prompt-tuning (adding prompt tokens to input), Prefix-tuning (prepending prompts to attention hidden states), and SPOT (transferring soft prompts across tasks).\n",
    "UnifiedFineTuning": "Unified Fine-Tuning provides a cohesive framework to integrate diverse fine-tuning methods into a single architecture. For example:\nAdaMix: Uses a mixture of adaptation modules (e.g., adapters, LoRA) with stochastic routing.\nSparseAdapter: Prunes adapters or LoRA parameters to enhance efficiency.\nProPETL: Shares a prototype network across layers with binary masks for task-specific sub-networks."
  },
  "Review10": {
    "On-device applications": "On-device applications refer to practical implementations of Large Language Models (LLMs) executed directly on edge devices (e.g., smartphones, IoT devices, robots). These applications leverage optimized LLMs to enable low-latency, privacy-preserving, and context-aware functionalities across diverse domains:\nPersonal use: AI assistants (e.g., task automation, healthcare monitoring), companion robots.\nEnterprise: Message completion, meeting summarization, computer operation automation.\nIndustrial: Autonomous driving, fault localization, anomaly detection in real-time systems.\nKey advantages include reduced dependency on cloud connectivity, enhanced data privacy, and adaptability to user-specific contexts.",
    "Pre-deployment techniques": "Pre-deployment techniques are offline optimizations applied to LLMs before deploying them on edge devices. These methods aim to reduce model size, computational complexity, and memory footprint while preserving performance:\nQuantization: Reducing weight and activation precision (e.g., 8-bit or lower).\nPruning: Removing redundant parameters (e.g., attention heads, layers).\nKnowledge distillation: Transferring knowledge from large \"teacher\" models to smaller \"student\" models.\nLow-rank approximation: Exploiting matrix redundancy to compress model layers.\nComplementary methods: Architectural optimizations (e.g., grouped query attention) and data curation.\nThese techniques enable LLMs to fit within the resource constraints of edge devices (e.g., limited RAM and processing power).",
    "Runtime optimization": "Runtime optimizations enhance LLM inference efficiency on edge devices during real-time execution. They focus on adapting to hardware heterogeneity and dynamic resource constraints:\nSoftware-level optimizations:\nCloud-edge collaboration (e.g., split inference, speculative decoding).\nSingle-device resource scheduling (e.g., token reduction, early exiting).\nLightweight frameworks (e.g., vLLM, llama.cpp) for memory and computation efficiency.\nHardware-software co-design:\nHardware-aware sparsity (e.g., ASIC-optimized pruning, in-memory computing).\nArithmetic format optimizations (e.g., low-bit precision, dynamic adaptive encoding).\nHardware-level optimizations:\nSpecialized accelerators (CPUs, GPUs, NPUs) tailored for LLM workloads (e.g., Apple Neural Engine, NVIDIA Jetson).\nThese optimizations ensure seamless inference despite edge devices’ limited resources, balancing speed, energy efficiency, and accuracy."
  },
  "Review11": {
    "Benchmarks and Datasets": "Benchmarks and datasets serve as standardized frameworks and data collections to evaluate large language models (LLMs). Datasets are curated data collections for specific tasks, such as GLUE and SuperGLUE for natural language understanding. Benchmarks integrate tasks, metrics, and evaluation protocols to assess LLMs holistically. For example, MMLU evaluates multi-task language understanding, HELM offers a comprehensive multi-metric assessment, and BIG-bench tests capabilities across 204 challenging tasks. These tools help quantify LLMs’ performance, robustness, and limitations in real-world scenarios.\n",
    "Evaluation of Natural Language Processing Tasks": "This evaluation focuses on LLMs’ capabilities in understanding and generating human language. It covers:\nNatural Language Understanding (NLU): Tasks like sentiment analysis (e.g., ChatGPT excels in sentiment prediction), text classification (e.g., GLM-130B achieves 85.8% accuracy), and natural language inference (NLI, where LLMs struggle to represent human disagreements).\nNatural Language Generation (NLG): Tasks such as summarization (e.g., ChatGPT shows moderate zero-shot performance), machine translation (e.g., GPT-4 outperforms commercial systems), and question answering (e.g., InstructGPT demonstrates high accuracy in QA).\nMultilingual Tasks: LLMs perform well in high-resource languages but struggle with non-Latin scripts and low-resource languages (e.g., ChatGPT has limited understanding of Arabic NLP tasks).",
    "Multimodal and Tool Application Evaluation": "Multimodal Evaluation: Assesses LLMs’ ability to process visual, audio, and textual inputs. Benchmarks like MME and MMBench evaluate multimodal perception and cognition, while SEED-Bench tests generative understanding of images and videos. For example, LVLM-eHub evaluates large vision-language models on tasks like image captioning and visual reasoning.\nTool Application Evaluation: Measures LLMs’ capacity to interact with external tools (e.g., APIs, databases). Frameworks like ToolLLM and HuggingGPT enable LLMs to execute tasks (e.g., code generation, API calls), with benchmarks like API-Bank and ToolBench assessing tool utilization efficiency and success rates.",
    "Resoning capacity evaluation": "This evaluates LLMs’ logical, mathematical, and commonsense reasoning abilities:\nMathematical Reasoning: LLMs excel in arithmetic (e.g., ChatGPT outperforms GPT-3.5 in basic math) but struggle with complex problems (e.g., GPT-4 achieves 60% accuracy on high-school competition math).\nCommonsense and Logical Reasoning: LLMs show robust temporal and causal reasoning but lack abstract and multi-hop reasoning (e.g., ChatGPT fails in counterfactual tasks).\nDomain-Specific Reasoning: Models like GPT-4 demonstrate potential in medical and legal reasoning but require improvement for expert-level performance (e.g., ChatGPT meets passing thresholds in USMLE exams with no medical training).",
    "Robustness, Ethics, and Bias Assessment": "Robustness: Evaluates LLMs’ stability under adversarial inputs or out-of-distribution (OOD) data. Benchmarks like PromptBench and GLUE-X measure adversarial robustness (e.g., LLMs are vulnerable to prompt attacks), while OOD evaluation assesses generalization to unseen contexts (e.g., visual input manipulation risks for vision-language models).\nEthics and Bias: Focuses on toxic content generation, social biases, and value alignment. Tools like TRUSTGPT and SafetyBench test toxicity and stereotype bias (e.g., ChatGPT exhibits residual toxicity and cultural value biases), while datasets like CHBias evaluate Chinese LLM biases.\nTrustworthiness: Includes hallucination detection (e.g., SelfCheckGPT identifies ungrounded claims) and consistency assessment (e.g., LLMs’ judgment vacillations under misleading cues)."
  },
  "Review12": {
    "Basic Model Architecture and Principles": "\"Basic Model Architecture and Principles\" refers to the use of Transformer-based structures (encoder-only, decoder-only, or encoder-decoder) and training methods like pre-training on medical corpora, fine-tuning, and prompting to enable language understanding and generation in medical contexts.\n",
    "Clinical application scenarios": "\"Clinical application scenarios\" are the real-world medical settings where LLMs are used, including medical decision-making, clinical coding, report generation, robotics, language translation, education, mental health support, and patient inquiry response.\n",
    "Development Methods of Medical Large Language Models": "\"Development Methods of Medical Large Language Models\" include pre-training from scratch on medical data, fine-tuning general LLMs through supervised, instruction-based, or parameter-efficient techniques, and using prompting strategies like in-context learning, chain-of-thought, or retrieval augmentation.\n",
    "Ethics, Safety and Regulations": "\"Ethics, Safety and Regulations\" involve addressing biases, privacy risks, and accountability in LLM use, mitigating hallucinations, and establishing adaptive regulatory frameworks to ensure safe and ethical medical applications.\n",
    "Evaluation Benchmarks and Metrics": "\"Evaluation Benchmarks and Metrics\" consist of task-specific measures like F1 score, ROUGE, and accuracy in medical QA, but currently lack comprehensive assessment of trustworthiness, explainability, and real-world clinical capabilities.\n"
  },
  "Review2": {
    "Chatbot": "A dialogue agent that combines information retrieval, multi-turn interaction, and text generation, often fine-tuned with human feedback for safety and factual grounding.",
    "Computational Biology": "The use of LLMs to generate protein embeddings from amino-acid or genomic sequences for structure prediction, classification, and novel sequence generation.",
    "Computer programming": "The application of LLMs to generate, complete, and debug code in various languages, addressing long-range dependencies via retrieval-augmented frameworks.",
    "Creative work": "The utilization of LLMs for generating stories, scripts, and poetry, often via modular prompting to manage long-form content coherence.",
    "Knowledge work": "The employment of LLMs in professional domains like finance, academia, and data analysis, enabling tasks such as report generation, scientific reasoning, and numerical analysis.",
    "Law": "The integration of LLMs for legal question answering, case prediction, and statutory reasoning, constrained by outdated legal knowledge and context complexity.",
    "Medicine": "The application of LLMs to medical question answering, clinical information extraction, and triage, with challenges in factual accuracy and bias mitigation.",
    "Reasoning": "Involves LLMs in mathematical and algorithmic tasks, leveraging chain-of-thought prompting to improve multi-step problem-solving.",
    "Robotics": "Uses LLMs for high-level task planning in robots, combining language with sensor data to generate actionable commands and handle embodied interactions.",
    "SocialScience": "Employs LLMs to simulate human behavior in psychological experiments, analyze model personalities, and model social relationships.",
    "Synthetic Training Data": "Refers to using LLMs to generate annotated datasets for training smaller models, though limited by potential hallucinations in data distribution."
  },
  "Review3": {
    "CS & SE": "It refers to the application of LLM-based autonomous agents in computer science and software engineering, which can automate coding, testing, debugging, and documentation generation.",
    "Documentation and data management Experiment Assistant": "It means the use of LLM agents to assist in natural scientific research, including efficiently querying and utilizing information, extracting key information from text descriptions, and using relevant tools to predict properties and structures.",
    "Industrial automation": "It involves integrating large language models with digital twin systems to adapt to flexible production needs, coordinate atomic functionalities and skills, and complete production tasks at different levels.",
    "Jurisprudence": "It refers to LLM-based agents serving as aids in legal decision-making processes, such as simulating the decision-making processes of multiple judges and supporting database or keyword search to mitigate the hallucination issue.",
    "Natural Science education": "It means leveraging LLM-based agents to develop educational tools, such as facilitating students' learning of experimental design, assisting in exploring and solving mathematical problems, and automatically assessing students' responses and providing feedback.",
    "Political Science and Economy": "It includes utilizing LLM-based agents for ideology detection, predicting voting patterns, understanding the discourse structure of political speech, and exploring human economic behaviors in simulated scenarios.",
    "Psychology": "It involves using LLM-based agents to conduct psychology experiments, generate results consistent with human participants, and analyze the effectiveness of conversation agents for mental well-being support.",
    "Research Assistant": "It refers to LLM-based agents serving as versatile assistants in social science research, such as generating article abstracts, extracting keywords, and crafting detailed scripts for studies.",
    "Robotics & embodied ai": "It focuses on developing more efficient reinforcement learning agents for robotics and embodied artificial intelligence, enhancing autonomous agents' abilities for planning, reasoning, and collaboration in embodied environments.",
    "Social Simulation": "It means building virtual environments with LLM-based agents to simulate social phenomena, such as the propagation of harmful information and human daily life in a virtual town."
  },
  "Review4": {
    "Explainability and Trustworthiness": "The ability to understand and validate how machine learning models make decisions, addressing concerns about transparency and reliability in industrial applications.",
    "Knowledge Representation": "The process of encoding data into structured formats that ML algorithms can interpret, such as feature extraction or dimensionality reduction for meaningful pattern recognition.",
    "Learning and Inference": "The core ML process where algorithms autonomously extract patterns from data (learning) and use these patterns to make predictions or decisions (inference).",
    "Logic and Reasoning": " The systematic approach to decision-making in ML, such as in reinforcement learning where agents use trial-and-error to derive optimal actions based on environmental feedback."
  },
  "Review5": {
    "Aggregations": "The process of combining or summarizing multiple elements, such as data points or symbolic representations, to form a unified whole in Neuro-Symbolic AI systems.",
    "Modifications to DL Architecture": "Alterations or adjustments made to deep learning frameworks, often involving the integration of symbolic processing components or changes to network structures, to facilitate interaction with symbolic reasoning parts.",
    "Pipelines": "Sequential workflows or processing chains in Neuro-Symbolic AI that integrate neural learning and symbolic inference stages to carry out end-to-end tasks.",
    "Rule-Constrained Model": "A model in which symbolic logic rules are incorporated to guide or limit the learning and inference processes of neural networks, ensuring that the outputs are logically consistent and in line with domain-specific knowledge."
  },
  "Review6": {
    "Explainability": "The ability of an AI system to provide clear, understandable justifications for its decisions or outputs, often through the use of knowledge bases or symbolic representations to make the reasoning process transparent to humans.",
    "KnowledgeProcessing": "The manipulation and integration of symbolic domain knowledge, such as ontologies, rules, or facts, into AI models to enhance their understanding and processing of natural language tasks.",
    "LogicalReasoning": "The use of formal logic, rules, and symbolic representations to derive conclusions or make inferences, ensuring consistency and adherence to domain-specific logic in AI systems.",
    "NeuralAutomata": "Neural network-based models that mimic the behavior of automata, combining connectionist learning with structured processing to handle sequential or rule-based natural language tasks.",
    "ProbabilisticReasoning": "The use of probabilistic models and soft logic to handle uncertainty in reasoning, allowing AI systems to make informed decisions by considering the likelihood of different outcomes or interpretations in natural language processing."
  },
  "Review7": {
    "Argumentation": "The process of using logical reasoning and evidence to form and support conclusions or claims, often involving the construction and evaluation of arguments",
    "MathematicalReasoning": "The ability to apply logical thinking and mathematical principles to solve problems, prove theorems, and draw valid conclusions",
    "ProgrammingSystems": "Systems that involve the design, development, and implementation of computer programs to perform specific tasks or solve problems",
    "Question-Answering": "The task of automatically providing relevant and accurate answers to natural language questions posed by users",
    "Robotics&Control": "The field focused on the design, development, and control of robots to perform various tasks in different environments",
    "ScientificDiscovery": "The process of uncovering new knowledge, theories, or phenomena through scientific methods and research",
    "Vision-Language Analysis&Reasoning": "The integration of visual and language understanding to analyze and reason about visual content using language-based models",
    "VisualSceneUnderstanding": "The ability to interpret and make sense of visual scenes by extracting and understanding objects, their relationships, and the overall context"
  },
  "Review8": {
    "LogicalConstraints": "Constraints derived from logical rules or reasoning that guide the learning process, ensuring predictions align with logical entailment or domain-specific knowledge.",
    "LogicallyInformedEmbedding": "Embedding approaches that integrate symbolic inference or logical knowledge as a preliminary step to augment the knowledge graph before generating numerical representations.",
    "RuleLearning": "Approaches that automatically discover or learn logical rules from data, often combining neural networks with symbolic reasoning to derive interpretable rules for knowledge graph completion."
  },
  "Review9": {
    "Constraint Solving": "A method that transforms neural networks into constraints and uses solvers like SAT solvers for verification.",
    "Over-Approximation": "A technique that calculates an upper bound of possible outputs for an input to verify neural networks.",
    "Over-Approximation & Constraint Solving": "An approach that combines calculating upper bounds of outputs and transforming networks into constraints for verification.",
    "Search-Based": "A verification method that employs exhaustive searching, such as Monte Carlo tree search, to check neural networks.",
    "Search-Based & Constraint Solving": "A combined approach that uses exhaustive searching and transforms networks into constraints for verification."
  }
}