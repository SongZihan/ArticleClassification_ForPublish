{
  "Agriculture": {
    "A review on enhancing agricultural intelligence with large language models": "This paper systematically explores the application potential of large language models (LLMs) in the field of agricultural intelligence, focusing on key technologies and practical pathways. The study focuses on the adaptation of LLMs to agricultural knowledge, starting with foundational concepts such as architecture design, pre-training strategies, and fine-tuning techniques, to build a technical framework for knowledge integration in the agricultural domain. Using tools such as vector databases and knowledge graphs, the study enables the structured development of professional agricultural knowledge bases. Additionally, by combining multimodal learning and intelligent question-answering (Q&A) system design, it validates the application value of LLMs in agricultural knowledge services. Addressing core challenges in domain adaptation, including knowledge acquisition and integration, logical reasoning, multimodal data processing, agent collaboration, and dynamic knowledge updating, the paper proposes targeted solutions. The study further explores the innovative applications of LLMs in scenarios such as precision crop management and market dynamics analysis, providing theoretical support and technical pathways for the development of agricultural intelligence. Through the technological innovation of large language models and their deep integration with the agricultural sector, the intelligence level of agricultural production, decision-making, and services can be effectively enhanced.",
    "A Study of the Application Domain of a Large Language Models in the Agricultural Sector": "Given the expanding global population and the increasing need for food, employing effective agricultural techniques to enhance productivity on finite land resources is imperative. Artificial Intelligence is increasingly widespread in agriculture, and Artificial Intelligence driven solutions enhance the existing farming system. Agricultural productivity relies on soil nutrient composition, moisture levels, crop rotation, precipitation, temperature, etc. Artificial intelligence -based products can utilize these characteristics to monitor agrarian productivity. Industries are increasingly adopting Artificial Intelligence technologies to enhance and streamline agricultural activities across the whole food supply chain. Agricultural applications and solutions utilizing artificial intelligence have been developed to support farmers in precise and controlled farming practices. These applications provide accurate guidance on water management, changing crops, timely harvesting, crop selection, optimal planting, pest control, and nutrition management. Artificial Intelligence enabled systems utilize data such as precipitation, wind speed, temperature, and sun radiation, together with images captured by sat",
    "Exploring New Frontiers in Agricultural NLP: Investigating the Potential of Large Language Models for Food Applications": "This paper explores new frontiers in agricultural natural language processing by investigating the effectiveness of using food-related text corpora for pretraining transformer-based language models. In particular, we focus on the task of semantic matching, which involves establishing mappings between food descriptions and nutrition data. To accomplish this, we fine-tune a pre-trained transformer-based language model, AgriBERT, on this task, utilizing an external source of knowledge, such as the FoodOn ontology. To advance the field of agricultural NLP , we propose two new avenues of exploration: (1) utilizing GPT -based models as a baseline and (2) leveraging ChatGPT as an external source of knowledge. ChatGPT has shown to be a strong baseline in many NLP tasks, and we believe it has the potential to improve our model in the task of semantic matching and enhance our model\u2019s understanding of food-related concepts and relationships. Additionally, we experiment with other applications, such as cuisine prediction based on food ingredients, and expand the scope of our research to include other NLP tasks beyond semantic matching. Overall, this paper provides promising avenues for future research in this field, with potential implications for improving the performance of agricultural NLP applications.",
    "Large Language Models and Foundation Models in Smart Agriculture: Basics, Opportunities, and Challenges": "The past decade has witnessed the rapid development and adoption of machine and deep learning (ML & DL) methodologies in agricultural systems, showcased by great successes in applications such as smart crop management, smart plant breeding, smart livestock farming, precision aquaculture farming, and agricultural robotics. However, these conventional ML/DL models have certain limitations: they heavily rely on large, costly - to - acquire labeled datasets for training, require specialized expertise for development and maintenance, and are mostly tailored for specific tasks, thus lacking generalizability. Recently, large pre - trained models, also known as foundation models (FMs), have demonstrated remarkable successes in language, vision, and decision - making tasks across various domains. These models are trained on a vast amount of data from multiple domains and modalities. Once trained, they can accomplish versatile tasks with just minor fine - tuning and minimal task - specific labeled data. Despite their proven effectiveness and huge potential, there has been little exploration of applying FMs to agriculture artificial intelligence (AI). Therefore, this study aims to explore the potential of FMs in the field of smart agriculture. In particular, conceptual tools and technical background are presented to facilitate the understanding of the problem space and uncover new research directions in this field. To this end, recent FMs in the general computer science (CS) domain are reviewed, and the models are",
    "Harnessing Large Vision and Language Models in Agriculture: A Review": "Large models can play important roles in many domains. Agriculture is another key factor affecting the lives of people around the world. It provides food, fabric, and coal for humanity. However, facing many challenges such as pests and diseases, soil degradation, global warming, and food security, how  to steadily increase the yield in the agricultural sector is a problem that humans still need to solve. Large models can help farmers improve production efficiency and harvest by detecting a series of agricultural production tasks such as pests and diseas es, soil quality, and seed quality. It can also help farmers make wise decisions through a variety of information, such as images, text, etc. Herein, we delve into the potential applications of large models in agriculture, from large language model (LLM) a nd large vision model (LVM) to large vision - language models (LVLM). After gaining a deeper understanding of multimodal large language  models (MLLM), it can be recognized that problems such as agricultural image processing, agricultural question answering systems, and agricultural machine automation can all be solved by large models. Large models have great potential in the field of agriculture. We outline the current applications of  agricultural  large models, and aims to emphasize the importance of large models in the domain of agriculture. In the end, we envisage a future in which famers use MLLM to accomplish many tasks in agriculture, which can greatly improve agricultural production efficiency and yield",
    "A COMPREHENSIVE SURVEY OF RETRIEVAL-AUGMENTED LARGE LANGUAGE MODELS FOR DECISION MAKING IN AGRICULTURE: UNSOLVED PROBLEMS AND RESEARCH OPPORTUNITIES": "The breakthrough in developing large language models (LLMs) over the past few years has led to their widespread implementation in various areas of industry, business, and agriculture. The aim of this article is to critically analyse and generalise the known results and research directions on approaches to the development and utilisation of LLMs, with a particular focus on their functional characteristics when integrated into decision support systems (DSSs) for agricultural monitoring. The subject of the research is approaches to the development and integration of LLMs into DSSs for agrotechnical monitoring. The main scientific and applied results of the article are as follows: the world experience of using LLMs to improve agricultural processes has been analysed; a critical analysis of the functional characteristics of LLMs has been carried out, and the areas of application of their architectures have been identified; the necessity of focusing on retrieval-augmented generation (RAG) as an approach to solving one of the main limitations of LLMs, which is the limited knowledge base of training data, has been established; the characteristics and prospects of using LLMs for DSSs in agriculture have been analysed to highlight trustworthiness, explainability and bias reduction as priority areas of research; the potential socio-economic effect from the implementation of LLMs and RAG in the agricultural sector is substantiated.",
    "IPM\u2011AgriGPT: A Large Language Model for Pest and Disease Management with a G\u2011EA Framework and Agricultural Contextual Reasoning": "Traditional pest and disease management methods are inefficient, relying on agricultural experts or static resources, making it difficult to respond quickly to large\u2011scale outbreaks and meet local needs. Although deep learning technologies have been applied in pest and disease management, challenges remain, such as the dependence on large amounts of manually labeled data and the limitations of dynamic reasoning. To ad\u2011dress these challenges, this study proposes IPM\u2011AgriGPT (Integrated Pest Management\u2014Agricultural Generative Pre\u2011Trained Transformer), a Chinese large language model specif\u2011ically designed for pest and disease knowledge. The proposed Generation\u2011Evaluation Ad\u2011versarial (G\u2011EA) framework is used to generate high\u2011quality question\u2013answer corpora and combined with Agricultural Contextual Reasoning Chain\u2011of\u2011Thought Distillation (ACR\u2011CoTD) and low\u2011rank adaptation (LoRA) techniques further optimizes the base model to build IPM\u2011AgriGPT. During the evaluation phase, this study designed a specialized bench\u2011mark for the agricultural pest and disease domain, comprehensively assessing the perfor",
    "Large language models and agricultural extension services": "Several factors have traditionally hampered the effectiveness of agricultural extension services, including limited institutional capacity and reach. Here we assess the potential of large language models (LLMs), specifically Generative Pre-trained Transformer (GPT), to transform agricultural extension. We focus on the ability of LLMs to simplify scientific knowledge and provide personalized, location-specific and data-driven agricultural recommendations. We emphasize shortcomings of this technology, informed by real-life testing of GPT to generate technical advice for Nigerian cassava farmers. To ensure a safe and responsible dissemination of LLM functionality across farming worldwide, we propose an idealized LLM design process with human experts in the loop."
  },
  "Art": {
    "Exploring the impact of ChatGPT on art creation and collaboration: Benefits, challenges and ethical implications": "This paper examines the chaos caused by introducing advanced language models, specifically ChatGPT, to art. Our focus is on the potential impact of ChatGPT on art creation and collaboration. We explore how it has been utilized to generate art and assist in creative writing and how it facilitates collaboration between artists. This exploration includes an investigation into the use of AI in creating art, music, and literature, emphasizing ChatGPT\u2019s role in generating poetry and prose and its ability to provide valuable suggestions for sentence structure and word choice in creative writing. We conduct case studies and interviews with diverse artists and AI experts to understand the benefits and challenges of using ChatGPT in the creative process. Our findings reveal that artists find ChatGPT helpful in generating new ideas, overcoming creative blocks, and improving the quality of their work. It enables remote collaboration between artists by providing a real - time communication and idea - sharing platform. However, ethical concerns relating to authorship ownership and authenticity have emerged. Artists fear using ChatGPT may lead to losing their artistic identity and ownership of their work. While our data suggests that ChatGPT holds the potential to transform the art world, careful consideration must be given to the ethical implications of AI in art. We recommend future research to focus on develop",
    "Large Language Models Are State-of-the-Art Evaluators of Translation Quality": "We describe GEMBA, a GPT-based metric for assessment of translation quality, which works both with a reference translation and without. In our evaluation, we focus on zero-shot prompting, comparing four prompt variants in two modes, based on the availability of the reference. We investigate nine versions of GPT models, including ChatGPT and GPT-4. We show that our method for translation quality assessment only works with GPT 3.5 and larger models. Comparing to results from WMT22\u2019s Metrics shared task, our method achieves state-of-the-art accuracy in both modes when compared to MQM-based human labels. Our results are valid on the system level for all three WMT22 Metrics shared task language pairs, namely English into German, English into Russian, and Chinese into English. This provides a first glimpse into the usefulness of pre-trained, generative large language models for quality assessment of translations. We publicly release all our code and prompt templates used for the experiments described in this work, as well as all corresponding scoring results, to allow for external validation and reproducibility.",
    "On the Creativity of Large Language Models": "Large Language Models (LLMs) are revolutionizing several areas of Artificial In- telligence. One of the most remarkable applications is creative writing, e.g., poetry or storytelling: the generated outputs are often of astonishing quality. However, a natural question arises: can LLMs be really considered creative? In this article, we first analyze the development of LLMs under the lens of creativity theories, investi- gating the key open questions and challenges. In particular, we focus our discussion on the dimensions of value, novelty, and surprise as proposed by Margaret Boden in her work. Then, we consider different classic perspectives, namely product, process, press, and person. We discuss a set of \u201ceasy\u201d and \u201chard\u201d problems in machine cre- ativity, presenting them in relation to LLMs. Finally, we examine the societal impact of these technologies with a particular focus on the creative industries, analyzing the opportunities offered, the challenges arising from them, and the potential associated risks, from both legal and ethical points of view.",
    "Art or Artifice? Large Language Models and the False Promise of Creativity": "Researchers have argued that large language models (LLMs) exhibit high-quality writing capabilities from blogs to stories. However, evaluating objectively the creativity of a piece of writing is challenging. Inspired by the Torrance Test of Creative Thinking (TTCT) [64], which measures creativity as a process , we use the Consensual Assessment Technique [ 3] and propose Torrance Test of Creative Writing (TTCW) to evaluate creativity as product . TTCW consists of 14 binary tests organized into the original dimensions of Fluency, Flexibility, Originality, and Elaboration. We recruit 10 creative writers and implement a human assessment of 48 stories written either by professional authors or LLMs using TTCW. Our analysis shows that LLM-generated stories pass 3-10X less TTCW tests than stories written by professionals. In addition, we explore the use of LLMs as assessors to automate the TTCW evaluation, revealing that none of the LLMs positively correlate with the expert assessments.",
    "LLM as an Art Director (LaDi): Using LLM\u2019s to improve Text-to-Media Generators": "Recent advancements in text-to-image generation have revo lutionized numerous \ufb01elds, including art and cinema, by automating the generati on of high-quality, context-aware images and video. However, the utility of the se technologies is of- ten limited by the inadequacy of text prompts in guiding the g enerator to produce artistically coherent and subject-relevant images. In thi s paper, We describe the techniques that can be used to make Large Language Models (LL Ms) act as Art Di- rectors that enhance image and video generation. We describ e our uni\ufb01ed system for this called \"LaDi\". We explore how LaDi integrates multi ple techniques for augmenting the capabilities of text-to-image generators ( T2Is) and text-to-video generators (T2Vs), with a focus on constrained decoding, in telligent prompting, \ufb01ne-tuning, and retrieval. LaDi and these techniques are be ing used today in apps and platforms developed by Plai Labs.",
    "EXPLORING FACTORS INFLUENCING THE INTEGRATION OF DRAWING TOOLS IN ARTS AND DESIGN EDUCATION": "The purpose of this study is to explore the factors that influence the integration of using artificial intelligence drawing tools into art and design education in colleges and universities. To integrate AI technology into art design education, it is first necessary to clarify the effect of the application of AI technology in the education process. Through the methods of literature review, case study, and practical teaching, we analyze the potential and influencing factors of the application of AI in education by integrating the theoretical foundations of art and design teaching with AI. This study summarizes the effects and possible shortcomings of the application of artificial intelligence from the case of universities in China and proposes corresponding countermeasures. The conclusions of the study can provide theoretical support and practical guidance for the application of artificial intelligence in art and design teaching.",
    "Artificial intelligence and the copyright dilemma": "Authorship of copyrightable works has been a hotly contested issue in the American legal system for over 200 years.  With the recent boom of artificial intelligence, more and more creative works have been the result of non - human authors.  Computer algorithms and learning machines have become a new source of creativity.  The U.S. Copyright Office, however, has been slow to acknowledge the significance of AI in the creative process by denying copyrights of non - human works and releasing them into the public domain.  This paper addresses the issue of IP ownership of AI generated works.  It argues that giving authorship to AI programmers and owners is essential to the future development of the AI industry.  The paper proposes that instead of redefining \u201cauthorship\u201d to include non - humans, it is simply necessary to reinterpret the terms \u201cemployee\u201d and \u201cemployer\u201d in the made for hire doctrine of the U.S. Copyright Act.  This reinterpretation would allow the current IP system to continue promoting \u201cthe progress of science and useful arts\u201d without a lengthy or controversial overhaul of the rules and guidelines currently set in place.",
    "INTEGRATING LARGE LANGUAGE MODELS IN ART AND DESIGN EDUCATION": "This paper provides a possible strategy for integrating large language artificial intelligence models (LLMs) in supporting students' education in artistic or design activities. We outline the methodological foundations concerning the integration of BLOOM LLM in the educational approach aimed at enhancing artistic conception and design ideation. We also present the knowledge and system architecture for integrating LLM in the \u00b0\u2019\u00b0Kobi system. Finally, this paper discusses some relevant aspects concerning the system's application in a real educational context and briefly reports its preliminary assessment.",
    "Large Language Model in Creative Work: The Role of Collaboration Modality and User Expertise": "Since the launch of ChatGPT in Dec 2022, Large Language Models (LLMs) are rapidly adopted by businesses to assist users in a wide range of open-ended tasks, including creative work. While the versatility of LLM has unlocked new ways of human-AI collaboration, it remains uncertain how LLMs should be used to enhance business outcomes. To examine the effects of human-LLM collaboration on business outcomes, we conducted an experiment where we tasked expert and non-expert users to write an ad copy with and without the assistance of LLMs. Here, we investigate and compare two ways of working with LLMs: (1) using LLMs as \u201cghostwriters,\u201d which assume the main role of content generation task and (2) using LLMs as \u201csounding boards,\u201d to provide feedback on human-created content. We measure the quality of the ads using the number of clicks generated by the created ads on major social media platforms. Our results show that different collaboration modalities can result in very different outcomes for different user types. Using LLMs as sounding boards enhances the quality of the resultant ad copies for non-experts. However, using LLMs as ghostwriters did not provide significant benefits and is in fact detrimental to expert users. We rely on textual analyses to understand the mechanisms and learned that using LLMs as ghostwriters produces an anchoring effect which leads to lower-quality ads. On the other hand, using LLMs as sounding boards helped non-experts achieve ad content with low semantic divergence to content produced by experts, thereby closing the gap between the two types of users."
  },
  "Business": {
    "How  well  can a large  language  model  explain  business  processes  as perceived  by users?": "Large Language  Models  (LLMs)  are trained  on a vast amount  of text to interpret  and generate human-like  textual  content.  They are becoming  a vital vehicle  in realizing  the vision of the autonomous  enterprise,  with organizations  today actively  adopting  LLMs to automate  many aspects  of their operations.  LLMs are likely to play a prominent  role in future AI-augmented business  process  management  systems  (ABPMSs)  catering  functionalities  across all system lifecycle  stages. One such system\u2019s  functionality  is Situation-Aware  eXplainability  (SAX), which relates to generating  causally  sound and yet human-interpretable  explanations  that take into account  the process  context  in which the explained  condition  occurred. In this paper, we present  the SAX4BPM  framework  developed  to generate  SAX explanations. The SAX4BPM  suite consists  of a set of services  and a central  knowledge  repository.  The functionality  of these services  is to elicit the various  knowledge  ingredients  that underlie SAX explanations.  A key innovative  component  among these ingredients  is the causal process execution  view. In this work, we integrate  the framework  with an LLM to leverage  its power to synthesize  the various  input ingredients  for the sake of improved  SAX explanations. Since the use of LLMs for SAX is also accompanied  by a certain  degree of doubt related to its capacity  to adequately  fulfill SAX along with its tendency  for hallucination  and lack of inherent  capacity  to reason,  we pursued  a methodological  evaluation  of the perceived  quality of the generated  explanations.  To this aim, we developed  a designated  scale and conducted a rigorous  user study. Our findings  show that the input presented  to the LLMs aided with the guard-railing  of its performance,  yielding  SAX explanations  having better-perceived  fidelity.  This improvement  is moderated  by the perception  of trust and curiosi",
    "Understanding the Capabilities and Limitations of Large Language Models for Cultural Commonsense": "Large language models (LLMs) have demonstrated substantial commonsense understanding through numerous benchmark evaluations. However, their understanding of cultural commonsense remains largely unexamined. In this paper, we conduct a comprehensive examination of the capabilities and limitations of several state-of-the-art LLMs in the context of cultural commonsense tasks. Using several general and cultural commonsense benchmarks, we find that (1) LLMs have a significant discrepancy in performance when tested on culture-specific commonsense knowledge for different cultures; (2) LLMs\u2019 general commonsense capability is affected by cultural context; and (3) The language used to query the LLMs can impact their performance on cultural-related tasks. Our study points to the inherent bias in the cultural understanding of LLMs and provides insights that can help develop culturally-aware language models.",
    "Large Language Models for Business Process Management: Opportunities and Challenges": "Large language models are deep learning models with a large number of parameters. The models made noticeable progress on a large number of tasks, and as a consequence allowing them to serve as valuable and versatile tools for a diverse range of applications. Their capabilities also offer opportunities for business process management, however, these opportunities have not yet been systematically investigated. In this paper, we address this research problem by foregrounding various management tasks of the BPM lifecycle. We investigate six research directions highlighting problems that need to be addressed when using large language models, including usage guidelines for practitioners.",
    "Advancements and Applications of Generative Artificial Intelligence and Large Language Models on Business Management: A Comprehensive Review": "This comprehensive review delves into the landscape and recent advancements of Generative Artificial Intelligence (AI) and Large Language Models (LLMs), shedding light on their transformative potential and applications across various sectors. Generative AI, exemplified by models like ChatGPT, DALL -E, and Midjourney, has rapidly evolved  and is  driven by breakthroughs in deep learning architectures and the availability of vast datasets. Concurrently, LLMs have revolutionized natural language processing tasks , utilizing vast text corpora to generate human -like text. The study explores recent developments, including the introduction o"
  },
  "Education": {
    "Practical and Ethical Challenges of Large Language Models in Education: A Systematic Scoping Review": "Educational technology innovations leveraging large language models (LLMs) have shown the potential to automate the laborious process of generating and analysing textual content. While various innovations have been developed to automate a range of educational tasks (e.g., question generation, feedback provision, and essay grading), there are concerns regarding the practicality and ethicality of these innovations. Such concerns may hinder future research and the adoption of LLMs - based innovations in authentic educational contexts. To address this, we conducted a systematic scoping review of 118 peer - reviewed papers published since 2017 to pinpoint the current state of research on using LLMs to automate and support educational tasks. The findings revealed 53 use cases for LLMs in automating education tasks, categorised into nine main categories: profiling/labelling, detection, grading, teaching support, prediction, knowledge representation, feedback, content generation, and recommendation. Additionally, we also identified several practical and ethical challenges, including low technological readiness, lack of replicability and transparency, and insufficient privacy and beneficence considerations. The findings were summarised into three recommendations for future studies, including updating existing innovations with state - of - the - art models (e.g., GPT - 3/4), embracing the initiative of open - sourcing models/systems, and adopting a human - centred approach throughout the developmental process. As the intersection of AI and education is continuously evolving, the findings of this study can serve as an essential reference point for researchers, allowing them to leve",
    "A Survey on Evaluation of Large Language Models": "Large language models (LLMs) are gaining increasing popularity in both academia and industry, owing to their unprecedented performance in various applications. As LLMs continue to play a vital role in both research and daily use, their evaluation becomes increasingly critical, not only at the task level, but also at the society level for better understanding of their potential risks. Over the past years, significant efforts have been made to examine LLMs from various perspectives. This paper presents a comprehensive review of these evaluation methods for LLMs, focusing on three key dimensions: what to evaluate, where to evaluate, and how to evaluate. Firstly, we provide an overview from the perspective of evaluation tasks, encompassing general natural language processing tasks, reasoning, medical usage, ethics, education, natural and social sciences, agent applications, and other areas. Secondly, we answer the \u2018where\u2019 and \u2018how\u2019 questions by diving into the evaluation methods and benchmarks, which serve as crucial components in assessing the performance of LLMs. Then, we summarize the success and failure cases of LLMs in different tasks. Finally, we shed light on several",
    "Large Language Models in Education: Vision and Opportunities": "With the rapid development of artificial intelligence technology, large language models (LLMs) have become a hot research topic. Education plays an important role in human social development and progress. Traditional education faces challenges such as individual student differences, insufficient allocation of teaching resources, and assessment of teaching effectiveness. Therefore, the applications of LLMs in the field of digital/smart education have broad prospects. The research on educational large models (EduLLMs) is constantly evolving, providing new methods and approaches to achieve personalized learning, intelligent tutoring, and educational assessment goals, thereby improving the quality of education and the learning experience. This article aims to investigate and summarize the application of LLMs in smart education. It first introduces the research background and motivation of LLMs and explains the essence of LLMs. It then discusses the relationship between digital education and EduLLMs and summarizes the current research status of educational large models. The main contributions are the systematic summary and vision of the research background, motivation, and application of large models for education (LLM4Edu). By reviewing existing research, this article provides guidance and insights for educators, researchers, and policy - makers to gain a deep understanding of the potential and challenges of LLM4Edu. It further provides guidance for further advancing the development and application of LLM4Edu, while still facing technical, ethical, and practical challenges requiring further research and exploration.",
    "Large Language Models for Education: A Survey and Outlook": "The advent of large language models (LLMs) has brought in a new era of possibilities in the realm of education. This survey paper summarizes the various technologies of LLMs in educational settings from multifaceted perspectives, encompassing student and teacher assistance, adaptive learning, and commercial tools. We systematically review the technological advancements in each perspective, organize related datasets and benchmarks, and identify the risks and challenges associated with the deployment of LLMs in education. Furthermore, we outline future research opportunities, highlighting the potential promising directions. Our survey aims to provide a comprehensive technological picture for educators, researchers, and policymakers to harness the power of LLMs to revolutionize educational practices and foster a more effective personalized learning environment.",
    "Large Language Models for Education: A Survey": "Artificial intelligence (AI) has a profound impact on traditional education. In recent years, large language models(LLMs) have been increasingly used in various applications such as natural language processing, computer vision, speech recognition, and autonomous driving. LLMs have also been applied in many fields, including recommendation, finance, government, education, legal affairs, and finance. As powerful auxiliary tools, LLMs incorporate various technologies such as deep learning, pre - training, fine - tuning, and reinforcement learning. The use of LLMs for smart education (LLMEdu) has been a significant strategic direction for countries worldwide. While LLMs have shown great promise in improving teaching quality, changing education models, and modifying teacher roles, the technologies are still facing several challenges. In this paper, we conduct a systematic review of LLMEdu, focusing on current technologies, challenges, and future developments. We first summarize the current state of LLMEdu and then introduce the characteristics of LLMs and education, as well as the benefits of integrating LLMs into education. We also review the process of integrating LLMs into the education industry, as well as the introduction of related technologies. Finally, we discuss the challenges and problems faced by LLMEdu, as well as prospects for future optimization of LLMEdu.",
    "A Position Paper\nChatGPT for Good? On Opportunities and\nChallenges of Large Language Models for Education": "Large language models represent a significant advancement in the field of AI. The underlying technology is key to further innovations and, despite critical views and even bans within communities and regions, large language models are here to stay. This position paper presents the potential benefits and challenges of educational applications of large language models, from student and teacher perspectives. We briefly discuss the current state of large language models and their applications. We then highlight how these models can be used to create educational content, improve student engagement and interaction, and personalize learning experiences. With regard to challenges, we argue that large language models in education require teachers and learners to develop sets of competencies and literacies necessary to both understand the technology as well as their limitations and unexpected brittleness of such systems. In addition, a clear strategy within educational systems and a clear pedagogical approach with a strong focus on critical thinking and strategies for fact checking are required to integrate and take full advantage of large language models in learning settings and teaching curricula. Other challenges such as the potential bias in the output, the need for continuous human oversight, and the potential for misuse are not unique to the application of AI in education. But we believe that, if handled sensibly, these challenges can offer insights and opportunities in education scenarios to acquaint students early on with potential societal biases, criticalities, and risks of AI applications. We conclude with recommendations for how to address these challenges and ensure that such models are used in a responsible and ethical manner in education.",
    "Large Language Models in Medical Education: Opportunities, Challenges, and Future Directions": "The integration of large language models (LLMs), such as those in the Generative Pre-trained Transformers (GPT) series, into medical education has the potential to transform learning experiences for students and elevate their knowledge, skills, and competence. Drawing on a wealth of professional and academic experience, we propose that LLMs hold promise for revolutionizing medical curriculum development, teaching methodologies, personalized study plans and learning materials, student assessments, and more. However, we also critically examine the challenges that such integration might pose by addressing issues of algorithmic bias, overreliance, plagiarism, misinformation, inequity, privacy, and copyright concerns in medical education. As we navigate the shift from an information-driven educational paradigm to an artificial intelligence (AI)\u2013driven educational paradigm, we argue that it is paramount to understand both the potential and the pitfalls of LLMs in medical education. This paper thus offers our perspective on the opportunities and challenges of using LLMs in this context. We believe that the insights gleaned from this analysis will serve as a foundation for future recommendations and best practices in the field, fostering the responsible and effective use of AI"
  },
  "Energy": {
    "Applying Large Language Models to Power Systems: Potential Security Threats": "Applying large language models (LLMs) to modern power systems presents a promising avenue for enhancing decision-making and operational efficiency. However, this action may also incur potential security threats, which have not been fully recognized so far. To this end, this article analyzes potential threats incurred by applying LLMs to power systems, emphasizing the need for urgent research and development of countermeasures.",
    "Opportunities and Challenges of Applying Large Language Models  in Building Energy Efficiency and Decarbonization Studies : An Exploratory Overview": "In recent years, the rapid advancement and impressive capabilities  of Large Language Models (LLMs) have been evident across various domains.  This paper explores the application, implications, and potential of LLMs in building energy efficiency and decarbonization studies . The wide -ranging capabilities of LLMs are examined in the context of the building energy field, including intelligent control systems, code generation, data infrastructure , knowledge extraction , and education . Despite the promising potenti al of LLMs, challenges including complex and expensive computation , data privacy, security and copyright, complexity  in fine -tuned LLMs , and self-consistency are discussed. The paper concludes with a call for future research focused on the enhancement of LLMs for domain -specific tasks, multi -modal LLMs , and collaborative research between AI and energy experts.",
    "EXPLORING THE CAPABILITIES AND LIMITATIONS OF LARGE LANGUAGE MODELS IN THE ELECTRIC ENERGY SECTOR\u2217": "Large Language Models (LLMs) as ChatBots have drawn remarkable attention thanks to their versatile capability in natural language processing as well as in a wide range of tasks. While there has been great enthusiasm towards adopting such foundational model-based artificial intelligence tools in all sectors possible, the capabilities and limitations of such LLMs in improving the operation of the electric energy sector need to be explored, and this article identifies fruitful directions in this regard. Key future research directions include data collection systems for fine-tuning LLMs, embedding power system-specific tools in the LLMs, and retrieval augmented generation (RAG)-based knowledge pool to improve the quality of LLM responses and LLMs in safety-critical use cases.",
    "Risks of Practicing Large Language Models in Smart Grid: Threat Modeling and Validation": "Large language models (LLMs) represent significant breakthroughs in artificial intelligence and hold potential for applications within smart grids. However, as demonstrated in previous literature, AI technologies are susceptible to various types of attacks. It is crucial to investigate and evaluate the risks associated with LLMs before deploying them in critical infrastructure like smart grids. In this paper, we systematically evaluated the risks of LLMs and identified two major types of attacks relevant to potential smart grid LLM applications, presenting the corresponding threat models. We validated these attacks using popular LLMs and real smart grid data. Our validation demonstrates that attackers are capable of injecting bad data and retrieving domain knowledge from LLMs employed in different smart grid applications.",
    "Large Language Models integration in Smart Grids": "Large Language Models (LLMs) are changing the way we operate our society and will undoubt-edly impact power systems as well\u2014but how exactly? By integrating various data streams\u2014including real-time grid data, market dynamics, and consumer behaviors\u2014LLMs have the potential to make power system operations more adaptive, enhance proactive security measures, and deliver personalized energy services. This paper provides a comprehensive analysis of 30 real-world applications across eight key categories: Grid Operations and Management, Energy Markets and Trading, Personalized Energy Management and Customer Engagement, Grid Planning and Education, Grid Security and Compliance, Advanced Data Analysis and Knowledge Discov-ery, Emerging Applications and Societal Impact, and LLM-Enhanced Reinforcement Learning. Critical technical hurdles, such as data privacy and model reliability, are examined, along with possible solutions. Ultimately, this review illustrates how LLMs can significantly contribute to building more resilient, efficient, and sustainable energy infrastructures, underscoring the necessity of their responsible and equitable deployment.",
    "Big Data for Energy Management and Energy-Efficient Buildings": "European buildings are producing a massive amount of data from a wide spectrum of energy-related sources, such as smart meters\u2019 data, sensors and other Internet of things devices, creating new research challenges. In this context, the aim of this paper is to present a high-level data-driven architecture for buildings data exchange, management and real-time processing. This multi-disciplinary big data environment enables the integration of cross-domain data, combined with emerging artificial intelligence algorithms and distributed ledgers technology. Semantically enhanced, interlinked and multilingual repositories of heterogeneous types of data are coupled with a set of visualization, querying and exploration tools, suitable application programming interfaces (APIs) for data exchange, as well as a suite of configurable and ready-to-use analytical components that implement a series of advanced machine learning and deep learning algorithms. The results from the pilot application of the proposed framework are presented and discussed. The data-driven architecture enables reliable and effective policymaking, as well as supports the creation and exploitation of innovative energy efficiency services through the utilization of a wide variety of data, for the effective operation of buildings.",
    "Privacy and Security in Artificial Intelligence and Machine Learning Systems for Renewable Energy Big Data": "This paper explores the critical intersection of security and privacy in advanced artificial intelligence (AI) and machine learning (ML) with Internet of Things (IoT) systems and edge computing applied to big data in the renewable energy (RE) sector, where the generated data is grown exponentially, presenting unique challenges in data management, analysis, and security. This study discusses the complexities of anomaly detection (AD) in RE data, examining the evolving security threats and the need for real -time processing. Through a comprehensive literature review and the proposal of an innovative framework, we address the security and privacy challenges in AD for RE data, evaluate the effectiveness of current solutions, and propose robust strategies for enhancing security measures. The study underscores the need for continuous security protocols\u2019 adaptation to evolving threats. It emphasizes the importance of regular audits and compliance with regulatory standards to maintain the resilience of RE systems against cyber threats."
  },
  "Finance": {
    "Financial sentiment analysis for pre-trained language models incorporating dictionary knowledge and neutral features": "With increasing financial market complexity, accurate sentiment analysis of financial texts has become crucial. Traditional methods often misinterpret financial terminology and show high error rates in neutral sentiment recognition. This study aims to improve financial sentiment analysis accuracy through developing EnhancedFin-SentiBERT, a model incorporating financial domain pre-training, dictionary knowledge embedding, and neutral feature extraction. Experiments on the FinancialPhraseBank, FiQA and Headline datasets demonstrate the model\u2019s superior performance compared to mainstream methods, particularly in neutral sentiment recognition. Ablation analysis reveals that dictionary knowledge embedding and neutral feature extraction contribute most significantly to model improvement.",
    "Fine-tuning Smaller Language Models for Question Answering over Financial Documents": "Recent research has shown that smaller language models can acquire substantial reasoning abilities when fine-tuned with reasoning exemplars crafted by a significantly larger teacher model. We explore this paradigm for the financial domain, focusing on the challenge of answering questions that require multi-hop numerical reasoning over financial texts. We assess the performance of several smaller models that have been fine-tuned to generate programs that encode the required financial reasoning and calculations. Our findings demonstrate that these fine-tuned smaller models approach the performance of the teacher model. To provide a granular analysis of model performance, we propose an approach to investigate the specific student model capabilities that are enhanced by fine-tuning. Our empirical analysis indicates that fine-tuning refines the student models ability to express and apply the required financial concepts along with adapting the entity extraction for the specific data format. In addition, we hypothesize and demonstrate that comparable financial reasoning capability can be induced using relatively smaller datasets.",
    "Proxy Tuning for Financial Sentiment Analysis: Overcoming Data Scarcity and Computational Barriers": "Financial sentiment analysis plays a pivotal role in the financial domain. However, the task remains challenging due to the nuanced nature of financial sentiment, the need for high interpretability, and the scarcity of high-quality datasets. To address these issues, we leverage recent advancements in large language models (LLMs) and propose to adapt proxy tuning for financial sentiment analysis. Proxy tuning efficiently transfers knowledge from a pre-trained expert model to a controllable base model by incorporating logit differences, steering the base model toward the desired sentiment representation. Our method offers significant advantages: (1) it is training-free, reducing computational demands and data dependency; (2) it achieves promising performance, with a 36.67% improvement over the base model and over 90% of the tuned model\u2019s performance; and (3) it is highly adaptable, functioning in a plug-and-play manner without requiring access to model architectures or weights. These results demonstrate the potential of proxy tuning as an efficient and practical solution for financial sentiment analysis in data-scarce scenarios.",
    "Hidden Technical Debts for Fair Machine Learning in Financial Services": "The recent advancements in machine learning (ML) have demon strated the poten - tial for providing a powerful solution to build complex pred iction systems in a short time. However, in highly regulated industries, such a s the \ufb01nancial technol - ogy (Fintech), people have raised concerns about the risk of ML systems discrimi - nating against speci\ufb01c protected groups or individuals. To address these concerns, researchers have introduced various mathematical fairnes s metrics and bias miti - gation algorithms. This paper discusses hidden technical d ebts and challenges of building fair ML systems in a production environment for Fin tech. We explore various stages that require attention for fairness in the ML system development and deployment life cycle. To identify hidden technical deb ts that exist in build - ing fair ML system for Fintech, we focus on key pipeline stage s including data preparation, model development, system monitoring and int egration in produc - tion. Our analysis shows that enforcing fairness for produc tion - ready ML systems in Fintech requires speci\ufb01c engineering commitments at dif ferent stages of ML system life cycle. We also propose several initial starting points to mitigate these technical debts for deploying fair ML systems in production.",
    "BloombergGPT: A Large Language Model for Finance": "The use of NLP in the realm of financial technology is broad and complex, with applications ranging from sentiment analysis and named entity recognition to question answering. Large Language Models (LLMs) have been shown to be effective on a variety of tasks; however, no LLM specialized for the financial domain has been reported in literature. In this work, we present BloombergGPT , a 50 billion parameter language model that is trained on a wide range of financial data. We construct a 363 billion token dataset based on Bloomberg\u2019s extensive data sources, perhaps the largest domain-specific dataset yet, augmented with 345 billion tokens from general purpose datasets. We validate BloombergGPT on standard LLM benchmarks, open financial benchmarks, and a suite of internal benchmarks that most accurately reflect our intended usage. Our mixed dataset training leads to a model that outperforms existing models on financial tasks by significant margins without sacrificing performance on general LLM benchmarks. Additionally, we explain our modeling choices, training process, and evaluation methodology. We release Training Chronicles (Appendix C) detailing our experience in training BloombergGPT .",
    "DATA-CENTRIC FINANCIAL LARGE LANGUAGE MODELS": "Large language models (LLMs) show promise for natural language tasks but struggle when applied directly to complex domains like finance. LLMs have difficulty reasoning about and integrating all relevant information. We propose a data-centric approach to enable LLMs to better handle financial tasks. Our key insight is that rather than overloading the LLM with everything at once, it is more effective to preprocess and pre-understand the data. We create a financial LLM (FLLM) using multitask prompt-based finetuning to achieve data pre-processing and pre-understanding. However, labeled data is scarce for each task. To overcome manual annotation costs, we employ abductive augmentation reasoning (AAR) to automatically generate training data by modifying the pseudo labels from FLLM\u2019s own outputs. Experiments show our data-centric FLLM with AAR substantially outperforms baseline financial LLMs designed for raw text, achieving state-of-the-art on financial analysis and interpretation tasks. We also open source a new benchmark for financial analysis and interpretation. Our methodology provides a promising path to unlock LLMs\u2019 potential for complex real-world domains.",
    "A Survey of Large Language Models for Financial Applications: Progress, Prospects and Challenges": "Recent advances in large language models (LLMs) have unlocked novel opportunities for machine learning applications in the financial domain. These models have demonstrated remarkable capabilities in understanding context, processing vast amounts of data, and generating human-preferred contents. In this survey, we explore the application of LLMs on various financial tasks, focusing on their potential to transform traditional practices and drive innovation. We provide a discussion of the progress and advantages of LLMs in financial contexts, analyzing their advanced technologies as well as prospective capabilities in contextual understanding, transfer learning flexibility, complex emotion detection, etc. We then highlight this survey for categorizing the existing literature into key application areas, including linguistic tasks, sentiment analysis, financial time series, financial reasoning, agent-based modeling, and other applications. For each application area, we delve into specific methodologies, such as textual analysis, knowledge-based analysis, forecasting, data augmentation, planning, decision support, and simulations. Furthermore, a comprehensive collection of datasets, model assets, and useful codes associated with mainstream applications are presented as resources for the researchers and practitioners. Finally, we outline the challenges and opportunities for future research, particularly emphasizing a number of distinctive aspects in this field. We hope our work can help facilitate the adoption and further development of LLMs in the financial sector.",
    "Fin-o1: On the Transferability of Reasoning-Enhanced LLMs and Reinforcement Learning to Finance": "As the fundamental capability behind decision-making in finance, financial reasoning poses distinct challenges for LLMs. Although reinforcement learning (RL) have boosted generic reasoning, the progress in finance is hindered by the absence of empirical study of building effective financial chain-of-thought (CoT) corpus, a systematic comparison of different RL methods, and comprehensive benchmarks. To address these gaps, we introduce FinCoT, the first open high-fidelity CoT corpus for finance, distilled from seven QA datasets by a novel three-stage pipeline that incorporates domain supervision, iterative LLM refinement, and difficulty-aware filtering. Based on FinCoT, we develop Fin-o1, the first open financial reasoning models trained via supervised fine-tuning and GRPO-based RL. Our models outperform existing financial reasoning models and SOTA general models such as GPT-o1, DeepSeek-R1, and GPT-4.5. We also investigate the effectiveness of three different RL methods in improving domain-specific reasoning, offering the first such empirical study. We finally propose FinReason, the first financial reasoning benchmark covering multi-table analysis, long-context reasoning, and equation-based tasks, and evaluate 29 LLMs. Our extensive experiments reveal general reasoning models excel on standard benchmarks yet exhibit obvious performance degradation in financial contexts; even finance-tuned models like Dianjin-R1 and FinR1 degrade on lengthy documents. In contrast, our Fin-o1 models consistently outperform their backbones and larger GPT-o1 and DeepSeek-R1, confirming the effectiveness of our data building and model training strategy. Our study further shows that GRPO yields reliable gains whereas PPO and DPO do not, highlighting the need for targeted data and optimisation rather than scale alone. These findings show that financial reasoning has unique challenges unmet by mere model scaling or generic techniques, highlighting the need for specialized data, models, and optimization. We release all datasets, models, and codes to support future res",
    "Responsible Innovation: A Strategic Framework for Financial LLM Integration": "Financial institutions of all sizes are increasingly adopting Large Language Models (LLMs) to enhance credit assessments, deliver personalized client advisory services, and automate various language-intensive processes. However, effectively deploying LLMs requires careful management of stringent data governance requirements, heightened demands for interpretability, ethical responsibilities, and rapidly evolving regulatory landscapes. To address these challenges, we introduce a structured six-decision framework specifically designed for the financial sector, guiding organizations systematically from initial feasibility assessments to final deployment strategies. The framework encourages institutions to: (1) evaluate whether an advanced LLM is necessary at all, (2) formalize robust data governance and privacy safeguards, (3) establish targeted risk management mechanisms, (4) integrate ethical considerations early in the development process, (5) justify the initiative\u2019s return on investment (ROI) and strategic value, and only then (6) choose the optimal implementation pathway\u2014open-source versus proprietary, or in-house versus vendor-supported\u2014aligned with regulatory requirements and operational realities. By linking strategic considerations with practical steps such as pilot testing, maintaining comprehensive audit trails, and conducting ongoing compliance evaluations, this decision framework offers a structured roadmap for responsibly leveraging LLMs. Rather than acting as a rigid, one-size-fits-all solution, it shows how advanced language models can be thoughtfully integrated into existing workflows\u2014balancing innovation with accountability to uphold stakeholder trust and regulatory integrity.",
    "LLMs Meet Finance: Fine-Tuning Foundation Models for the Open FinLLM Leaderboard": "This paper investigates the application of large language models (LLMs) to financial tasks. We fine-tuned foundation models using the Open FinLLM Leaderboard as a benchmark. Building on Qwen2.5 and Deepseek-R1, we employed techniques including supervised fine-tuning (SFT), direct preference optimization (DPO), and reinforcement learning (RL) to enhance their financial capabilities. The fine-tuned models demonstrated substantial performance gains across a wide range of financial tasks. Moreover, we measured the data scaling law in the financial domain. Our work demonstrates the potential of large language models (LLMs) in financial applications.",
    "BizFinBench: A Business-Driven Real-World Financial Benchmark for Evaluating LLMs": "Large language models excel in general tasks, yet assessing their reliability in logic -heavy, precision -critical domains like finance, law, and healthcare remains challenging. To address this, we introduce BizFinBench, the first benchmark specifically designed to evaluate LLMs in real-world financial applications. BizFinBench consists of 6,781 well-annotated queries in Chinese, spanning five dimensions: numerical calculation, reasoning, information extraction, prediction recognition, and knowledge-based question answering, grouped into nine fine-grained categories. The benchmark includes both objective and subjective metrics. We also introduce IteraJudge, a novel LLM evaluation method that reduces bias when LLMs serve as evaluators in objective metrics. We benchmark 25 models, including both proprietary and open-source systems. Extensive experiments show that no model dominates across all tasks. Our evaluation reveals distinct capability patterns: (1) In Numerical Calculation, Claude-3.5-Sonnet (63.18) and DeepSeek-R1 (64.04) lead, while smaller models like Qwen2.5-VL-3B (15.92) lag significantly; (2) In Reasoning, proprietary models dominate (ChatGPT-o3: 83.58, Gemini-2.0-Flash: 81.15), with open-source models trailing by up to 19.49 points; (3) In Information Extraction, the performance spread is the largest, with DeepSeek-R1 scoring 71.46, while Qwen3-1.7B scores 11.23; (4) In Prediction Recognition, performance variance is minimal, with top models scoring between 39.16 and 50.00. We find that while current LLMs handle routine finance queries competently, they struggle with complex scenarios requiring cross-concept reasoning. BizFinBench offers a rigorous, business-aligned benchmark for future research. The code and dataset are available at https://github.com/HiThink-Research/BizFinBench.",
    "Large Language Models in Finance: A Survey": "Recent advances in large language models (LLMs) have opened new possibilities for artificial intelligence applications in finance. In this paper, we provide a practical survey focused on two key aspects of utilizing LLMs for financial tasks: existing solutions and guidance for adoption. First, we review current approaches employing LLMs in finance, including leveraging pretrained models via zero-shot or few-shot learning, fine-tuning on domain-specific data, and training custom LLMs from scratch. We summarize key models and evaluate their performance improvements on financial natural language processing tasks. Second, we propose a decision framework to guide financial professionals in selecting the appropriate LLM solution based on their use case constraints around data, compute, and performance needs. The framework provides a pathway from lightweight experimentation to heavy investment in customized LLMs. Lastly, we discuss limitations and challenges around leveraging LLMs in financial applications. Overall, this survey aims to synthesize the state-of-the-art and provide a roadmap for responsibly applying LLMs to advance financial AI.",
    "Large Language Models and Sentiment Analysis in Financial Markets: A Review, Datasets, and Case Study": "This paper comprehensively examines Large Language Models (LLMs) in sentiment analysis, specifically focusing on financial markets and exploring the correlation between news sentiment and Bitcoin prices. We systematically categorize various LLMs used in financial sentiment analysis, highlighting their unique applications and features. We also investigate the methodologies for effective data collection and categorization, underscoring the need for diverse and comprehensive datasets. Our research features a case study investigating the correlation between news sentiment and Bitcoin prices, utilizing advanced sentiment analysis and financial analysis methods to demonstrate the practical application of LLMs. The findings reveal a modest but discernible correlation between news sentiment and Bitcoin price fluctuations, with historical news patterns showing a more substantial impact on Bitcoin\u2019s longer - term price than immediate news events. This highlights LLMs\u2019 potential in market trend prediction and informed investment decision - making.",
    "ChatGPT: Unlocking the Future of NLP in Finance": "This paper reviews the current state of ChatGPT technology in finance and its potential to improve existing NLP-based financial applications. We discuss the ethical and regulatory considerations, as well as potential future research directions in the field. The literature suggests that ChatGPT has the potential to improve NLP-based financial applications, but also raises ethical and regulatory concerns that need to be addressed. The paper highlights the need for research in robustness, interpretability, and ethical considerations to ensure responsible use of ChatGPT technology in finance.",
    "Explainable Artificial Intelligence (XAI) approaches for transparency and accountability in financial decision -making": "Recently, there has been a growing trend in incorporating Artificial Intelligence (AI) into financial decision - making, prompting concerns about the transparency and accountability  of these intricate systems. This study investigates the impact of Explainable Artificial Intelligence (XAI) approaches in alleviating these concerns and improving transparency in financial decision - making processes. The paper commences by outlining the cu rrent landscape of AI applications in finance, underscoring the complex and opaque nature of advanced machine learning models. The lack of interpretability in these models presents a significant challenge, as stakeholders, regulators, and end - users often s truggle to comprehend the reasoning behind AI - driven financial decisions. This opacity raises questions regarding accountability and trust, particularly in critical financial scenarios. The primary focus of the research centers on the analysis and implemen tation of XAI techniques to introduce transparency into financial AI systems. Various XAI methods, including rule - based systems, model - agnostic approaches, and interpretable machine learning models, are scrutinized for their effectiveness in producing unde rstandable explanations for AI - driven financial decisions. The paper explores how these approaches can be tailored to meet the distinct requirements of the financial domain, where interpretability is essential for regulatory compliance and stakeholder conf idence. Moreover, the research delves into the potential impact of XAI on accountability mechanisms within financial institutions. By offering interpretable explanations for model outputs, XAI not only enhances transparency but also empowers financial prof essionals to identify and rectify biases, errors, or unethical behaviour in AI algorithms. By promoting transparency and accountability, XAI not only addresses ethical concerns but also facilitates the responsible and trustworthy deployment of AI in the fi nancial sector. This, in turn, contributes to the advancement of fair, reliable, and secure financial systems."
  },
  "Industry": {
    "Large Language Models for Telecom: Forthcoming Impact on the Industry": "Large Language Models (LLMs), AI-driven models that can achieve general-purpose language understanding and generation, have emerged as a transformative force, revolutionizing fields well beyond Natural Language Processing (NLP) and garnering unprecedented attention. As LLM technology continues to progress, the telecom industry is facing the prospect of its impact on its landscape. To elucidate these implications, we delve into the inner workings of LLMs, providing insights into their current capabilities and limitations. We also examine the use cases that can be readily implemented in the telecom industry, streamlining tasks, such as anomalies resolutions and technical specifications comprehension, which currently hinder operational efficiency and demand significant manpower and expertise. Furthermore, we uncover essential research directions that deal with the distinctive challenges of utilizing the LLMs within the telecom domain. Addressing them represents a significant stride towards fully harnessing the potential of LLMs and unlocking their capabilities to the fullest extent within the telecom domain.",
    "Large Language Models for Robotics: Opportunities, Challenges, and Perspectives": "Large language models (LLMs) have undergone significant expansion and have been increasingly integrated across various domains. Notably, in the realm of robot task planning, LLMs harness their advanced reasoning and language comprehension capabilities to formulate precise and efficient action plans based on natural language instructions. However, for embodied tasks, where robots interact with complex environments, text-only LLMs often face challenges due to a lack of compatibility with robotic visual perception. This study provides a comprehensive overview of the emerging integration of LLMs and multimodal LLMs into various robotic tasks. Additionally, we propose a framework that utilizes multimodal GPT - 4V to enhance embodied task planning through the combination of natural language instructions and robot visual perceptions. Our results, based on diverse datasets, indicate that GPT - 4V effectively enhances robot performance in embodied tasks. This extensive survey and evaluation of LLMs and multimodal LLMs across a variety of robotic tasks enriches the understanding of LLM - centric embodied intelligence and provides forward - looking insights toward bridging the gap in Human - Robot - Environment interaction.",
    "LLMs with Industrial Lens: Deciphering the Challenges and Prospects \u2013 A Survey": "Large language models (LLMs) have become the secret ingredient driving numerous industrial applications, showcasing their remarkable versatility across a diverse spectrum of tasks. From natural language processing and sentiment analysis to content generation and personalized recommendations, their unparalleled adaptability has facilitated widespread adoption across industries. This transformative shift driven by LLMs underscores the need to explore the underlying associated challenges and avenues for enhancement in their utilization. In this paper, our objective is to unravel and evaluate the obstacles and opportunities inherent in leveraging LLMs within an industrial context. To this end, we conduct a survey involving a group of industry practitioners, develop four research questions derived from the insights gathered, and examine 68 industry papers to address these questions and derive meaningful conclusions. We maintain the Github1repository with the most recent papers in the field.",
    "On-Device LLMs for SMEs: Challenges and Opportunities": "This paper presents a systematic review of the infrastructure requirements for deploying Large Language Models (LLMs) on-device within the context of small and medium-sized enterprises (SMEs), focusing on both hardware and software perspectives. From the hardware viewpoint, we discuss the utilization of processing units like GPUs and TPUs, efficient memory and storage solutions, and strategies for effective deployment, addressing the challenges of limited computational resources typical in SME settings. From the software perspective, we explore framework compatibility, operating system optimization, and the use of specialized libraries tailored for resource-constrained environments. The review is structured to first identify the unique challenges faced by SMEs in deploying LLMs on-device, followed by an exploration of the opportunities that both hardware innovations and software adaptations offer to overcome these obstacles. Such a structured review provides practical insights, contributing significantly to the community by enhancing the technological resilience of SMEs in integrating LLMs.",
    "Large Language Models for Manufacturing": "The rapid advances in Large Language Models (LLMs) have the potential to transform manu- facturing industry, offering new opportunities to optimize processes, improve efficiency, and drive innovation. This paper provides a comprehensive exploration of the integration of LLMs into the manufacturing domain, focusing on their potential to automate and enhance various aspects of manufacturing, from product design and development to quality control, supply chain opti- mization, and talent management. Through extensive evaluations across multiple manufacturing tasks, we demonstrate the remarkable capabilities of state-of-the-art LLMs, such as GPT-4V, in understanding and executing complex instructions, extracting valuable insights from vast amounts of data, and facilitating knowledge sharing. We also delve into the transformative potential of LLMs in reshaping manufacturing education, automating coding processes, enhancing robot con- trol systems, and enabling the creation of immersive, data-rich virtual environments through the industrial metaverse. By highlighting the practical applications and emerging use cases of LLMs in manufacturing, this paper aims to provide a valuable resource for professionals, researchers, and decision-makers seeking to harness the power of these technologies to address real-world chal- lenges, drive operational excellence, and unlock sustainable growth in an increasingly competitive landscape.",
    "Ship Detection under Low-Visibility Weather Interference via an Ensemble Generative Adversarial Network": "Maritime ship detection plays a crucial role in smart ships and intelligent transportation systems. However, adverse maritime weather conditions, such as rain streak and fog, can signi\ufb01cantly impair the performance of visual systems for maritime traf\ufb01c. These factors constrain the performance of traf\ufb01c monitoring systems and ship-detection algorithms for autonomous ship navigation, affecting maritime safety. The paper proposes an approach to resolve the problem by visually removing rain streaks and fog from images, achieving an integrated framework for accurate ship detection. Firstly, the paper employs an attention generation network within an adversarial neural network to focus on the distorted regions of the degraded images. The paper also utilizes a contextual encoder to infer contextual information within the distorted regions, enhancing the credibility of image restoration. Secondly, a weighted bidirectional feature pyramid network (BiFPN) is introduced to achieve rapid multi-scale feature fusion, enhancing the accuracy of maritime ship detection. The proposed GYB framework was validated using the SeaShip dataset. The experimental results show that the proposed framework achieves an average accuracy of 96.3%, a recall of 95.35%, and a harmoni",
    "Industrial applications of large language models": "Large language models (LLMs) are artificial intelligence (AI) based computational models designed to understand and generate human like text. With billions of training parameters, LLMs excel in identifying intricate language patterns, enabling remarkable performance across a variety of natural language processing (NLP) tasks. After the introduction of transformer architectures, they are impacting the industry with their text generation capabilities. LLMs play an innovative role across various industries by automating NLP tasks. In healthcare, they assist in diagnosing diseases, personalizing treatment plans, and managing patient data. LLMs provide predictive maintenance in automotive industry. LLMs provide recommendation systems, and consumer behavior analyzers. LLMs facilitates researchers and offer personalized learning experiences in education. In finance and banking, LLMs are used for fraud detection, customer service automation, and risk management. LLMs are driving significant advancements across the industries by automating tasks, improving accuracy, and providing deeper insights. Despite these advancements, LLMs face challenges such as ethical concerns, biases in training data, and significant computational resource requirements, which must be addressed to ensure impartial and sustainable deployment. This study provides a comprehensive analysis of LLMs, their evolution, and their diverse applications across industries, offering researchers valuable insights into their transformative potential and the accompanying limitations.",
    "ChatGPT and similar generative artificial intelligence (AI) for smart industry: role, challenges, and opportunities for Industry 4.0, Industry 5.0, and Society 5.0": "Generative Artificial Intelligence (AI) models like ChatGPT have become transformative tools across various industries, marking the advent of Industry 4.0, Industry 5.0, and Society 5.0. These AI systems have significantly improved communication and problem - solving abilities, boosting efficiency and productivity in fields ranging from customer service to healthcare and education. However, their widespread use presents challenges. Concerns about data privacy, biases in generated content, and potential effects on employment patterns raise important questions about the responsible integration of these technologies. In Industry 4.0, ChatGPT and similar AI systems have enabled automation and streamlined data analysis, optimizing manufacturing processes and supply chain management. As Industry 5.0 combines human intuition with advanced technologies, these AI models facilitate collaborative, adaptive, and empathetic human - machine interactions, creating safer workplaces and enhancing overall productivity. Furthermore, within the context of Society 5.0, these AI tools are crucial in addressing societal issues like healthcare accessibility and educational disparities, providing tailored and accessible solutions to diverse communities. This research examines the evolving role of ChatGPT and comparable generative AI in the realms of Industry 4.0, Industry 5.0, and Society 5.0. It explores the challenges associated with their implementation, underscoring the necessity for ethical frameworks and regulatory policies. Simultaneously, it underscores the vast opportunities these technologies present, from stimulating innovation to promoting inclusivity, shaping a future where AI enhances human abilities and cultivates a harmonious coexistence between humans and intelligent machines."
  },
  "Law": {
    "Large language models in law: A survey": "The advent of artificial intelligence (AI) has significantly impacted the traditional judicial industry. Moreover, recently, with the development of AI-generated content (AIGC), AI and law have found applications in various domains, including image recognition, automatic text generation, and interactive chat. With the rapid emergence and growing popularity of large models, it is evident that AI will drive transformation in the traditional judicial industry. However, the application of legal large language models (LLMs) is still in its nascent stage. Several challenges need to be addressed. In this paper, we aim to provide a comprehensive survey of legal LLMs. We not only conduct an extensive survey of LLMs but also expose their applications in the judicial system. We first provide an overview of AI technologies in the legal field and showcase the recent research in LLMs. Then, we discuss the practical implementations presented by legal LLMs, such as providing legal advice to users and assisting judges during trials. In addition, we explore the limitations of legal LLMs, including data, algorithms, and judicial practice. Finally, we summarize practical recommendations and propose future development directions to address these challenges.",
    "Large language models and their possible uses in law": "The paper explores the potential applications of Large Language Models (LLMs) like ChatGPT in the legal field, focusing on how they can enhance access to law. We begin by elucidating the fundamental workings of LLMs and their current and future general applications. The core of our study predicts the utilization of LLMs in various legal domains, especially where tasks like text retrieval, generation, labeling, and classification are prevalent. We argue that tools like ChatGPT could play a pivotal role in these areas. Additionally, we discuss the limitations and customization requirements of LLMs, particularly for legal uses. An experiment conducted by one of the authors, involving a tailored version of GPT for small law firms, serves as a practical example, but building on this, the paper also proposes ways in which LLM - based applications could democratize access to justice, making legal assistance more accessible and efficient for the broader public. This study contributes to the understanding of the intersection between AI technology and legal services, highlighting both the opportunities and challenges in this field.",
    "Legal Evalutions and Challenges of Large Language Models": "In this paper, we review legal testing methods based on Large Language Models (LLMs), using the OPENAI o1 model as a case study to evaluate the performance of large models in applying legal provisions. We compare current state - of - the - art LLMs, including open - source, closed - source, and legal - specific models trained specifically for the legal domain. Systematic tests are conducted on English and Chinese legal cases, and the results are analyzed in depth. Through systematic testing of legal cases from common law systems and China, this paper explores the strengths and weaknesses of LLMs in understanding and applying legal texts, reasoning through legal issues, and predicting judgments. The experimental results highlight both the potential and limitations of LLMs in legal applications, particularly in terms of challenges related to the interpretation of legal language and the accuracy of legal reasoning. Finally, the paper provides a comprehensive analysis of the advantages and disadvantages of various types of models, offering valuable insights and references for the future application of AI in the legal field.",
    "ChatGPT, Large Language Models, and Law": "This Essay explores Artificial Intelligence (AI) Large Language Models (LLMs) like ChatGPT/GPT-4, detailing the advances and challenges in applying AI to law.  It first explains how these AI technologies work at an understandable level.  It then examines the significant evolution of LLMs since 2022 and their improved capabilities in understanding and generating complex documents, such as legal texts.  Finally, this Essay discusses the limitations of these technologies, offering a balanced view of their potential role in legal work.",
    "Large Legal Fictions: Profiling Legal Hallucinations in Large Language Models": "Do large language models (LLMs) know the law? LLMs are increasingly being used to augment legal practice, education, and research, yet their revolutionary potential is threatened by the presence of \u201challucinations\u201d\u2014textual output that is not consistent with legal facts. We present the first systematic evidence of these hallucinations in public-facing LLMs, documenting trends across jurisdictions, courts, time periods, and cases. Using OpenAI\u2019s ChatGPT 4 and other public models, we show that LLMs hallucinate at least 58% of the time, struggle to predict their own hallucinations, and often un-critically accept users\u2019 incorrect legal assumptions. We conclude by cautioning against the rapid and unsupervised integration of popular LLMs into legal tasks, and we develop a typology of legal hallucinations to guide future research in this area.",
    "Can large language models apply the law?": "This paper asks whether large language models (LLMs) can apply the law. It does not question whether LLMs should apply the law. Instead, it distinguishes between two interpretations of the \u2018can\u2019 question. One, can LLMs apply the law like ordinary individuals? Two, can LLMs apply the law in the same manner as judges? The study examines D\u2019 Almeida\u2019s theory of law application, divided into inferential and pragmatic law application. It argues that his account of pragmatic law application can be improved as it does not fully consider that law application (and rule-following) is a shared, public practice collectively realized by members of a linguistic community. The study concludes that LLMs cannot apply the law. They cannot apply the law in the inferential sense as they have mere syntactic (not semantic) interaction with the law. They cannot apply the law in the pragmatic sense as pragmatic law application does not depend on a single agent, whether that agent is a judge, an ordinary citizen, or a non-human entity."
  },
  "Media": {
    "Investigating Bias in LLM-Based Bias Detection: Disparities between LLMs and Human Perception": "The pervasive spread of misinformation and disinformation in social media underscores the critical importance of detecting media bias. While robust Large Language Models (LLMs) have emerged as foundational tools for bias prediction, concerns about inherent biases within these models persist. In this work, we investigate the presence and nature of bias within LLMs and its consequential impact on media bias detection. Departing from conventional approaches that focus solely on bias detection in media content, we delve into biases within the LLM systems themselves. Through meticulous examination, we probe whether LLMs exhibit biases, particularly in political bias prediction and text continuation tasks. Additionally, we explore bias across diverse topics, aiming to uncover nuanced variations in bias expression within the LLM framework. Importantly, we propose debiasing strategies, including prompt engineering and model fine - tuning. Extensive analysis of bias tendencies across different LLMs sheds light on the broader landscape of bias propagation in language models. This study advances our understanding of LLM bias, offering critical insights into its implications for bias detection tasks and paving the way for more robust and equitable AI systems.",
    "MentaLLaMA: Interpretable Mental Health Analysis on Social Media with Large Language Models": "As an integral part of people\u2019s daily lives, social media is becoming a rich source for automatic mental health analysis. As traditional discriminative methods bear poor generalization ability and low interpretability, the recent large language models (LLMs) have been explored for interpretable mental health analysis on social media, which aims to provide detailed explanations along with predictions in zero-shot or few-shot settings. The results show that LLMs still achieve unsatisfactory classification performance in a zero-shot/few-shot manner, which further significantly affects the quality of the generated explanations. Domain-specific finetuning is an effective solution, but faces two critical challenges: 1) lack of high-quality training data. 2) no open-source foundation LLMs. To alleviate these problems, we formally model interpretable mental health analysis as a text generation task, and build the first multi-task and multi-source interpretable mental health instruction (IMHI) dataset with 105K data samples to support LLM instruction tuning and evaluation. The raw social media data are collected from 10 existing sources covering 8 mental health analysis tasks. We prompt ChatGPT with expert-designed few-shot prompts to obtain explanations. To ensure the reliability of the explanations, we perform strict automatic and human evaluations on the correctness, consistency, and quality of generated data. Based on the IMHI dataset and LLaMA2 foundation models, we train MentaLLaMA, the first open-source instruction-following LLM series for interpretable mental health analysis on social media. We evaluate MentaLLaMA and other advanced methods on the IMHI benchmark, the first holistic evaluation benchmark for interpretable mental health analysis. The results show that MentaLLaMA approaches state-of-the-art discrimi",
    "Simulating Social Media Using Large Language Models to Evaluate Alternative News Feed Algorithms": "Social media is often criticized for amplifying toxic discourse and discouraging constructive conversations. But designing social media platforms to promote better conversations is inherently challenging. This paper asks whether simulating social media through a combination of Large Language Models (LLM) and Agent-Based Modeling can help researchers study how different news feed algorithms shape the quality of online conversations. We create realistic personas using data from the American National Election Study to populate simulated social media platforms. Next, we prompt the agents to read and share news articles \u2014 and like or comment upon each other\u2019s messages \u2014 within three platforms that use different news feed algorithms. In the first platform, users see the most liked and commented posts from users whom they follow. In the second, they see posts from all users \u2014 even those outside their own network. The third platform employs a novel \u201cbridging\u201d algorithm that highlights posts that are liked by people with opposing political views. We find this bridging algorithm promotes more constructive, non-toxic, conversation across political divides than the other two models. Though further research is needed to evaluate these findings, we argue that LLMs hold considerable potential to improve simulation research on social media and many other complex social settings.",
    "\u201cI\u2019m Not Sure, But...\u201d: Examining the Impact of Large Language Models\u2019 Uncertainty Expression on User Reliance and Trust": "Widely deployed large language models (LLMs) can produce convincing yet incorrect outputs, potentially misleading users who may rely on them as if they were correct. To reduce such overreliance, there have been calls for LLMs to communicate their uncertainty to end users. However, there has been little empirical work examining how users perceive and act upon LLMs\u2019 expressions of uncertainty. We explore this question through a large-scale, pre-registered, human-subject experiment (N=404) in which participants answer medical questions with or without access to responses from a fictional LLM-infused search engine. Using both behavioral and self-reported measures, we examine how different natural language expressions of uncertainty impact participants\u2019 reliance, trust, and overall task performance. We find that first-person expressions (e.g., \u201c I\u2019m not sure, but... \u201d) decrease participants\u2019 confidence in the system and tendency to agree with the system\u2019s answers, while increasing participants\u2019 accuracy. An exploratory analysis suggests that this increase can be attributed to reduced (but not fully eliminated) overreliance on incorrect answers. While we observe similar effects for uncertainty expressed from a general perspective (e.g., \u201c It\u2019s not clear, but... \u201d), these effects are weaker and not statistically significant. Our findings suggest that using natural language expressions of uncertainty may be an effective approach for reducing overreliance on LLMs, but that the precise language used matters. This highlights the importance of user testing before deploying LLMs at scale.",
    "Challenges and Innovations in LLM-Powered Fake News Detection: A Synthesis of Approaches and Future Directions": "The pervasiveness of the dissemination of fake news through social media platforms poses critical risks to the trust of the general public, societal stability, and democratic institutions. This challenge calls for novel methodologies in detection, which can keep pace with the dynamic and multi-modal nature of misinformation. Recent works include powering the detection using large language model advances in multimodal frameworks, methodologies using graphs, and adversarial training in the literature of fake news. Based on the different approaches which can bring success, some key highlights will be underlined: enhanced LLM-improves accuracy through more advanced semantics and cross-modality fusion for robust detections. The review further identifies critical gaps in adaptability to dynamic social media trends, real-time, and cross-platform detection capabilities, as well as the ethical challenges thrown up by the misuse of LLMs. Future directions underline the development of style-agnostic models, cross-lingual detection frameworks, and robust policies with a view to mitigating LLM-driven misinformation. This synthesis thus lays a concrete foundation for those researchers and practitioners committed to reinforcing fake news detection systems with complications that keep on growing in the digital landscape.",
    "The Impact of Large Language Models on Social Media Communication": "This article explores the impact of large language models (LLMs) on social media communication, with a focus on the spread of misinformation and cyberbullying. As social media becomes an integral part of modern life, challenges such as the rapid spread of misinformation and unethical online behavior continue to escalate. In this paper, the lab\u2019s main research delves into how large language models can improve the accuracy of information dissemination on platforms such as Twitter with their advanced capabilities and larger parameters. It also highlights the application of LLMs in identifying and filtering misinformation, as well as potential ethical and privacy considerations associated with their use. The studies mentioned here also explore the impact of LLMs in shaping social media communications, addressing technological advancements, and attendant social responsibilities.",
    "Large language models can infer psychological dispositions of social media users": "Large language models (LLMs) demonstrate increasingly human-like abilities across a wide variety of tasks. In this paper, we investigate whether LLMs like ChatGPT can accurately infer the psychological dispositions of social media users and whether their ability to do so varies across socio-demographic groups. Specifically, we test whether GPT-3.5 and GPT-4 can derive the Big Five personality traits from users\u2019 Facebook status updates in a zero-shot learning scenario. Our results show an average correlation of r=0B29 (range =[0B22, 0B33]) between LLM-inferred and self-reported trait scores \u2014a level of accuracy that is similar to that of supervised machine learning models specifically trained to infer personality. Our findings also highlight heterogeneity in the accuracy of personality inferences across different age groups and gender categories: predictions were found to be more accurate for women and younger individuals on several traits, suggesting a potential bias stemming from the underlying training data or differences in online self-expression. The ability of LLMs to infer psychological dispositions from user-generated text has the potential to democratize access to cheap and scalable psychometric assessments for both researchers and practitioners. On the one hand, this democratization might facilitate large-scale research of high ecological validity and spark innovation in personalized services. On the other hand, it also raises ethical concerns regarding user privacy and self-determination, highlighting the need for stringent ethical frameworks and regulation.",
    "Large Language Models Outperform Expert Coders and Supervised Classifiers at Annotating Political Social Media Messages": "Instruction-tuned Large Language Models (LLMs) have recently emerged as a powerful new tool for text analysis. As these models are capable of zero-shot annotation based on instructions written in natural language, they obviate the need of large sets of training data \u2014and thus bring potential paradigm-shifting implications for using text as data. While the models show substantial promise, their relative performance compared to human coders and supervised models remains poorly understood and subject to significant academic debate. This paper assesses the strengths and weaknesses of popular fine-tuned AI models compared to both conventional supervised classifiers and manual annotation by experts and crowd workers. The task used is to identify the political affiliation of politicians based on a single X/Twitter message, focusing on data from 11 different countries. The paper finds that GPT-4 achieves higher accuracy than both supervised models and human coders across all languages and country contexts. In the US context, it achieves an accuracy of 0.934 and an inter-coder reliability of 0.982. Examining the cases where the models fail, the paper finds that the LLM \u2014unlike the supervised models \u2014correctly annotates messages that require interpretation of implicit or unspoken references, or reasoning on the basis of contextual knowledge \u2014capacities that have traditionally been understood to be distinctly human. The paper thus contributes to our understanding of the revolutionary implications of LLMs for text analysis within the social sciences."
  },
  "Medicine": {
    "Disparities in Dermatology AI Performance on a Diverse, Curated Clinical Image Set": "Access to dermatological care is a major issue, with an estimated 3 billion people lacking access to care globally. Artificial intelligence (AI) may aid in triaging skin diseases. However, most AI models have not been rigorously assessed on images of diverse skin tones or uncommon diseases. To ascertain potential biases in algorithm performance in this context, we curated the Diverse Dermatology Images (DDI) dataset\u2014the first publicly available, expertly curated, and pathologically confirmed image dataset with diverse skin tones. Using this dataset of 656 images, we show that state - of - the - art dermatology AI models perform substantially worse on DDI, with receiver operator curve area under the curve (ROC - AUC) dropping by 27 - 36% percent compared to the models\u2019 original test results. All the models performed worse on dark skin tones and uncommon diseases, which are represented in the DDI dataset. Additionally, we find that dermatologists, who typically provide visual labels for AI training and test datasets, also perform worse on images of dark skin tones and uncommon diseas",
    "Large language models in medicine: the potentials and pitfalls": "Large language models (LLMs) have been applied to tasks in healthcare, ranging from medical exam questions to responding to patient questions. With increasing institutional partnerships between companies producing LLMs and healthcare systems, real world clinical application is coming closer to reality. As these models gain traction, it is essential for healthcare practitioners to understand what LLMs are, their development, their current and potential applications, and the associated pitfalls when utilized in medicine. This review and accompanying tutorial aim to give an overview of these topics to aid healthcare practitioners in understanding the rapidly changing landscape of LLMs as applied to medicine.",
    "SYSTEMATIC REVIEW": "Background  Large language models are increasingly evaluated for use in healthcare. However, concerns about their impact on disparities persist. This study reviews current research on demographic biases in large language models to identify prevalent bias types, assess measurement methods, and evaluate mitigation strategies. Methods  We conducted a systematic review, searching publications from January 2018 to July 2024 across five databases. We included peer-reviewed studies evaluating demographic biases in large language models, focusing on gender, race, ethnicity, age, and other factors. Study quality was assessed using the Joanna Briggs Institute Critical Appraisal Tools. Results  Our review included 24 studies. Of these, 22 (91.7%) identified biases. Gender bias was the most prevalent, reported in 15 of 16 studies (93.7%). Racial or ethnic biases were observed in 10 of 11 studies (90.9%). Only two studies found minimal or no bias in certain contexts. Mitigation strategies mainly included prompt engineering, with varying effectiveness. However, these findings are tempered by a potential publication bias, as studies with negative results are",
    "Large language models in health care: Development, applications, and challenges": "Recently, the emergence of ChatGPT, an artificial intelligence chatbot developed by OpenAI, has attracted significant attention due to its exceptional language comprehension and content generation capabilities, highlighting the immense potential of large language models (LLMs). LLMs have become a burgeoning hotspot across many fields, including health care. Within health care, LLMs may be classified into LLMs for the biomedical domain and LLMs for the clinical domain based on the corpora used for pre - training. In the last 3 years, these domain - specific LLMs have demonstrated exceptional performance on multiple natural language processing tasks, surpassing the performance of general LLMs as well. This not only emphasizes the significance of developing dedicated LLMs for the specific domains, but also raises expectations for their applications in health care. We believe that LLMs may be used widely in preconsultation, diagnosis, and management, with appropriate development and supervision. Additionally, LLMs hold tremendous promise in assisting with medical education, medical writing and other related applications. Likewise, health care systems must recognize and address the challenges posed by LLMs.",
    "Large Language Models in Healthcare and Medical Domain: A Review": "The deployment of large language models (LLMs) within the healthcare sector has sparked both enthusiasm and apprehension. These models exhibit the remarkable ability to provide proficient responses to free - text queries, demonstrating a nuanced understanding of professional medical knowledge. This comprehensive survey delves into the functionalities of existing LLMs designed for healthcare applications and elucidates the trajectory of their development, starting with traditional Pretrained Language Models (PLMs) and then moving to the present state of LLMs in the healthcare sector. First, we explore the potential of LLMs to amplify the efficiency and effectiveness of diverse healthcare applications, particularly focusing on clinical language understanding tasks. These tasks encompass a wide spectrum, ranging from named entity recognition and relation extraction to natural language inference, multimodal medical applications, document classification, and question - answering. Additionally, we conduct an extensive comparison of the most recent state - of - the - art LLMs in the healthcare domain, while also assessing the utilization of various open - source LLMs and highlighting their significance in healthcare applications. Furthermore, we present the essential performance metrics employed to evaluate LLMs in the biomedical domain, shedding light on their effectiveness and limitations. Finally, we summarize the prominent challenges and constraints faced by large language models in the healthcare sector by offering a holistic perspec",
    "Large language models in medicine": "Large language models (LLMs) can respond to free-text queries without being specifically trained in the task in question, causing excitement and concern about their use in healthcare settings. ChatGPT is a generative artificial intelligence (AI) chatbot produced through sophisticated fine-tuning of an LLM, and other tools are emerging through similar developmental processes. Here we outline how LLM applications such as ChatGPT are developed, and we discuss how they are being leveraged in clinical settings. We consider the strengths and limitations of LLMs and their potential to improve the efficiency and effectiveness of clinical, educational and research work in medicine. LLM chatbots have already been deployed in a range of biomedical contexts, with impressive but mixed results. This review acts as a primer for interested clinicians, who will determine if  and how LLM technology is used in healthcare for the benefit of patients  and practitioners.",
    "Bias recognition and mitigation strategies in arti \ufb01cial intelligence healthcare applications": "Arti\ufb01cial intelligence (AI) is delivering value across all aspects of clinical practice. However, bias may exacerbate healthcare disparities. This review examines the origins of bias in healthcare AI, strategies for mitigation, and responsibilities of relevant stakeholders towards achieving fair and equitable use. We highlight the importance of systematically identifying bias and engaging relevant mitigation activities throughout the AI model lifecycle, from model conception through to deployment and longitudinal surveillance.",
    "Explainable AI (XAI) in healthcare: Enhancing trust and transparency in critical decision-making": "The integration of artificial intelligence (AI) in healthcare is revolutionizing diagnostic and treatment procedures, offering unprecedented accuracy and efficiency. However, the opacity of many advanced AI models, often described as \"black boxes,\" creates challenges in adoption due to concerns around trust, transparency, and interpretability, particularly in high-stakes environments like healthcare. Explainable AI (XAI) addresses these concerns by providing a framework that not only achieves high performance but also offers insight into how decisions are made. This research explores the application of XAI techniques in healthcare, focusing on critical areas such as disease diagnostics, predictive analytics, and personalized treatment recommendations. The study will analyse various XAI methods, including model-agnostic approaches (LIME, SHAP), interpretable deep learning models, and domain-specific applications of XAI. It also evaluates the ethical implications, such as accountability and bias mitigation, and how XAI can foster collaboration between clinicians and AI systems. Ultimately, the goal is to create AI systems that are both powerful and trustworthy, promoting broader adoption in the healthcare sector while ensuring ethical and safe outcomes for patients."
  },
  "Programming": {
    "Program Synthesis with Large Language Models": "This paper explores the limits of the current generation of large language models for program synthesis in general purpose programming languages. We evaluate a collection of such models (with between 244M and 137B parameters) on two new benchmarks, MBPP and MathQA-Python, in both the few-shot and \ufb01ne-tuning regimes. Our benchmarks are designed to measure the ability of these models to synthesize short Python programs from natural language descriptions. The Mostly Basic Programming Problems (MBPP) dataset contains 974programming tasks, designed to be solvable by entry-level programmers. The MathQA-Python dataset, a Python version of the MathQA benchmark, contains 23914 problems that evaluate the ability of the models to synthesize code from more complex text. On both datasets, we \ufb01nd that synthesis performance scales log-linearly with model size. Our largest models, even without \ufb01netuning on a code dataset, can synthesize solutions to 59.6% of the problems from MBPP using few-shot learning with a well-designed prompt. Fine-tuning on a held-out portion of the dataset improves performance by about 10 percentage points across most model sizes. On the MathQA-Python dataset, the largest \ufb01ne-tuned model achieves 83.8% accuracy. Going further, we study the model\u2019s ability to engage in dialog about code, incorporating human feedback to improve its solutions. We \ufb01nd that natural language feedback from a human halves the error rate compared to the model\u2019s initial prediction. Additionally, we conduct an error analysis to shed light on where these models fall short and what types of programs are most dif\ufb01cult to generate. Finally, we explore the semantic grounding of these models by \ufb01ne-tuning them to predict the results of program execution. We \ufb01nd that even our best models are generally unable to predict the output of a program given a speci\ufb01c input.",
    "A SYSTEMATIC EVALUATION OF LARGE LANGUAGE MODELS OF CODE": "Large language models (LMs) of code have recently shown tremendous promise in completing code and synthesizing code from natural language descriptions. However, the current state-of-the-art code LMs (e.g., Codex (Chen et al., 2021)) are not publicly available, leaving many questions about their model and data design decisions. We aim to \ufb01ll in some of these blanks through a systematic evaluation of the largest existing models: Codex, GPT - J, GPT - Neo, GPT - NeoX - 20B, and CodeParrot, across various programming languages. Although Codex itself is not open - source, we \ufb01nd that existing open - source models do achieve close results in some programming languages, although targeted mainly for natural language modeling. We further identify an important missing piece in the form of a large open - source model trained exclusively on a multi - lingual corpus of code. We release a new model, PolyCoder, with 2.7B parameters based on the GPT - 2 architecture, that was trained on 249GB of code across 12 programming languages on a single machine. In the C programming language, PolyCoder outperforms all models including Codex . Our trained models are open - source and publicly available at https://github.com/VHellendoorn/Code - LMs , which enables future research and application in this area.",
    "Fully Autonomous Programming with Large Language Models": "Current approaches to program synthesis with Large Language Models (LLMs) exhibit a \u201cnear miss syndrome\u201d: they tend to generate programs that semantically resemble the correct answer (as measured by text similarity metrics or human evaluation), but achieve a low or even zero accuracy as measured by unit tests due to small imperfections, such as the wrong input or output format. This calls for an approach known as Synthesize, Execute, Debug (SED), whereby a draft of the solution is generated first, followed by a program repair phase addressing the failed tests. To effectively apply this approach to instruction-driven LLMs, one needs to determine which prompts perform best as instructions for LLMs, as well as strike a balance between repairing unsuccessful programs and replacing them with newly generated ones. We explore these trade - offs empirically, comparing replace - focused, repair - focused, and hybrid debug strategies, as well as different template - based and model - based prompt - generation techniques. We use OpenAI Codex as the LLM and Program Synthesis Benchmark 2 as a database of problem descriptions and tests for evaluation. The resulting framework outperforms both conventional usage of Codex without the repair phase and traditional genetic programming approaches.",
    "Can Large Language Models Transform Computational Social Science?": "Large Language Models (LLMs) are capable of successfully performing many language processing tasks zero-shot (without training data). If zero-shot LLMs can also reliably classify and explain social phenomena like persuasiveness and political ideology, then LLMs could augment the Computational Social Science (CSS) pipeline in important ways. This work provides a road map for using LLMs as CSS tools. Towards this end, we contribute a set of prompting best practices and an extensive evaluation pipeline to measure the zero-shot performance of 13 language models on 25 representative English CSS benchmarks. On taxonomic labeling tasks (classification), LLMs fail to outperform the best fine-tuned models but still achieve fair levels of agreement with humans. On free-form coding tasks (generation), LLMs produce explanations that often exceed the quality of crowdworkers\u2019 gold references. We conclude that the performance of today\u2019s LLMs can augment the CSS research pipeline in two ways: (1) serving as zero-shot data annotators on human annotation teams, and (2) bootstrapping challenging creative generation tasks (e.g., explaining the underlying attributes of a text). In summary, LLMs are posed to meaningfully participate in social science analysis in partnership with humans.",
    "The Larger They Are, the Harder They Fail: Language Models do not Recognize Identifier Swaps in Python": "Large Language Models (LLMs) have successfully been applied to code generation tasks, raising the question of how well these models understand programming. Typical programming languages have invariances and equivariances in their semantics that human programmers intuitively understand and exploit, such as the (near) invariance to the renaming of identifiers. We show that LLMs not only fail to properly generate correct Python code when default function names are swapped, but some of them even become more confident in their incorrect predictions as the model size increases, an instance of the recently discovered phenomenon of Inverse Scaling, which runs contrary to the commonly observed trend of increasing prediction quality with increasing model size. Our findings indicate that, despite their astonishing typical - case performance, LLMs still lack a deep, abstract understanding of the content they manipulate, making them unsuitable for tasks that statistically deviate from their training data, and that mere scaling is not enough to achieve such capability.",
    "Performance of Large Language Models in a Computer Science Degree Program": "Large language models such as ChatGPT-3.5 and GPT-4.0 are ubiquitous and dominate the current discourse. Their transformative capabilities have led to a paradigm shift in how we interact with and utilize (text-based) information. Each day, new possibilities to leverage the capabilities of these models emerge. This paper presents findings on the performance of different large language models in a university of applied sciences\u2019 undergraduate computer science degree program. Our primary objective is to assess the effectiveness of these models within the curriculum by employing them as educational aids. By prompting the models with lecture material, exercise tasks, and past exams, we aim to evaluate their proficiency across different computer science domains. We showcase the strong performance of current large language models while highlighting limitations and constraints within the context of such a degree program. We found that ChatGPT-3.5 averaged 79.9% of the total score in 10 tested modules, BingAI achieved 68.4%, and LLaMa, in the 65 billion parameter variant, 20%. Despite these convincing results, even GPT-4.0 would not pass the degree program - due to limitations in mathematical calculations.",
    "Large Language Models in Computer Science Education: A Systematic Literature Review": "Large language models (LLMs) are becoming increasingly better at a wide range of Natural Language Processing tasks (NLP), such as text generation and understanding. Recently, these models have extended their capabilities to coding tasks, bridging the gap between natural languages (NL) and programming languages (PL). Foundational models such as the Generative Pre-trained Transformer (GPT) andLLaMA series have set strong baseline performances in various NL and PL tasks. Additionally, several models have been fine-tuned specifically for code generation, showing significant improvements in code-related applications. Both foundational and fine-tuned models are increasingly used in education, helping students write, debug, and understand code. We present a comprehensive systematic literature review to examine the impact of LLMs in computer science and computer engineering education. We analyze their effectiveness in enhancing the learning experience, supporting personalized education, and aiding educators in curriculum development. We address five research questions to uncover insights into how LLMs contribute to educational outcomes, identify challenges, and suggest directions for future research.",
    "Using Large Language Models to Enhance Programming Error Messages": "A key part of learning to program is learning to understand programming error messages. They can be hard to interpret and identifying the cause of errors can be time-consuming. One factor in this challenge is that the messages are typically intended for an audience that already knows how to program, or even for programming environments that then use the information to highlight areas in code. Researchers have been working on making these errors more novice friendly since the 1960s, however progress has been slow. The present work contributes to this stream of research by using large language models to enhance programming error messages with explanations of the errors and suggestions on how to fix them. Large language models can be used to create useful and novice-friendly enhancements to programming error messages that sometimes surpass the original programming error messages in interpretability and actionability. These results provide further evidence of the benefits of large language models for computing educators, highlighting their use in areas known to be challenging for students. We further discuss the benefits and downsides of large language models and highlight future streams of research for enhancing programming error messages.",
    "Automatic Programming: Large Language Models and Beyond": "Automatic programming has seen increasing popularity due to the emergence of tools like GitHub Copilot which rely on Large Language Models (LLMs). At the same time, automatically generated code faces challenges during deployment due to concerns around quality and trust. In this article, we study automated coding in a general sense and study the concerns around code quality, security, and related issues of programmer responsibility. These are key issues for organizations while deciding on the usage of automatically generated code. We discuss how advances in software engineering such as program repair and analysis can enable automatic programming. We conclude with a forward looking view, focusing on the programming environment of the near future, where programmers may need to switch to different roles to fully utilize the power of automatic programming. Automated repair of automatically generated programs from LLMs can help produce higher assurance code from LLMs, along with evidence of assurance.",
    "The impact of LLM chatbots on learning outcomes in advanced driver assistance systems education": "Our study investigates the efficacy of ChatGPT-assisted learning in enhancing the understanding of Advanced Driver Assistance Systems (ADAS) functionalities, comparing it against conventional paper-based learning methods. By employing multiple-choice questionnaires and the NASA Task Load Index to evaluate comprehension and cognitive load, we aimed to assess the impact of interactive Large Language Model (LLM)-driven learning on knowledge acquisition and learner satisfaction. Our findings indicate that participants who engaged with ChatGPT-based training scored higher (on average 11% higher) in correctness and experienced lower cognitive and physical demands, suggesting a more effective and less stressful learning process. This study contributes by highlighting ChatGPT\u2019s potential to accommodate a wide range of learning preferences and improve the comprehension of complex systems or topics. This adaptability was evident across diverse educational backgrounds among young adult participants, showcasing the tool\u2019s ability to bridge knowledge gaps more efficiently than conventional methods. Our research advocates the integration of LLM-driven tools in educational and policy-making frameworks to improve the effectiveness of teaching complex systems. This suggests broader applicability and necessitates further investigation into the scalability and effectiveness of ChatGPT-based training across different demographics and learning domains, potentially informing future educational strategies."
  },
  "Research": {
    "Summary of ChatGPT-Related research and perspective towards the future of large language models": "This paper presents a comprehensive survey of ChatGPT-related (GPT-3.5 and GPT-4) research, state-of-the-art large language models (LLM) from the GPT series, and their prospective applications across diverse domains. Indeed, key innovations such as large-scale pre-training that captures knowledge across the entire world wide web, instruction \ufb01ne-tuning and Reinforcement Learning from Human Feedback (RLHF) have played signi\ufb01cant roles in enhancing LLMs' adaptability and performance. We performed an in-depth analysis of 194 relevant papers on arXiv, encompassing trend analysis, word cloud representation, and distribution analysis across various application domains. The \ufb01ndings reveal a signi\ufb01cant and increasing interest in ChatGPT-related research, predominantly centered on direct natural language processing applications, while also demonstrating considerable potential in areas ranging from education and history to mathematics, medicine, and physics. This study endeavors to furnish insights into ChatGPT's capabilities, potential implications, ethical concerns, and offer direction for future advancements in this \ufb01eld.",
    "Utilizing Large Language Models to Boost Innovative Research and Development in Enterprises": "With the advancement of large language models like ChatGPT, harnessing these technologies for fostering innovation and research & development (R&D) has emerged as an important exploratory practice for enterprises. This paper offers an in -depth analysis of the extensive applications of large language models within the sphere of corporate innovation and R&D, highlighting their remarkable capabilities in facilitating knowledge acquisition, enhancing emotional comprehension, generating creative ideas, and boosting the efficiency of R&D teams. Additionally, the paper discusses certain limitations associated with large language models, including challenges in assessing the reliability of generated content and a deficiency in domain -specific knowledge. Building on these insights, we advocate for enterprises to adopt a hybrid approach, integrating human expertise with large language models to maximize the collaborative benefits. Through comprehensive analysis and discussion, this paper aims to provide substantial guidance and reference for effectively applying large language models in innovative R&D, which makes it a valuable experience for enterprises exploring this cutting -edge domain.",
    "Siren\u2019s Song in the AI Ocean: A Survey on Hallucination in Large Language Models": "While large language models (LLMs) have demonstrated remarkable capabilities across a range of downstream tasks, a significant concern revolves around their propensity to exhibithallucinations: LLMs occasionally generate content that diverges from the user input, contradicts previously generated con- text, or misaligns with established world knowledge. This phenomenon poses a substantial challenge to the reliability of LLMs in real-world scenarios. In this paper, we survey recent efforts on the detection, ex- planation, and mitigation of hallucination, with an emphasis on the unique challenges posed by LLMs. We present taxonomies of the LLM hallucination phenomena and evaluation benchmarks, analyze existing ap- proaches aiming at mitigating LLM halluci- nation, and discuss potential directions for future research.",
    "Moderating Illicit Online Image Promotion for Unsafe User-Generated Content Games Using Large Vision-Language Models": "Online user-generated content games (UGCGs) are increasingly popular among children and adolescents for social interaction and more creative online entertainment. However, they pose a heightened risk of exposure to explicit content, raising growing concerns for the online safety of children and adolescents. Despite these concerns, few studies have addressed the issue of illicit image-based promotions of unsafe UGCGs on social media, which can inadvertently attract young users. This challenge arises from the difficulty of obtaining comprehensive training data for UGCG images and the unique nature of these images, which differ from traditional unsafe content. In this work, we take the first step towards studying the threat of illicit promotions of unsafe UGCGs. We collect a real-world dataset comprising 2,924 images that display diverse sexually explicit and violent content used to promote UGCGs by their game creators. Our in-depth studies reveal a new understanding of this problem and the urgent need for automatically flagging illicit UGCG promotions. We additionally create a cutting-edge system, UGCG-GUARD, designed to aid social media platforms in effectively identifying images used for illicit UGCG promotions. This system leverages recently introduced large vision-language models (VLMs) and employs a novel conditional prompting strategy for zero-shot domain adaptation, along with chain-of-thought (CoT) reasoning for contextual identification. UGCG-GUARD achieves outstanding results, with an accuracy rate of 94% in detecting these images used for the illicit promotion of such games in real-world scenarios.",
    "A Comprehensive Survey of Scientific Large Language Models and Their Applications in Scientific Discovery": "In many scientific fields, large language models (LLMs) have revolutionized the way text and other modalities of data ( e.g., molecules and proteins) are handled, achieving superior performance in various applications and augmenting the scientific discovery process. Nevertheless, previous surveys on scientific LLMs often concentrate on one or two fields or a single modality. In this paper, we aim to provide a more holistic view of the research landscape by unveiling cross-field and cross-modal connections between scientific LLMs regarding their architectures and pre-training techniques. To this end, we comprehensively survey over 260 scientific LLMs, discuss their commonalities and differences, as well as summarize pre-training datasets and evaluation tasks for each field and modality. Moreover, we investigate how LLMs have been deployed to benefit scientific discovery. Resources related to this survey are available at https://github.com/yuzhimanhua/Awesome-Scientific-Language-Models .",
    "LARGE LANGUAGE MODEL INFERENCE ACCELERATION : A COMPREHENSIVE HARDWARE PERSPECTIVE": "Large Language Models (LLMs) have demonstrated remarkable capabilities across various fields, from natural language understanding to text generation. Compared to non-generative LLMs like BERT and DeBERTa, generative LLMs like GPT series and Llama series are currently the main focus due to their superior algorithmic performance. The advancements in generative LLMs are closely intertwined with the development of hardware capabilities. Various hardware platforms exhibit distinct hardware characteristics, which can help improve LLM inference performance. Therefore, this paper comprehensively surveys efficient generative LLM inference on different hardware platforms. First, we provide an overview of the algorithm architecture of mainstream generative LLMs and delve into the inference process. Then, we summarize different optimization methods for different platforms such as CPU, GPU, FPGA, ASIC, and PIM/NDP, and provide inference results for generative LLMs. Furthermore, we perform a qualitative and quantitative comparison of inference performance with batch sizes 1 and 8 on different hardware platforms by considering hardware power consumption, absolute inference speed ( tokens/s ), and energy efficiency (tokens/J ). We compare the performance of the same optimization methods across different hardware platforms, the performance across different hardware platforms, and the performance of different methods on the same hardware platform. This provides a systematic and comprehensive summary of existing inference acceleration work by integrating software optimization methods and hardware platforms. We point out that the development of edge intelligence has gained significant momentum, driven by the increasing capability of LLMs and the increasing demands of edge applications. And three trends (multimodality, inference-time compute, and higher inference energy"
  },
  "Tourism": {
    "Customized language models for tourism management: Implications and future research": "Sitting at the intersection between social and computer sciences, human-computer interaction research focuses on understanding human behavior in relation to computer systems (Olson & Olson, 2002). Having seen many developments over the years, humancomputer interaction has been a focal point in sector-specific research, including in tourism management (Stankov & Gretzel, 2020; Tung & Law, 2020). Recently, attention has been given to human-artificial intelligence interaction in particular. For instance, Lu et al.'s (2019) Service Robot Integration Willingness Scale and Gursoy et al.'s (2019) Artificially Intelligent (AI) Device Use Acceptance model explore guests' willingness to accept different types of AI in tourism contexts, while Fu et al. (2022) have put forward the Robot Usage Resistance model to explain tourism employees' reasons for resisting the use of robots. Most recently, user interfaces based on large language models have rapidly grown in popularity (Shanahan et al., 2023). Language model based consumer products, such as ChatGPT or Gemini, offer tourism companies new ways of working (Tuomi, 2023). For instance, Expedia recently launched language model based trip-planning tools (Biesiada, 2023), InterContinental Hotels Group is building a similar tool to improve booking experience (IHG, 2024), while Air Canada made headlines when their language model offered tourists discounts that did not exist (Garcia, 2024). Importantly, the potential for so called generative artificial intelligence goes beyond major tourism corporations or tourist-artificial intelligence interaction. New tools facilitate the construction and sharing of Custom Assistants  customized versions of popular large language models  at a click of a few buttons, providing new affordances for tourism businesses and other stakeholders by facilitating new types of human-computer interaction in tourism, including touristartificial intelligence, employee-artificial intelligence, business-artificial intelligence and policymaker-artificial intelligence.",
    "ETHICAL CONSIDERATIONS AND POLICY IMPLICATIONS FOR LARGE LANGUAGE MODELS : GUIDING RESPONSIBLE DEVELOPMENT AND DEPLOYMENT": "This paper examines the ethical considerations and implications of large language models (LLMs) in generating content. It highlights the potential for both positive and negative uses of generative AI programs and explores the challenges in assigning responsibility for their outputs. The discussion emphasizes the need for proactive ethical frameworks and policy measures to guide the responsible development and deployment of LLMs.",
    "TourLLM: Enhancing LLMs with Tourism Knowledge": "Recently, large language models (LLMs) have demonstrated their effectiveness in various natural language processing (NLP) tasks. However, the lack of tourism knowledge limits the performance of LLMs in tourist attraction presentations and travel planning. To address this challenge, we constructed a supervised fine-tuning dataset for the culture and tourism domain, named Cultour. This dataset consists of three parts: tourism knowledge base QA data, travelogues data, and tourism diversity QA data. Additionally, we propose TourLLM, a Qwen-based model supervised fine-tuned with Cultour, to improve the quality of the information provided about attractions and travel planning. To evaluate the performance of TourLLM, we employed both automatic and human evaluation, and we proposed a human evaluation criterion named CRA (Consistency, Readability, Availability). The experimental results demonstrate the effectiveness of the responses generated by the TourLLM. Our proposed Cultour is accessible at https://github.com/mrweiqk/Cultour.",
    "A novel forecasting framework combining virtual samples and enhanced Transformer models for tourism demand forecasting": "Accurate tourism demand forecasting is hindered by limited historical data and complex spatiotemporal dependencies among tourist origins. A novel forecasting framework integrating virtual sample generation and a novel Transformer predictor addresses constraints arising from restricted data availability. A spatiotemporal GAN produces realistic virtual samples by dynamically modeling spatial correlations through a graph convolutional network, and an enhanced Transformer captures local patterns with causal convolutions and long - term dependencies with self - attention, eliminating autoregressive decoding. A joint training strategy refines virtual sample generation based on predictor feedback to maintain robust performance under data - scarce conditions. Experimental evaluations on real - world daily and monthly tourism demand datasets indicate a reduction in average MASE by 18.37% compared to conventional Transformer - based models, demonstrating improved forecasting accuracy. The integration of adaptive spatiotemporal sample augmentation with a specialized Transformer can effectively address limited - data forecasting scenarios in tourism management.",
    "TraveLLaMA: Facilitating Multi-modal Large Language Models to Understand Urban Scenes and Provide Travel Assistance": "Tourism and travel planning increasingly rely on digital assistance, yet existing multimodal AI systems often lack specialized knowledge and contextual understanding of urban environments. We present TraveLLaMA , a specialized multimodal language model designed for urban scene understanding and travel assistance. Our work addresses the fundamental challenge of developing practical AI travel assistants through a novel large-scale dataset of 220k question-answer pairs. This comprehensive dataset uniquely combines 130k text QA pairs meticulously curated from authentic travel forums with GPT-enhanced responses, alongside 90k vision-language QA pairs specifically focused on map understanding and scene comprehension. Through extensive fine-tuning experiments on state-of-the-art vision-language models (LLaVA, Qwen-VL, Shikra), we demonstrate significant performance improvements ranging from 6.5%-9.4% in both pure text travel understanding and visual question answering tasks. Our model exhibits exceptional capabilities in providing contextual travel recommendations, interpreting map locations, and understanding place-specific imagery while offering practical information such as operating hours and visitor reviews. Comparative evaluations show TraveLLaMA significantly outperforms general-purpose models in travel-specific tasks, establishing a new benchmark for multi-modal travel assistance systems.",
    "A Survey on Privacy Risks and Protection in Large Language Models": "Although Large Language Models (LLMs) have become increasingly integral to diverse applications, their capabilities raise significant privacy concerns. This survey offers a comprehensive overview of privacy risks associated with LLMs and examines current solutions to mitigate these challenges. First, we analyze privacy leakage and attacks in LLMs, focusing on how these models unintentionally expose sensitive information through techniques such as model inversion, training data extraction, and membership inference. We investigate the mechanisms of privacy leakage, including the unauthorized extraction of training data and the potential exploitation of these vulnerabilities by malicious actors. Next, we review existing privacy protection against such risks, such as inference detection, federated learning, backdoor mitigation, and confidential computing, and assess their effectiveness in preventing privacy leakage. Furthermore, we highlight key practical challenges and propose future research directions to develop secure and privacy - preserving LLMs, emphasizing privacy risk assessment, secure knowledge transfer between models, and interdisciplinary frameworks for privacy governance. Ultimately, this survey aims to establish a roadmap for addressing escalating privacy challenges in the LLMs domain.",
    "Leveraging LLMs in Tourism: A Comparative Study of the latest GPT Omni models and BERT NLP for Customer Review Classification and Sentiment Analysis": "In today's rapidly evolving digital landscape, customer reviews play a crucial role in shaping the reputation and success of hotels. Accurately analyzing and classifying the sentiment of these reviews offers valuable insights into customer satisfaction, en abling businesses to gain a competitive edge. This study undertakes a comparative analysis between traditional natural language processing (NLP) models, like BERT, and advanced large language models (LLMs), specifically GPT -4 Omni and GPT -4o Mini , both pre - and post - fine-tuning with few -shot learning. By leveraging an extensive dataset of hotel reviews, we evaluate the effectiveness of these models in predicting star ratings based on review content. The findings demonstrate that",
    "The Future of Tourism: Examining the Potential Applications of Large Language Models": "Large language models such as the Generative Pre-trained Transformer (GPT) have recently gained attention for their impressive natural language processing capabilities. While their potential to revolutionize various industries is still being explored, the tourism industry stands to benefit significantly from their use. In this study, we conduct an early assessment of the impact potential of GPTs on the tourism industry using a mixed - methods approach. We first analyze the existing literature on the use of GPTs in the tourism industry and identify several potential applications such as personalized travel recommendations, language translation, and chatbots. We then collect data from various stakeholders in the tourism industry through surveys and interviews to understand their current practices and their willingness to adopt GPT - based solutions. Our results indicate that while there is a high level of awareness and interest in GPTs among tourism professionals, the adoption of these technologies is currently limited. The main barriers identified include a lack of technical expertise, concerns around data privacy and security, and the high cost of implementing GPT - based solutions. However, those who have adopted GPTs report significant benefits in terms of increased efficiency and improved customer satisfaction. To further explore the potential of GPTs in the tourism industry, we conduct a pilot study to develop a GPT - based travel recommendation system. The system uses GPT to generate personalized travel itineraries based on user preferences and feedback. Our evaluation of the system indicates that it performs well in terms of accuracy and user satisfaction, demonstrating the potential for GPTs to provide personalized and tailored experiences to travellers. Overall, our study provides an early look at the impact potential of GPTs on the tourism industry and identifies several avenues for future research. We recommend that tourism professionals and researchers collaborate to address the current barriers to adoption and explore the full range of applications for GPTs in the industry."
  }
}