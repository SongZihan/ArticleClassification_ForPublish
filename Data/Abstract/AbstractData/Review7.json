{
    "Argumentation": {
        "A neural cognitive model of argumentation with application to legal inference and decision making.": "Article history:. Received 17 August 2012 Accepted 29 August 2013 Available online 23 October 2013  \n\nKeywords:   \nArgumentation   \nNeural-symbolic reasoning Legal decision making.   \nCognitive modelling.  \n\nFormal models of argumentation have been investigated in several areas, from multiagent systems and artificial intelligence (AI) to decision making, philosophy and law. In artificial intelligence, logic-based models have been the standard for the representation of argumentative reasoning. More recently, the standard logic-based models have been shown equivalent to standard connectionist models. This has created a new line of research where (i) neural networks can be used as a parallel computational model for argumentation and (ii) neural networks can be used to combine argumentation, quantitative reasoning and statistical learning. At the same time, non-standard logic models of argumentation started to emerge. In this paper, we propose a connectionist cognitive model of argumentation that accounts for both standard and non-standard forms of argumentation. The model is shown to be an adequate framework for dealing with standard and non-standard argumentation, including joint-attacks, argument support, ordered attacks, disjunctive attacks, meta-level attacks, self-defeating attacks, argument accrual and uncertainty. We show that the neural cognitive approach offers an adequate way of modelling all. of these different aspects of argumentation. We have applied the framework to the modelling of a public prosecution charging decision as part of a real legal decision making case study containing many of the above aspects of argumentation. The results show that the model can be a useful tool in the analysis of legal decision making, including the analysis of what-if questions and the analysis of alternative conclusions. The approach opens up two new perspectives in the short-term: the use of neural networks for computing prevailing arguments efficiently through the propagation in parallel of neuronal activations, and the use of the same networks to evolve the structure of the argumentation network through learning (e.g. to learn the strength of arguments from data).  \n\n$\\copyright$ 2013 Elsevier B.V. All rights reserved.",
        "Value-based Argumentation Frameworks as Neural-symbolic Learning Systems": "While neural networks have been successfully used in a number of machine learning applications, logical languages have been the standard for the representation of argumentative reasoning. In this paper, we establish a relationship between neural networks and argumentation networks, combining reasoning and learning in the same argumentation framework. We do so by presenting a new neural argumentation algorithm, responsible for translating argumentation networks into standard neural networks. We then show a correspondence between the two networks. The algorithm works not only for acyclic argumentation networks, but also for circular networks, and it enables the accrual of arguments through learning as well as the parallel computation of arguments.  \n\nKeywords: Neural-symbolic systems, value-based argumentation frameworks, hybrid systems.",
        "Argumentation-Based Multi-Agent Decision Making with Privacy Preserved": "We consider multi-agent decision making problems in which agents need to communicate with other agents to make socially optimal decisions but, at the same time, have some private information that they do not want to share. Abstract argumentation has been widely used in both single-agent and multi-agent decision making problems, because of its ability for reasoning with incomplete and conflicting information. In this work, we propose an abstract argumentation-based. knowledge representation and communication protocol, such that agents can find socially optimal strategies by only disclosing the 'necessary' and 'disclosable' information. We prove that our protocol is sound, efficient, of perfect information security and guaranteed to terminate.",
        "Extracting Dialogical Explanations for Review Aggregations with Argumentative Dialogical Agents": "The aggregation of online reviews is fast becoming the chosen. method of quality control for users in various domains, from retail to entertainment. Consequently, fair, thorough and explain-. able aggregation of reviews is increasingly sought-after. We consider the movie review domain, and in particular Rotten Tomatoes' ubiquitous (and arguably over-simplified) aggregation method, the. Tomatometer Score (TS). For a movie, this amounts to the percentage of critics giving the movie a positive review. We define a novel form of argumentative dialogical agent (ADA) for explaining the reasoning within the reviews. ADA integrates: 1.) NLP with reviews to extract a Quantitative Bipolar Argumentation Framework. (QBAF) for any chosen movie to provide the underlying structure of explanations, and 2.) gradual semantics for QBAFs for deriving. a dialectical strength measure for movies, as an alternative to the TS, satisfying desirable properties for obtaining explanations. We evaluate ADA using some prominent NLP methods and gradual semantics for QBAFs. We show that they provide a dialectical strength which is comparable with the TS, while at the same time being able to provide dialogical explanations of why a movie obtained its strength via interactions between the user and ADA..",
        "Towards Artificial Argumentation": "The field of computational models of argument is emerging as an important aspect of artificial intelligence research. The reason for this is based on the recognition that if we are to develop robust intelligent systems, then it is imperative that they can handle incomplete. and inconsistent information in a way that somehow emulates the way humans tackle such a complex task. And one of the key ways that humans do this is to use argumentation -- either internally, by evaluating arguments and counterarguments - or externally, by for instance entering into a discussion or debate where arguments are exchanged. As we report in this review, recent developments in the field are leading to technology for artificial argumentation, in the legal, medical, and e-government domains, and interesting tools for argument mining, for debating technologies, and for argumentation solvers are emerging.",
        "An Argument-Based Multi-Agent System for Information Integration.": "An Argument-Based Multi-Agent System for Information Integration.  \n\nMarcela Capobianco and Guillermo R. Simari  \n\nArtificial Intelligence Research and Development Laboratory Department of Computer Science and Engineering Universidad Nacional del Sur - Av. Alem 1253, (8000) Bahia Blanca ARGenTINA EMAIL: $\\left\\{m c,g r s\\right\\}@c s.u n s.e d u.a r$  \n\nAbstract. In this paper we address the problem of obtaining a consolidated view of the knowledge that a community of information agents possesses in the form of private, possibly large, databases. Each agent in the community has independent sources of information and each database. could contain information that is potentially inconsistent and incomplete, both by itself and/or in conjunction with some of the others. These. characteristics make the consolidation difficult by traditional means. The idea of obtaining a single view is to provide a way of querying the resulting knowledge in a skeptical manner, i.e., receiving one answer that reflects the perception of the information community.  \n\nAgents using the proposed system will be able to access multiple sources of knowledge represented in the form of deductive databases as if they. were accessing a single one. One application of this schema is a novel architecture for decision-support systems (DSS) that will combine database technologies, specifically federated databases, which we will cast as in-. formation agents, with an argumentation-based framework..  \n\nCategories and Subjects Descriptors: I.2.4 [Artificial Intelligence]: Knowledge Representation Formalisms and Methods-Representation languages, Representations (procedural and rule-based); H.1.0 [Models and Principles]: Systems and Information Theory-General systems theory.  \n\nKeywords: Argumentation, Knowledge representation, Design languages for agent systems.",
        "Neural-Symbolic Probabilistic Argumentation Machines": "Neural-symbolic systems combine the strengths of neural networks and symbolic formalisms. In this paper, we in-. troduce a neural-symbolic system which combines restricted Boltzmann machines and probabilistic semi-abstract argu-. mentation. We propose to train networks on argument labellings explaining the data, so that any sampled data outcome is associated with an argument labelling. Argument labellings are integrated as constraints within restricted Boltzmann machines, so that the neural networks are used to learn probabilistic dependencies amongst argument labels. Given a dataset and an argumentation graph as prior knowledge, for. every example/case $K$ in the dataset, we use a so-called. $K$ maxconsistent labelling of the graph, and an explanation of case $K$ refers to a $K$ -maxconsistent labelling of the given argumentation graph. The abilities of the proposed system to predict correct labellings were evaluated and compared with standard machine learning techniques. Experiments revealed that such argumentation Boltzmann machines can outperform other classification models, especially in noisy settings.",
        "A Roadmap for Neuro-argumentative Learning": "Computational argumentation (CA) has emerged, in recent decades, as a powerful formalism for knowl-. edge representation and reasoning in the presence of conflicting information, notably when reasoning non-monotonically with rules and exceptions. Much existing work in CA has focused, to date, on reasoning with given argumentation frameworks (AFs) or, more recently, on using AFs, possibly automat-. ically drawn from other systems, for supporting forms of XAI. In this short paper we focus instead on the problem of learning AFs from data, with a focus on neuro-symbolic approaches. Specifically, we overview existing forms of neuro-argumentative (machine) learning, resulting from a combination. of neural machine learning mechanisms and argumentative (symbolic) reasoning. We include in our overview neuro-symbolic paradigms that integrate reasoners with a natural understanding in argumentative terms, notably those capturing forms of non-monotonic reasoning in logic programming. We also outline avenues and challenges for future work in this spectrum..",
        "Argumentation-based multi-agent distributed reasoning in dynamic and open environments": "This work presents an approach for distributed and contextualized reasoning in multi-agent. systems, considering environments in which agents may have incomplete, uncertain and inconsistent knowledge. Knowledge is represented by defeasible logic with mapping rules, which model the capability of agents to acquire knowledge from other agents during rea-. soning. Based on such knowledge representation, an argumentation-based reasoning model that enables distributed building of reusable argument structures to support conclusions is proposed. Conflicts between arguments are resolved by an argument strength calculation that. considers the trust among agents and the degree of similarity between knowledge of different agents, based on the intuition that greater similarity between knowledge defined by different agents implies in less uncertainty about the validity of the built argument. Contextualized reasoning is supported through sharing of relevant knowledge by an agent when issuing queries to other agents, which enable the cooperating agents to be aware of knowledge not known a priori but that is important to reach a reasonable conclusion given the context of the agent that issued the query. A distributed algorithm is presented and analytically and experimentally evaluated asserting its computational feasibility. Finally, our approach is compared to related work, highlighting the contributions presented, demonstrating its applicability in a broader range of scenarios, and presenting perspectives for future work.  \n\nKeywords Multi-agent reasoning $\\begin{array}{r l}\\end{array}.$ Distributed reasoning $\\begin{array}{r l}\\end{array}.$ Contextual reasoning $\\begin{array}{r l}\\end{array}.$ Defeasible logic $\\cdot$ Argumentation $\\begin{array}{r l}\\end{array}.$ Open environments",
        "A systematic review of argumentation techniques for multi-agent systems research": "A systematic review of argumentation techniques for multi-agent systems research  \n\nAlvaro Carrera1 . Carlos A. Iglesias1  \n\nPublished online: 25 July 2015 $\\copyright$ The Author(s) 2015. This article is published with open access at Springerlink.com  \n\nAbstract The ability to build arguments that express thoughts is crucial for intelligent interactions among human beings. Thus, argumentation techniques have been applied for years in fields, such as rhetoric or artificial intelligence. More specifically, the agents paradigm fits into the use of these types of techniques because agents shape a society in which they interact to make arrangements or to decide future actions. Those interactions can be modelled using argumentation techniques. Therefore, the application of those techniques in multi-agent systems is an interesting research field. However, no systematic review has been conducted previously, to the best of the authors' knowledge, to provide an overview of argumentation techniques for multi-agent systems. This paper presents a systematic review of argumentation techniques for multi-agent systems research. The period of time that is included in this review. is from 1998 to 2014. The objective of this review is to obtain an overview of the existing approaches and to study their impact on research and practice. The research method has been defined to identify relevant studies based on a predefined search strategy, and it is clearly defined to facilitate the reading of this paper. All of the included studies in this review have. been analysed from two different points of view: the Application view and the Multi-Agent System view. A comprehensive analysis of the extracted data is provided in the paper, which is based on a set of research questions that are defined. The results of this review reveal suggestions for further research and practice. The argumentation technology is actually in a phase of internal enhancement and exploration. Moreover, the research interest in this topic has increased in the last years. Furthermore, several interesting findings are presented in the paper.  \n\ndsSystematic review $\\begin{array}{r l}\\end{array}.$ Multi-agent system $\\begin{array}{r l}\\end{array}.$ Argume"
    },
    "MathematicalReasoning": {
        "A Goal-Driven Tree-Structured Neural Model for Math Word Problems": "Most existing neural models for math word problems exploit Seq2Seq model to generate solution expressions sequentially from left to right, whose results are far from satisfactory due to the lack of goal-driven mechanism commonly seen in human problem solving. This paper proposes a treestructured neural model to generate expression tree in a goal-driven manner. Given a math word problem, the model first identifies and encodes its goal to achieve, and then the goal gets decomposed into sub-goals combined by an operator in a top-down recursive way. The whole process is repeated until the goal is simple enough to be realized by a known quantity as leaf node. During the process, two-layer gated-feedforward networks are designed to implement each step of goal decomposition, and a recursive neural network is used to encode fulfilled subtrees into subtree embeddings, which provides a better representation of subtrees than the simple goals of subtrees. Experimental results on the dataset Math23K have shown that our treestructured model outperforms significantly several state-of-the-art models.",
        "HMS: A Hierarchical Solver with Dependency-Enhanced Understanding for Math Word Problem.": "Automatically solving math word problems is a crucial task for exploring the intelligence levels of machines in the general AI domain. It is highly challenging since it requires not only natural language understanding but also mathematical expression inference. Existing solutions usually explore sequence-to-sequence models to generate expressions, where the problems are simply encoded sequentially. However, such models are generally far from enough for understanding problems as similar to humans and lead to incorrect answers. To this end, in this paper, we propose a novel Hierarchical Math Solver (HMS) to make deep understanding and exploitation of problems. In problem understanding, imitating human reading habits, we propose a hierarchical word-clauseproblem encoder. Specifically, we first split each problem into several clauses and learn problem semantics from the local clause level to the global problem level. Then, in clause understanding, we propose a dependency-based module to enhance clause semantics with the dependency structure of the problem. Next, in expression inference, we propose a novel tree-based decoder to generate the mathematical expression for the answer. In the decoder, we apply a hierarchical attention mechanism to enhance the problem semantics with context from different levels, and a pointer-generator network to guide the model to copy existing information and infer extra knowledge. Extensive experimental results on two widely used datasets demonstrate that HMS achieves not only better answers but also more reasonable inference.",
        "End-to-End Differentiable Proving": "We introduce neural networks for end-to-end differentiable proving of queries to knowledge bases by operating on dense vector representations of symbols. These neural networks are constructed recursively by taking inspiration from the backward chaining algorithm as used in Prolog. Specifically, we replace symbolic unification with a differentiable computation on vector representations of symbols using a radial basis function kernel, thereby combining symbolic reasoning with learning subsymbolic vector representations. By using gradient descent, the resulting neural network can be trained to infer facts from a given incomplete knowledge base. It learns to (i) place representations of similar symbols in close proximity in a vector space, (ii) make use of such similarities to prove queries, (ii) induce logical rules, and (iv) use provided and induced logical rules for multi-hop reasoning. We demonstrate that this architecture outperforms ComplEx, a state-of-the-art neural link prediction model, on three out of four benchmark knowledge bases while at the same time inducing interpretable function-free first-order logic rules..",
        "Graph Representations for Higher-Order Logic and Theorem Proving": "This paper presents the first use of graph neural networks (GNNs) for higher-order proof search and demonstrates that. GNNs can improve upon state-of-the-art results in this do-. main. Interactive, higher-order theorem provers allow for. the formalization of most mathematical theories and have been shown to pose a significant challenge for deep learning. Higher-order logic is highly expressive and, even though it is well-structured with a clearly defined grammar and semantics, there still remains no well-established method to convert formulas into graph-based representations. In this paper,. we consider several graphical representations of higher-order. logic and evaluate them against the HOList benchmark for higher-order theorem proving.",
        "DEEP LEARNING FOR SYMBOLIC MATHEMATICS": "Neural networks have a reputation for being better at solving statistical or approximate problems than at performing calculations or working with symbolic data. In this paper, we show that they can be surprisingly good at more elaborated tasks in mathematics, such as symbolic integration and solving differential equations. We propose a syntax for representing mathematical problems, and methods for generating large datasets that can be used to train sequence-to-sequence models. We achieve results that outperform commercial Computer Algebra Systems such as Matlab or Mathematica.",
        "Learning Reasoning Strategies in End-to-End Differentiable Proving": "Attempts to render deep learning models interpretable, data-efficient, and robust have seen some success through hybridisation with rule-based systems, for example, in Neural Theorem Provers (NTPs). These neuro-symbolic models can induce interpretable rules and learn representations from data via back-propagation, while providing logical explanations for their predictions. However, they are restricted by their computational complexity, as they need to consider all possible proof paths for explaining a goal, thus rendering them unfit for large-scale applications. We present Conditional Theorem Provers (CTPs), an extension to NTPs that learns an optimal rule selection strategy via gradient-based optimisation. We show that CTPs are scalable and yield stateof-the-art results on the CLUTRR dataset, which tests systematic generalisation of neural models by learning to reason over smaller graphs and evaluating on larger ones. Finally, CTPs show better link prediction results on standard benchmarks in comparison with other neural-symbolic models, while being explainable. All source code and datasets are available online. 1",
        "Graph-to-Tree Learning for Solving Math Word Problems": "While the recent tree-based neural models have demonstrated promising results in generating solution expression for the math word problem (MwP), most of these models do not capture the relationships and order information among the quantities well. This results in poor quantity representations and incorrect solution expressions. In this paper, we propose Graph2Tree, a novel deep learning architecture that combines the merits of the graph-based encoder and tree-based decoder to generate better solution expressions. Included in our Graph2Tree framework are two graphs, namely the Quantity Cell Graph and Quantity Comparison Graph, which are designed to address limitations of existing methods by effectively representing the relationships and order information among the quantities in MWPs.We conduct extensive experiments on two available datasets. Our experiment results show that Graph2Tree outperforms the state-of-the-art baselines on two benchmark datasets significantly. We also discuss case studies and empirically examine Graph2Tree's effectiveness in translating the MWP text into solution expressions'.",
        "Neural-Symbolic Solver for Math Word Problems with Auxiliary Tasks": "Previous math word problem solvers following the encoder-decoder paradigm fail to explicitly incorporate essential math symbolic constraints, leading to unexplainable and unreasonable predictions. Herein, we propose Neural-Symbolic Solver (NS-Solver) to explicitly and seamlessly incorporate different levels of symbolic constraints by auxiliary tasks. Our NS-Solver consists of a problem reader to encode problems, a programmer to generate symbolic equations, and a symbolic executor to obtain answers. Along with target expression supervision, our solver is also optimized via 4 new auxiliary objectives to enforce different symbolic reasoning: a) self-supervised number prediction task predicting both number quantity and number locations; b) commonsense constant prediction task predicting what prior knowledge (e.g. how many legs a chicken has) is required; c) program consistency checker computing the semantic loss between predicted equation and target equation to ensure reasonable equation mapping; d) duality exploiting task exploiting the quasi duality between symbolic equation generation and problem's part-of-speech generation to enhance the understanding ability of a solver. Besides, to provide a more realistic and challenging benchmark for developing a universal and scalable solver, we also construct a new large-scale MWP benchmark CM17K consisting of 4 kinds of MWPs (arithmetic, one-unknown linear, one-unknown non-linear, equation set) with more than 17K samples. Extensive experiments on Math23K and our CM17k demonstrate the superiority of our NS-Solver compared to state-of-the-art methods.",
        "Seeking Patterns, Not just Memorizing Procedures: Contrastive Learning for Solving Math Word Problems": "Math Word Problem (MwP) solving needs to discover the quantitative relationships over natural language narratives. Recent work shows that existing models memorize procedures from context and rely on shallow heuristics to solve MwPs. In this paper, we look at this issue and argue that the cause is a lack of overall understanding of MWP patterns. We first investigate how a neural network understands patterns only from semantics, and observe that, if the prototype equations like $n_{1}+$ $n_{2}$ are the same, most problems get closer representations and those representations apart from them or close to other prototypes tend to produce wrong solutions. Inspired by it, we propose a contrastive learning approach, where the neural network perceives the divergence of patterns.We collect contrastive examples by converting the prototype equation into a tree and seeking similar tree structures. The solving model is trained with an auxiliary objective on the collected examples, resulting in the representations of problems with similar prototypes being pulled closer. We conduct experiments' on the Chinese dataset Math23k and the English dataset MathQA. Our method greatly improves the performance in monolingual and multilingual settings..",
        "SOFTENED SYMBOL GROUNDING FOR NEURO-SYMBOLIC SYSTEMS": "Neuro-symbolic learning generally consists of two separated worlds, i.e., neural network training and symbolic constraint solving, whose success hinges on symbol grounding, a fundamental problem in AI. This paper presents a novel, softened symbol grounding process, bridging the gap between the two worlds, and resulting in an effective and efficient neuro-symbolic learning framework. Technically, the framework features (1) modeling of symbol solution states as a Boltzmann distribution, which avoids expensive state searching and facilitates mutually beneficial interactions between network training and symbolic reasoning; (2) a new MCMC technique leveraging projection and SMT solvers, which efficiently samples from disconnected symbol solution spaces; (3) an annealing mechanism that can escape from sub-optimal symbol groundings. Experiments with three representative neuro-symbolic learning tasks demonstrate that, owining to its superior symbol grounding capability, our framework successfully solves problems well beyond the frontier of the existing proposals.",
        "Tree-structured Decoding for Solving Math Word Problems": "Automatically solving math word problems is an interesting research topic that needs to bridge natural language descriptions and formal math equations. Previous studies introduced end-to-end neural network methods, but these approaches did not efficiently consider an important characteristic of the equation, i.e., an abstract syntax tree. To address this. problem, we propose a tree-structured decoding method that generates the abstract syntax tree of the equation in a top-down manner. In addition, our approach can automatically stop. during decoding without a redundant stop token. The experimental results show that our method achieves single model state-of-the-art. performance on Math23K, which is the largest. dataset on this task.",
        "Discovering faster matrix multiplication algorithms with reinforcement learning": "Discovering faster matrix multiplication algorithms with reinforcement learning  \n\nhttps://doi.org/10.1038/s41586-022-05172-4  \n\nReceived: 2 October 2021  \n\nAccepted: 2 August 2022  \n\nPublished online: 5 October 2022  \n\nOpen access  \n\nCheck for updates  \n\nAlhussein Fawzi1,2, Matej Balog1'2, Aja Huang1'2, Thomas Hubert',2,   \nBernardino Romera-Paredes'2, Mohammadamin Barekatain', Alexander Novikov',   \nFrancisco J. R. Ruiz', Julian Schrittwieser', Grzegorz Swirszcz', David Silver', Demis Hassabis'   \n& Pushmeet Kohli1  \n\nImproving the efficiency of algorithms for fundamental computations can have a widespread impact, as it can affect the overall speed of a large amount of computations. Matrix multiplication is one such primitive task, occurring in many systems-from neural networks to scientific computing routines. The automatic discovery of algorithms using machine learning offers the prospect of reaching beyond human. intuition and outperforming the current best human-designed algorithms. However, automating the algorithm discovery procedure is intricate, as the space of possible algorithms is enormous. Here we report a deep reinforcement learning approach based on AlphaZero' for discovering efficient and provably correct algorithms for the. multiplication of arbitrary matrices. Our agent, AlphaTensor, is trained to play a single-player game where the objective is finding tensor decompositions within a. finite factor space. AlphaTensor discovered algorithms that outperform the state-. of-the-art complexity for many matrix sizes. Particularly relevant is the case of $\\mathbf{4}\\times\\mathbf{4}$ matrices in a finite field, where AlphaTensor's algorithm improves on Strassen's twolevel algorithm for the first time, to our knowledge, since its discovery 50 years ago?. We further showcase the flexibility of AlphaTensor through different use-cases: algorithms with state-of-the-art complexity for structured matrix multiplication and improved practical efficiency by optimizing matrix multiplication for runtime on. specific hardware. Our results highlight AlphaTensor's ability to accelerate the process of algorithmic discovery on a range of problems, and to optimize for different criteria.  \n\nWe focus on the fundamental task of matrix multiplication, and use deep reinforcement learning(DRL) to search for provably correct and efficient matrix multiplication algorithms. This algorithm discovery. process is particularly amenable to automation because a rich space of matrix multiplication algorithms can be formalized as low-rank decompositions of a specific three-dimensional (3D) tensor?, called the matrix multiplication tensor3-7. This space of algorithms contains the standard matrix multiplication algorithm and recursive algorithms such as Strassen's', as well as the (unknown) asymptotically optimal algorithm.. Although an important body of work aims at characterizing the complexity of the asymptotically optimal algorithm8-12, this does not yield practical algorithms'. We focus here on practical matrix multiplication algorithms, which correspond to explicit low-rank decompositions of the matrix multiplication tensor. In contrast to two-dimensional matrices, for which efficient polynomial-time algorithms computing the rank have existed for over two centuries1, finding low-rank decompositions of 3D tensors (and beyond) is NP-hard'4 and is also hard in practice. In fact, the search space is so large that even the optimal algorithm for multiplying two. $_{3\\times3}$ matrices is still unknown. Nevertheless, in a. longstanding research effort, matrix multiplication algorithms have been discovered by attacking this tensor decomposition problem using human search21s,16, continuous optimization17-19 and combinatorial search2o. These approaches often rely on human-designed heuristics, which are probably suboptimal. We instead use DRL to learn to recog-. nize and generalize over patterns in tensors, and use the learned agent to predict efficient decompositions.  \n\nWe formulate the matrix multiplication algorithm discovery pro-. cedure (that is, the tensor decomposition problem) as a single-player game, called TensorGame. At each step of TensorGame, the player selects how to combine different entries of the matrices to multiply.. A score is assigned based on the number of selected operations required to reach the correct multiplication result. This is a challenging game. with an enormous action space (more than. $10^{12}$ actions for most interesting cases) that is much larger than that of traditional board games such as chess and Go (hundreds of actions). To solve TensorGame and find efficient matrix multiplication algorithms, we develop a DRL agent, AlphaTensor. AlphaTensor is built on AlphaZerol,21, where a neural net-. work is trained to guide a planning procedure searching for efficient. matrix multiplication algorithms. Our framework uses a single agent to decompose matrix multiplication tensors of various sizes, yielding transfer of learned decomposition techniques across various tensors. To address the challenging nature of the game, AlphaTensor uses a specialized neural network architecture, exploits symmetries of the problem and makes use of synthetic training games.  \n\n  \nFig. 1|Matrix multiplicationtensor and algorithms. a, Tensor $\\scriptstyle{T_{2}}$ representing b, Strassen's algorithm? for multiplying $2\\times2$ matrices using 7 multiplications. the multiplication of two $2\\times2$ matrices. Tensor entries equal to1are depicted c, Strassen's algorithm in tensor factor representation. The stacked factors in purple, and Oentries are semi-transparent. The tensor specifies which entries U, V and W (green, purple and yellow, respectively) provide a rank-7. from the input matrices to read, and where to write the result. For example, decomposition of. $\\scriptstyle{T_{2}}$ (equation (1). The correspondence between arithmetice as $\\mathrm{~\\boldmath~\\mathsf~{~\\sigma~}~}_{3}\\,c_{1}\\,{=}\\,a_{1}b_{1}+a_{2}b_{3}$ tensor entries located at $(a_{1},b_{1},c_{1})$ and $(a_{2},b_{3},c_{1})$ are set to1. operations (b) and factors (c) is shown by using the aforementioned colours.  \n\nAlphaTensor scales to a substantially larger algorithm space than what is within reach for either human or combinatorial search. In fact, AlphaTensor discovers from scratch many provably correct matrix multiplication algorithms that improve over existing algorithms in. terms of number of scalar multiplications. We also adapt the algo. rithm discovery procedure to finite fields, and improve over Strassen's two-level algorithm for multiplying. $4\\times4$ matrices for the first time, to. our knowledge, since its inception in 1969. AlphaTensor also discovers a diverse set of algorithms-up to thousands for each size-showing that the space of matrix multiplication algorithms is richer than previously thought. We also exploit the diversity of discovered factorizations to. improve state-of-the-art results for large matrix multiplication sizes. Through different use-cases, we highlight AlphaTensor's flexibility. and wide applicability: AlphaTensor discovers efficient algorithms for structured matrix multiplication improving over known results, and finds efficient matrix multiplication algorithms tailored to specific hardware, by optimizing for actual runtime. These algorithms multiply large matrices faster than human-designed algorithms on the same hardware."
    },
    "ProgrammingSystems": {
        "DEEPCODER: LEARNING TO WRITE PROGRAMS": "We develop a first line of attack for solving programming competition-style prob-. lems from input-output examples using deep learning. The approach is to train a. neural network to predict properties of the program that generated the outputs from the inputs. We use the neural network's predictions to augment search techniques from the programming languages community, including enumerative search and an SMT-based solver. Empirically, we show that our approach leads to an order of magnitude speedup over the strong non-augmented baselines and a Recurrent. Neural Network approach, and that we are able to solve problems of difficulty. comparable to the simplest problems on programming competition websites..",
        "NEURAL SKETCH LEARNING FOR CONDITIONAL PROGRAM GENERATION": "We study the problem of generating source code in a strongly typed, Java-like programming language, given a label (for example a set of API calls or types) carrying a small amount of information about the code that is desired. The generated programs are expected to respect a \"realistic\" relationship between programs and labels, as exemplified by a corpus of labeled programs available during training.  \n\nTwo challenges in such conditional program generation are that the generated pro-. grams must satisfy a rich set of syntactic and semantic constraints, and that source code contains many low-level features that impede learning. We address these problems by training a neural generator not on code but on program sketches, or models of program syntax that abstract out names and operations that do not generalize across programs. During generation, we infer a posterior distribution over. sketches, then concretize samples from this distribution into type-safe programs. using combinatorial techniques. We implement our ideas in a system for generating API-heavy Java code, and show that it can often predict the entire body of a method given just a few API calls or data types that appear in the method..",
        "Learning to Infer Graphics Programs from Hand-Drawn Images": "We introduce a model that learns to convert simple hand drawings into graphics programs written in a subset of $\\mathrm{{I}\\!\\!A\\!\\!P\\!E\\!X}$ . The model combines techniques from deep learning and program synthesis. We learn a convolutional neural network that proposes plausible drawing primitives that explain an image. These drawing primitives are a specification (spec) of what the graphics program needs to draw. We learn a model that uses program synthesis techniques to recover a graphics program from that spec. These programs have constructs like variable bindings, iterative loops, or simple kinds of conditionals. With a graphics program in hand, we can correct errors made by the deep network, measure similarity between drawings by use of similar high-level geometric structures, and extrapolate drawings.",
        "Neural Program Generation Modulo Static Analysis": "State-of-the-art neural models of source code tend to be evaluated on the generation of individual expressions and lines of code, and commonly fail on long-horizon. tasks such as the generation of entire method bodies. We propose to address this. deficiency using weak supervision from a static program analyzer. Our neurosym-. bolic method allows a deep generative model to symbolically compute, using calls to a static-analysis tool, long-distance semantic relationships in the code that it has already generated. During training, the model observes these relationships and learns to generate programs conditioned on them. We apply our approach to the problem of generating entire Java methods given the remainder of the class that contains the method. Our experiments show that the approach substantially outperforms state-of-the-art transformers and a model that explicitly tries to learn program semantics on this task, both in terms of producing programs free of basic. semantic errors and in terms of syntactically matching the ground truth."
    },
    "Question-Answering": {
        "Neural Symbolic Machines: Learning Semantic Parsers on Freebase with Weak Supervision": "Harnessing the statistical power of neural networks to perform language understanding and symbolic reasoning is difficult, when it requires executing efficient discrete operations against a large knowledge-base. In this work, we introduce a Neural Symbolic Machine (NSM), which contains (a) a neural \"programmer\"', i.e., a sequence-to-sequence model that maps language utterances to programs and utilizes a key-variable memory to handle compositionality (b) a symbolic \"computer\", i.e., a Lisp interpreter that performs program execution, and helps find good programs by pruning the search space. We apply REINFORCE to directly optimize the task reward of this structured prediction problem. To train with weak supervision and improve the stability of. REINFORCE we augment it with an iterative maximum-likelihood training process. NSM outperforms the state-of-theart on the WeBQuESTIONsSP dataset when trained from question-answer pairs only, without requiring any feature engineering or domain-specific knowledge..",
        "Dynamic Neuro-Symbolic Knowledge Graph Construction for Zero-shot Commonsense Question Answering": "Understanding narratives requires reasoning about implicit.   \nworld knowledge related to the causes, effects, and states of situations described in text. At the core of this challenge is.   \nhow to access contextually relevant knowledge on demand.   \nand reason over it.  \n\nIn this paper, we present initial studies toward zero-shot commonsense question answering by formulating the task as inference over dynamically generated commonsense knowledge graphs. In contrast to previous studies for knowledge integration that rely on retrieval of existing knowledge from static knowledge graphs, our study requires commonsense knowledge integration where contextually relevant knowledge is often not present in existing knowledge bases. Therefore, we present a novel approach that generates contextually-relevant symbolic knowledge structures on demand using generative neural commonsense knowledge models.  \n\nEmpirical results on two datasets demonstrate the efficacy of our neuro-symbolic approach for dynamically constructing knowledge graphs for reasoning. Our approach achieves significant performance boosts over pretrained language models and vanilla knowledge models, all while providing interpretable reasoning paths for its predictions.",
        "NEURAL MODULE NETWORKS FOR REASONING OVER TEXT": "Answering compositional questions that require multiple steps of reasoning against text is challenging, especially when they involve discrete, symbolic operations. Neural module networks (NMNs) learn to parse such questions as executable programs composed of learnable modules, performing well on synthetic visual QA domains. However, we find that it is challenging to learn these models for non-synthetic questions on open-domain text, where a model needs to deal with the diversity of natural language and perform a broader range of reasoning. We extend NMNs by: (a) introducing modules that reason over a paragraph of text, performing symbolic reasoning (such as arithmetic, sorting, counting) over numbers and dates in a probabilistic and differentiable manner; and (b) proposing an unsupervised auxiliary loss to help extract arguments associated with the events in text. Additionally, we show that a limited amount of heuristically-obtained question program and intermediate module output supervision provides sufficient. inductive bias for accurate learning. Our proposed model significantly outperforms state-of-the-art models on a subset of the DROP dataset that poses a variety of. reasoning challenges that are covered by our modules.",
        "Knowledge-driven Data Construction for Zero-shot Evaluation in Commonsense Question Answering": "Recent developments in pre-trained neural language modeling have led to leaps in accuracy on common-. sense question-answering benchmarks. However, there is increasing concern that models overfit to specific tasks, without learning to utilize external knowledge or perform general semantic reasoning. In contrast, zeroshot evaluations have shown promise as a more robust measure of a model's general reasoning abilities. In this paper, we propose a novel neuro-symbolic framework for zero-shot question answering across commonsense tasks. Guided by a set of hypotheses, the framework studies how to transform various pre-existing knowledge resources into a form that is most effective for pretraining models. We vary the set of language models, training regimes, knowledge sources, and data generation strategies, and measure their impact across tasks. Extending on prior work, we devise and compare four constrained distractor-sampling strategies. We provide empirical results across five commonsense questionanswering tasks with data generated from five external knowledge resources. We show that, while an individual knowledge graph is better suited for specific tasks, a global knowledge graph brings consistent gains across. different tasks. In addition, both preserving the structure of the task as well as generating fair and informative questions help language models learn more effectively.",
        "Adaptable and Interpretable Neural Memory Over Symbolic Knowledge": "Past research has demonstrated that large neural language models (LMs) encode surprising amounts of factual information: however, augmenting or modifying this information requires modifying a corpus and retraining, which is computationally expensive. To address this problem, we develop a neural LM that includes an interpretable neuro-symbolic KB in the form of a \"fact memory\". Each element of the fact memory is formed from a triple of vectors, where each vector corresponds to a KB entity or relation. Our LM improves performance on knowledge-intensive question-answering tasks, sometimes dramatically, including a 27 point increase in one setting of WebQuestionsSP over a state-of-the-art open-book model, despite using $5\\%$ of the parameters. Most interestingly, we demonstrate that the model can be modified, without any re-training, by updating the fact memory.",
        "RNG-KBQA: Generation Augmented Iterative Ranking for Knowledge Base Question Answering.": "Existing KBQA approaches, despite achieving strong performance on i.i.d. test data, often struggle in generalizing to questions involving unseen KB schema items. Prior rankingbased approaches have shown some success in generalization, but suffer from the coverage issue. We present RnG-KBQA, a Rank-andGenerate approach for KBQA, which remedies the coverage issue with a generation model while preserving a strong generalization capability. Our approach first uses a contrastive ranker to rank a set of candidate logical forms obtained by searching over the knowledge graph. It then introduces a tailored generation model conditioned on the question and the top-ranked candidates to compose the final logical form. We achieve new state-ofthe-art results on GRAILQA and WeBQSP datasets. In particular, our method surpasses the prior state-of-the-art by a large margin on the GRAILQA leaderboard. In addition, RnGKBQA outperforms all prior approaches on the popular WeBQSP benchmark, even including the ones that use the oracle entity linking. The experimental results demonstrate the effectiveness of the interplay between ranking and generation, which leads to the superior performance of our proposed approach across all settings with especially strong improvements in zero-shot generalization.'  \n\n  \nFigure 1: Overview of our rank-and-generate approach. Given a question, we first rank logical form candidates obtained by searching over the KB based on predefined rules. Here, the ground truth logical form is not in the top-ranked candidates as it is not covered by the rules. We solve this problem using another generation step that produces the correct logical form based on topranked candidates. The final logical form is executed over the KB to yield the answer.",
        "A Two-Stage Approach towards Generalization in Knowledge Base Question Answering": "Most existing approaches for Knowledge Base Question Answering (KBQA) focus on a specific underlying knowledge base either because of inherent assumptions in the approach,. or because evaluating it on a different knowledge base requires non-trivial changes. However, many popular knowledge bases share similarities in their underlying schemas that can be leveraged to facilitate generalization across knowledge bases. To achieve this, we introduce a KBQA framework based on a 2-stage architecture that explicitly separates semantic parsing from the knowledge base interaction, facilitating transfer learning across datasets and knowledge graphs. We show that pretraining on datasets with a different underlying knowledge base can nevertheless provide significant performance gains and reduce sample complexity. Our approach achieves comparable or state-of-the-art performance for LC-QuAD (DBpedia), WebQSP (Freebase), SimpleQuestions (Wikidata) and MetaQA (Wikimovies-KG)."
    },
    "Robotics&Control": {
        "PEORL: Integrating Symbolic Planning and Hierarchical Reinforcement Learning for Robust Decision-Making": "Reinforcement learning and symbolic planning have both been used to build intelligent autonomous agents. Reinforcement learning relies on learning from interactions with real world, which often requires an unfeasibly large amount of experience. Symbolic planning relies on manually crafted symbolic knowledge, which may not be robust to. domain uncertainties and changes. In this paper we present a unified framework PEORL that integrates symbolic planning with hierarchical reinforcement learning (HRL) to cope with decision-making in a dynamic environment with uncertainties. Symbolic plans are used to guide the agent's task execution and learning, and the learned experience is fed back to symbolic knowledge to improve planning. This method leads to rapid policy search and robust symbolic plans in complex domains. The framework is tested on benchmark domains of HRL..",
        "Neural Task Programming: Learning to Generalize Across Hierarchical Tasks": "Neural Task Programming: Learning to Generalize Across Hierarchical Tasks  \n\nDanfei $\\mathrm{Xu}^{*1}$ , Suraj Nair\\*2, Yuke. $Z\\mathrm{{hu}}^{1}$ , Julian $\\mathrm{Gao}^{1}$ , Animesh $\\mathrm{Garg^{1}}$ , Li Fei-Feil, Silvio Savaresel  \n\nAbstract-In this work, we propose a novel robot learning. framework called Neural Task Programming (NTP), which. bridges the idea of few-shot learning from demonstration and neural program induction. NTP takes as input a task specification (e.g., video demonstration of a task) and recursively decomposes it into finer sub-task specifications. These specifications are fed to a hierarchical neural program, where bottom-. level programs are callable subroutines that interact with the environment. We validate our method in three robot manipulation tasks. NTP achieves strong generalization across sequential tasks that exhibit hierarchal and compositional structures. The experimental results show that NTP learns to generalize well towards unseen tasks with increasing lengths, variable topologies, and changing objectives. stanfordvl.github.io/ntp/",
        "Hierarchical Planning for Long-Horizon Manipulation with Geometric and Symbolic Scene Graphs.": "Hierarchical Planning for Long-Horizon Manipulation with Geometric and Symbolic Scene Graphs.  \n\nYifeng $Z\\mathrm{hu^{1,2}}$ , Jonathan Tremblayl, Stan Birchfield', Yuke Zhul,2  \n\nAbstract-- We present a visually grounded hierarchical planning algorithm for long-horizon manipulation tasks. Our algorithm offers a joint framework of neuro-symbolic task planning and low-level motion generation conditioned on the specified. goal. At the core of our approach is a two-level scene graph rep-. resentation, namely geometric scene graph and symbolic scene graph. This hierarchical representation serves as a structured,. object-centric abstraction of manipulation scenes. Our model uses graph neural networks to process these scene graphs. for predicting high-level task plans and low-level motions. We. demonstrate that our method scales to long-horizon tasks and generalizes well to novel task goals. We validate our method. in a kitchen storage task in both physical simulation and the. real world. Experiments show that our method achieves over. $70\\%$ success rate and nearly $90\\%$ of subgoal completion rate on the real robot while being four orders of magnitude faster. in computation time compared to standard search-based task-. and-motion planner.'",
        "Learning Neuro-Symbolic Skills for Bilevel Planning": "Learning Neuro-Symbolic Skills for Bilevel Planning  \n\nTom Silver, Ashay Athalye Joshua B. Tenenbaum, Tomas Lozano-Perez, Leslie Pack Kaelbling MIT Computer Science and Artificial Intelligence Laboratory. {tslvr, ashay, jbt, tlp, lpk}@mit.edu.  \n\nDecision-making is challenging in robotics environments with continuous object-centric states, continuous actions, long horizons, and sparse feed-. back. Hierarchical approaches, such as task and motion planning (TAMP), ad-. dress these challenges by decomposing decision-making into two or more levels of abstraction. In a setting where demonstrations and symbolic predicates are given, prior work has shown how to learn symbolic operators and neural. samplers for TAMP with manually designed parameterized policies. Our main contribution is a method for learning parameterized polices in combination with operators and samplers. These components are packaged into modular neurosymbolic skills and sequenced together with search-then-sample TAMP to solve new tasks. In experiments in four robotics domains, we show that our approach -- bilevel planning with neuro-symbolic skills -- can solve a wide range of tasks with varying initial states, goals, and objects, outperforming six baselines and ablations. Video: https://youtu.be/PbFZP8rPuGg Code: https:. //tinyurl. com/skill-learning  \n\nKeywords: Skill Learning, Neuro-Symbolic, Task and Motion Planning",
        "Neuro-Symbolic Program Search for Autonomous Driving Decision Module Design": "Neuro-Symbolic Program Search for Autonomous Driving Decision Module Design  \n\nJiankai Sun!Hao Sun!Tian. $\\mathbf{Han}^{2}$ Bolei Zhou! 1The Chinese University of Hong Kong 2Stevens Institute of Technology {sj019, sh018, bzhou}@ie.cuhk.edu.hk than6@stevens.edu  \n\nAs a promising topic in cognitive robotics, neuro-symbolic modeling integrates symbolic reasoning and neural representation altogether. However, previous neuro-symbolic models usually wire their structures and the connections manually, making the underlying parameters sub-optimal. In this work,. we propose the Neuro-Symbolic Program Search (NSPs) to improve the autonomous driving system design. NSPS is a novel automated search method that synthesizes the Neuro-Symbolic Programs. It can produce robust and expressive Neuro-Symbolic Programs and automatically tune the hyper-parameters.. We validate NSPS in the CARLA driving simulation environment. The resulting Neuro-Symbolic Decision Programs successfully handle multiple traffic scenarios. Compared with previous neural-network-based driving and rule-based methods, our neuro-symbolic driving pipeline achieves more stable and safer behaviors in complex driving scenarios while maintaining an interpretable symbolic decision-making process.  \n\nKeywords: Neuro-Symbolic AI, Cognitive Robotics, Autonomous Driving"
    },
    "ScientificDiscovery": {
        "SYNTAX-DIRECTED VARIATIONAL AUTOENCODER FOR STRUCTURED DATA": "Deep generative models have been enjoying success in modeling continuous data. However it remains challenging to capture the representations for discrete struc-. tures with formal grammars and semantics, e.g., computer programs and molecular structures. How to generate both syntactically and semantically correct data still remains largely an open problem. Inspired by the theory of compiler where the syntax and semantics check is done via syntax-directed translation (SDT), we propose a novel syntax-directed variational autoencoder (SD-VAE) by introducing stochastic lazy attributes. This approach converts the offline SDT check into. on-the-fly generated guidance for constraining the decoder. Comparing to the state-of-the-art methods, our approach enforces constraints on the output space so that the output will be not only syntactically valid, but also semantically reasonable. We evaluate the proposed model with applications in programming language and molecules, including reconstruction and program/molecule optimization. The results demonstrate the effectiveness in incorporating syntactic and semantic constraints in discrete generative models, which is significantly better than current state-of-the-art approaches.",
        "Retrosynthesis Prediction with Conditional Graph Logic Network": "Retrosynthesis is one of the fundamental problems in organic chemistry. The task is to identify reactants that can be used to synthesize a specified product molecule. Recently, computer-aided retrosynthesis is finding renewed interest from both chemistry and computer science communities. Most existing approaches rely on template-based models that define subgraph matching rules, but whether or not a chemical reaction can proceed is not defined by hard decision rules. In this work, we propose a new approach to this task using the Conditional Graph Logic Network, a conditional graphical model built upon graph neural networks that learns when rules from reaction templates should be applied, implicitly considering whether the resulting reaction would be both chemically feasible and strategic. We also propose an efficient hierarchical sampling to alleviate the computation cost. While achieving a significant improvement of $8.1\\%$ over current state-of-the-art methods on the benchmark dataset, our model also offers interpretations for the prediction.",
        "Discovering Symbolic Models from Deep Learning with Inductive Biases.": "We develop a general approach to distill symbolic representations of a learned deep model by introducing strong inductive biases. We focus on Graph Neural Networks (GNNs). The technique works as follows: we first encourage sparse latent representations when we train a GNN in a supervised setting, then we apply symbolic regression to components of the learned model to extract explicit physical relations. We find the correct known equations, including force laws and Hamiltonians, can be extracted from the neural network. We then apply our method to a non-trivial cosmology example-a detailed dark matter simulation-and discover a new analytic formula which can predict the concentration of dark matter from the mass distribution of nearby cosmic structures. The symbolic expressions extracted from the GNN using our technique also generalized to out-of-distributiondata better than the GNN itself. Our approach offers alternative directions for interpreting neural networks and discovering novel physical principles from the representations they learn.",
        "Learning Differentiable Programs with Admissible Neural Heuristics.": "We study the problem of learning differentiable functions expressed as programs in a domain-specific language. Such programmatic models can offer benefits such as composability and interpretability; however, learning them requires optimizing over a combinatorial space of program \"architectures\". We frame this optimization problem as a search in a weighted graph whose paths encode top-down derivations of program syntax. Our key innovation is to view various classes of neural networks as continuous relaxations over the space of programs, which can then be used to complete any partial program. This relaxed program is differentiable and can be trained end-to-end, and the resulting training loss is an approximately admissible heuristic that can guide the combinatorial search. We instantiate our approach on top of the $\\mathbf{A}^{*}$ algorithm and an iteratively deepened branch-and-bound search, and use these algorithms to learn programmatic classifiers in three sequence classification tasks. Our experiments show that the algorithms outperform stateof-the-art methods for program learning, and that they discover programmatic classifiers that yield natural interpretations and achieve competitive accuracy.",
        "Automatic Synthesis of Diverse Weak Supervision Sources for Behavior Analysis": "Obtaining annotations for large training sets is expensive, especially in settings where domain knowledge is required, such as behavior analysis. Weak supervision has been studied to reduce annotation costs by using weak la bels from task-specific labeling functions (LFs) to augment ground truth labels. However, domain experts still need to hand-craft different LFs for different tasks, limiting scal ability. To reduce expert effort, we present AutoswAP: a framework for automatically synthesizing data-efficient task-level LFs. The key to our approach is to efficiently represent expert knowledge in a reusable domain-specific language and more general domain-level LFs, with which we use state-of-the-art program synthesis techniques and a small labeled dataset to generate task-level LFs. Additionally, we propose a novel structural diversity cost that allows for efficient synthesis of diverse sets of LFs, further improving AutoSWAP's performance. We evaluate AutoSWAP in three behavior analysis domains and demonstrate that AutoSWAP outperforms existing approaches using only a fraction of the data. Our results suggest that AutoSwAP is an effective way to automatically generate LFs that can significantly reduce expert effort for behavior analysis.",
        "Retrosynthetic Design": "Retrosynthetic Design",
        "Planning chemical syntheses with deep neural networks and symbolic AI": "Planning chemical syntheses with deep neural networks and symbolic AI  \n\nMarwin H. S. Seglerl,2, Mike Preuss & Mark P. Waller4  \n\nTo plan the syntheses of small organic molecules, chemists use retrosynthesis, a problem-solving technique in which target molecules are recursively transformed into increasingly simpler precursors. Computer-aided retrosynthesis would be a valuable tool but at present it is slow and provides results of unsatisfactory quality. Here we use Monte Carlo. tree search and symbolic artificial intelligence (AI) to discover retrosynthetic routes. We combined Monte Carlo tree search with an expansion policy network that guides the search, and a filter network to pre-select the most promising retrosynthetic steps. These deep neural networks were trained on essentially all reactions ever published in organic chemistry. Our system solves for almost twice as many molecules, thirty times faster than the traditional computer-aided. search method, which is based on extracted rules and hand-designed heuristics. In a double-blind AB test, chemists on average considered our computer-generated routes to be equivalent to reported literature routes.  \n\nRetrosynthetic analysis is the canonical technique used to plan the synthesis of small organic molecules1,2. In retrosynthesis, a search tree. is built by working backwards, analysing molecules recursively and transforming them into simpler precursors until one obtains a set of known or commercially available building-block molecules $(\\mathrm{Fig}.\\,1)^{3,4}$ Given that transformations are formally reversed chemical reactions, the plan can be then carried out in the laboratory in the forward direction to synthesize the target compound3,4. Transformations are derived from successfully conducted series of similar reactions with analogous starting materials, and are often named after their discoverers (named reactions')5. At each retrosynthetic step, a small set out of hundreds of. thousands of transformations known in modern chemistry has to be selected. In a pattern recognition process, chemists intuitively prioritise the most promising transformations, which they then consider, without actively thinking about the less promising ones'. However, when a transformation is applied to a new molecule, there is no guarantee that the corresponding reaction will proceed in the expected way'. A molecule failing to react as predicted is called out of scope. This can be due to steric or electronic effects, an incomplete understanding of the reaction mechanism, or conflicting reactivity in the molecular context. Predicting which molecules are in scope can be challenging. even for the best human chemists4,7.  \n\nComputer-assisted synthesis planning (CASP) could help chemists to find better routes faster, and is a missing component in virtual. de novo design and robot systems performing molecular designsynthesis-test cycles8-10. To perform CASP, the knowledge that humans gain must be transferred into an executable program11-16. Despite. 60 years of research, attempts to formalize chemistry by manual encoding by experts have not convinced synthetic chemists, and it does not scale to exponentially growing knowledge15-19. Methods of algorithmically extracting transformations from reaction datasets20-22 have. been criticized for high noise and lack of chemical intelligence'13,14. However, we recently showed that deep neural networks can learn to rank extracted symbolic transformations, and to avoid reactivity conflicts, which mimics the expert's intuitive decision-making23. To guide the search in promising directions, heuristic best first search (BFS) has been employed, in which hand-designed heuristic functions determine position valuesl3. Unfortunately, unlike in chess, it is difficult to define strong heuristics in chemistry for three reasons. First, chemists tend to disagree on what constitutes a good position24,25. Second, although it is generally desirable to simplify the molecules, it can be tactically. beneficial to temporarily increase complexity by the use of protecting or directing groups. Finally, the position value depends highly on the. availability of suitable precursors13,15. Even complex molecules can be made in a few steps if precursors are readily available. Therefore, one. cannot reliably estimate the value of a synthetic position without completely playing the molecules until the end of the game.  \n\nMonte Carlo tree search (MCTS) has emerged as a general search technique for sequential decision problems with large branching factors without strong heuristics, such as games or automated theorem proving26-28. MCTS uses rollouts to determine position values. Rollouts are Monte Carlo simulations, in which random search steps are performed without branching until a solution has been found or a maximum depth is reached. These random steps can be sampled from machine-learned policies $p(t|s)^{29}$ which predict the probability. of taking the move (applying the transformation) $t$ in position $s,$ and are trained to predict the winning move by using human games or. self-play30-35.  \n\nIn this work, we combine three different neural networks together. with MCTS to perform chemical synthesis planning (3N-MCTS). The first neural network (the expansion policy) guides the search in. promising directions by proposing a restricted number of automatically extracted transformations. A second neural network then predicts whether the proposed reactions are actually feasible (in scope). Finally, to estimate the position value, transformations are sampled from a third neural network during the rollout phase. The neural networks were trained on essentially all reactions published in the history of organic chemistry.",
        "Highly accurate protein structure prediction with AlphaFold": "Proteins are essential to life, and understanding their structure can facilitate a mechanistic understanding of their function. Through an enormous experimental effort1,2,3,4, the structures of around 100,000 unique proteins have been determined5, but this represents a small fraction of the billions of known protein sequences6,7. Structural coverage is bottlenecked by the months to years of painstaking effort required to determine a single protein structure. Accurate computational approaches are needed to address this gap and to enable large-scale structural bioinformatics. Predicting the three-dimensional structure that a protein will adopt based solely on its amino acid sequence—the structure prediction component of the ‘protein folding problem’8—has been an important open research problem for more than 50 years9. Despite recent progress10,11,12,13,14, existing methods fall far short of atomic accuracy, especially when no homologous structure is available. Here we provide the first computational method that can regularly predict protein structures with atomic accuracy even in cases in which no similar structure is known. We validated an entirely redesigned version of our neural network-based model, AlphaFold, in the challenging 14th Critical Assessment of protein Structure Prediction (CASP14)15, demonstrating accuracy competitive with experimental structures in a majority of cases and greatly outperforming other methods. Underpinning the latest version of AlphaFold is a novel machine learning approach that incorporates physical and biological knowledge about protein structure, leveraging multi-sequence alignments, into the design of the deep learning algorithm."
    },
    "Vision-Language Analysis&Reasoning": {
        "Deep Compositional Question Answering with Neural Module Networks": "Visual question answering is fundamentally compositional in nature-a question like where is the dog? shares substructure with questions like what color is the dog? and where is the cat? This paper seeks to simultaneously exploit the representational capacity of deep networks and the compositional linguistic structure of questions. We describe a procedure for constructing and learning neural module networks, which compose collections of jointly-trained neural \"modules\" into deep networks for question answering. Our. approach decomposes questions into their linguistic substructures, and uses these structures to dynamically instantiate modular networks (with reusable components for recognizing dogs, classifying colors, etc.). The resulting compound networks are jointly trained. We evaluate our ap-. proach on two challenging datasets for visual question answering, achieving state-of-the-art results on both the VQA natural image dataset and a new dataset of complex questions about abstract shapes.  \n\n  \nFigure 1: A schematic representation of our proposed. model--the shaded gray area is a neural module network of the kind introduced in this paper. Our approach uses a nat-. ural language parser to dynamically lay out a deep network composed of reusable modules. For visual question answering tasks, an additional sequence model provides sentence context and learns common-sense knowledge.",
        "Inferring and Executing Programs for Visual Reasoning": "Existing methods for visual reasoning attempt to directly map inputs to outputs using black-box architectures without explicitly modeling the underlying reasoning processes. As a result, these black-box models often learn to exploit biases in the data rather than learning to perform visual reasoning. Inspired by module networks, this paper proposes a model for visual reasoning that consists of a program generator that constructs an explicit representation of the reasoning process to be performed, and an execution engine that executes the resulting program to produce an answer. Both the program generator and the execution engine are implemented by neural networks, and are trained using a combination of backpropagation and REINFORCE. Using the CLEVR benchmark for visual reasoning, we show that our model significantly outperforms strong baselines and generalizes better in a variety of settings.",
        "COMPOSITIONAL ATTENTION NETWORKS FOR MACHINE REASONING": "We present the MAC network, a novel fully differentiable neural network architecture, designed to facilitate explicit and expressive reasoning. MAC moves away from monolithic black-box neural architectures towards a design that encourages both transparency and versatility. The model approaches problems by decomposing them into a series of attention-based reasoning steps, each performed by a novel recurrent Memory, Attention, and Composition (MAC) cell that maintains. a separation between control and memory. By stringing the cells together and imposing structural constraints that regulate their interaction, MAC effectively learns. to perform iterative reasoning processes that are directly inferred from the data in an end-to-end approach. We demonstrate the model's strength, robustness and interpretability on the challenging CLEVR dataset for visual reasoning, achieving a new state-of-the-art $98.9\\%$ accuracy, halving the error rate of the previous best. model. More importantly, we show that the model is computationally-efficient and. data-efficient, in particular requiring. $\\mathsf{5x}$ less data than existing models to achieve. strong results.",
        "Neural-Symbolic VQA: Disentangling Reasoning from Vision and Language Understanding.": "We marry two powerful ideas: deep representation learning for visual recognition and language understanding, and symbolic program execution for reasoning. Our neural-symbolic visual question answering (NS-VQA) system first recovers a structural scene representation from the image and a program trace from the. question. It then executes the program on the scene representation to obtain an. answer. Incorporating symbolic structure as prior knowledge offers three unique advantages. First, executing programs on a symbolic space is more robust to long program traces; our model can solve complex reasoning tasks better, achieving an. accuracy of $99.8\\%$ on the CLEVR dataset. Second, the model is more data- and. memory-efficient: it performs well after learning on a small number of training. data; it can also encode an image into a compact representation, requiring less storage than existing methods for offline question answering. Third, symbolic program execution offers full transparency to the reasoning process; we are thus able to interpret and diagnose each execution step..",
        "Explainable and Explicit Visual Reasoning over Scene Graphs": "We aim to dismantle the prevalent black-box neural architectures used in complex visual reasoning tasks, into the proposed eXplainable and eXplicit Neural Modules (XNMs), which advance beyond existing neural module networks towards using scene graphs - objects as nodes and the pairwise relationships as edges - for explainable and explicit reasoning with structured knowledge. XNMs allow us to pay more attention to teach machines how to \"think\", regardless of what they \"look\". As we will show in the paper, by using scene graphs as an inductive bias, 1) we can design XNMs in a concise and flexible fashion, i.e., XNMs merely consist of 4 meta-types, which significantly reduce the number of parameters by 10 to 100 times, and 2) we can explicitly trace the reasoning-flow in terms of graph attentions. XNMs are so generic that they support a wide range of scene graph implementations with various qualities. For example, when the graphs are detected perfectly, XNMs achieve $I O O\\%$ accuracy on both CLEVR and CLEVR CoGenT, establishing an empirical performance upper-bound for visual reasoning; when the graphs are noisily detected from real-world images, XNMs are still robust to achieve a competitive $67.5\\%$ accuracy on $V Q A\\nu2.O_{\\ast}$ surpassing the popular bag-of-objects attention models without graph structures.",
        "Probabilistic Neural-symbolic Models for Interpretable Visual Question Answering.": "We propose a new class of probabilistic neuralsymbolic models, that have symbolic functional programs as a latent, stochastic variable. Instantiated in the context of visual question answering, our probabilistic formulation offers two key conceptual advantages over prior neural-symbolic models for VQA. Firstly, the programs generated by our model are more understandable while requiring less number of teaching examples. Secondly, we show that one can pose counterfactual scenarios to the model, to probe its beliefs on the programs that could lead to a specified answer given an image. Our results on the CLEVR and SHAPES datasets verify our hypotheses, showing that the model gets better program (and answer) prediction accuracy even in the low data regime, and allows one to probe the coherence and consistency of reasoning performed.",
        "THE NEURO-SYMBOLIC CONCEPT LEARNER: INTERPRETING SCENES, WORDS, AND SENTENCES FROM NATURAL SUPERVISION": "We propose the Neuro-Symbolic Concept Learner (NS-CL), a model that learns visual concepts, words, and semantic parsing of sentences without explicit supervision on any of them; instead, our model learns by simply looking at images and. reading paired questions and answers. Our model builds an object-based scene. representation and translates sentences into executable, symbolic programs. To bridge the learning of two modules, we use a neuro-symbolic reasoning module that executes these programs on the latent scene representation. Analogical to human concept learning, the perception module learns visual concepts based on the language description of the object being referred to. Meanwhile, the learned visual concepts facilitate learning new words and parsing new sentences. We use. curriculum learning to guide the searching over the large compositional space of images and language. Extensive experiments demonstrate the accuracy and efficiency of our model on learning visual concepts, word representations, and semantic parsing of sentences. Further, our method allows easy generalization to new object attributes, compositions, language concepts, scenes and questions, and even new program domains. It also empowers applications including visual question answering and bidirectional image-text retrieval.",
        "Neuro-Symbolic Visual Reasoning: Disentangling \"Visual' from \"Reasoning''": "Visual reasoning tasks such as visual question answering (VQA) require an interplay of visual perception with reasoning about the question semantics grounded in perception. However, recent advances in this area are still primarily driven by perception improvements (e.g. scene graph generation) rather than reasoning. Neuro-symbolic models such as Neural Module Networks bring the benefits of compositional reasoning to VQA, but they are still entangled with visual representation learning, and thus neural reasoning is hard to improve and assess on its own. To address this, we propose (1) a framework to isolate and evaluate the reasoning aspect of VQA separately from its perception, and (2) a novel top-down calibration technique that allows the model to answer reasoning questions even with imperfect perception. To this end, we introduce a differentiable first-order logic formalism for VQA that explicitly decouples question answering from visual perception. On the challenging GQA dataset, this framework is used to perform in-depth, disentangled comparisons between well-known VQA models leading to informative insights regarding the participating models as well as the task.",
        "Learning to Reason: End-to-End Module Networks for Visual Question Answering": "Natural language questions are inherently compositional, and many are most easily answered by reasoning about their decomposition into modular sub-problems. For example, to answer \"is there an equal number of balls and boxes?\" we can look for balls, look for boxes, count them, and compare the results. The recently proposed Neural Module Network (NMN) architecture [3, 2] implements this approach to question answering by parsing questions into linguistic substructures and assembling question-specific deep networks from smaller modules that each solve one subtask. However, existing NMN implementations rely on brittle off-the-shelf parsers, and are restricted to the module configurations proposed by these parsers rather than learning them from data. In this paper, we propose End-to-End Module Networks (N2NMNs), which learn to reason by directly predicting instance-specific network layouts without the aid of a parser. Our model learns to generate network structures (by imitating expert demonstrations) while simultaneously learning network parameters (using the downstream task loss). Experimental results on the new CLEVR dataset targeted at compositional question answering show that N2NMNs achieve an error reduction of nearly. $50\\%$ relative to state-of-theart attentional approaches, while discovering interpretable network architectures specialized for each question..",
        "Transparency by Design: Closing the Gap Between Performance and Interpretability in Visual Reasoning.": "Visual question answering requires high-order reasoning about an image, which is a fundamental capability needed by machine systems to follow complex directives. Recently, modular networks have been shown to be an effective framework for performing visual reasoning tasks. While modular networks were initially designed with a degree of model transparency, their performance on complex visual reasoning benchmarks was lacking. Current stateof-the-art approaches do not provide an effective mechanism for understanding the reasoning process. In this paper,. we close the performance gap between interpretable models and state-of-the-art visual reasoning methods. We propose a set of visual-reasoning primitives which, when composed, manifest as a model capable of performing complex reasoning tasks in an explicitly-interpretable manner. The fidelity and interpretability of the primitives' outputs enable an unparalleled ability to diagnose the strengths and weaknesses of the resulting model. Critically, we show that these primitives are highly performant, achieving state-of-the-art accuracy of $99.I\\%$ on the CLEVR dataset. We also show that. our model is able to effectively learn generalized representations when provided a small amount of data containing novel object attributes. Using the CoGenT generalization task, we show more than a 20 percentage point improvement over the current state of the art..",
        "Multimodal Graph Networks for Compositional Generalization in Visual Question Answering.": "Compositional generalization is a key challenge in grounding natural language to visual perception. While deep learning models have achieved great success in multimodal tasks like visual question answering, recent studies have shown that they fail to generalize to new inputs that are simply an unseen combination of those seen in the training distribution [6]. In this paper, we propose to tackle this. challenge by employing neural factor graphs to induce a tighter coupling between concepts in different modalities (e.g. images and text). Graph representations are inherently compositional in nature and allow us to capture entities, attributes and relations in a scalable manner. Our model first creates a multimodal graph, processes it with a graph neural network to induce a factor correspondence matrix, and then outputs a symbolic program to predict answers to questions. Empirically, our model achieves close to perfect scores on a caption truth prediction problem and state-of-the-art results on the recently introduced CLOSURE dataset, improving on. the mean overall accuracy across seven compositional templates by $4.77\\%$ over previous approaches.2"
    },
    "VisualSceneUnderstanding": {
        "Logic Tensor Networks for Semantic Image Interpretation": "Semantic Image Interpretation (SII) is the task of extracting structured semantic descriptions from images. It is widely agreed that the combined use of visual data and background knowledge is of great importance for SII. Recently, Statistical Relational Learning (SRL) approaches have been developed for reasoning under uncertainty and learning in the presence of data and rich knowledge. Logic Tensor Networks (LTNs) are an SRL framework which integrates neural networks. with first-order fuzzy logic to allow (i) efficient learning from noisy data in the presence of logical constraints, and (ii) reasoning with logical formulas describing general properties of the data. In this paper, we develop and apply LTNs to two of the main tasks of SII, namely, the classification of an image's bounding. boxes and the detection of the relevant part-of relations between objects. To the best of our knowledge, this is the first successful application of SRL to such SII tasks. The proposed approach is evaluated on a standard image processing benchmark. Experiments show that the use of background knowledge in the form of logical constraints can improve the performance of purely data-driven approaches, including the state-of-the-art Fast Region-based Convolutional Neural Networks (Fast R-CNN). Moreover, we show that the use of logical background knowledge adds robustness to the learning system when errors are present in the labels of the training data.",
        "Embedding Symbolic Knowledge into Deep Networks": "In this work, we aim to leverage prior symbolic knowledge to improve the performance of deep models. We propose a graph embedding network that projects propositional formulae (and assignments) onto a manifold via an augmented Graph Convolutional Network (GCN). To generate semantically-faithful embeddings, we develop techniques to recognize node heterogeneity, and semantic regularization that incorporate structural constraints into the embedding. Experiments show that our approach improves the performance of models trained to perform entailment checking and visual relation prediction. Interestingly, we observe a connection between the tractability of the propositional theory representation and the ease of embedding. Future exploration of this connection may elucidate the relationship between knowledge compilation and vector representation learning.",
        "Making Better Mistakes: Leveraging Class Hierarchies with Deep Networks": "Deep neural networks have improved image classification dramatically over the past decade, but have done so by focusing on performance measures that treat all classes other than the ground truth as equally wrong. This has led to a situation in which mistakes are less likely to be made than before, but are equally likely to be absurd or catastrophic when they do occur. Past works have recognised and tried to address this issue of mistake severity, often by using graph distances in class hierarchies, but this has largely been neglected since the advent of the current deep learning era in computer vision. In this paper, we aim to renew interest in this problem by reviewing past approaches and proposing two simple modifications of the cross-entropy loss which outperform the prior art under several metrics on two large datasets with complex class hierarchies: tieredImageNet and iNaturalist'19.",
        "Deep Hierarchical Semantic Segmentation": "Humans are able to recognize structured relations in observation, allowing us to decompose complex scenes into simpler parts and abstract the visual world in multiple levels. However, such hierarchical reasoning ability of human perception remains largely unexplored in current literature of semantic segmentation. Existing work is often aware of flatten labels and predicts target classes exclusively for each pixel. In this paper, we instead address hierarchical semantic segmentation (HSS), which aims at structured, pixel-wise description of visual observation in terms of a class hierarchy. We devise HssN, a general HSS framework that tackles two critical issues in this task: i) how to efficiently adapt existing hierarchy-agnostic segmentation networks to the HSS setting, and ii) how to leverage the hierarchy information to regularize HSS network learning. To address i), HssN directly casts HSS as a pixel-wise multi-label classification task, only bringing minimal architecture change to current segmentation models. To solve ii), HssN first explores inherent properties of the hierarchy as a training objective, which en-. forces segmentation predictions to obey the hierarchy structure. Further, with hierarchy-induced margin constraints, HssN reshapes the pixel embedding space, so as to generate well-structured pixel representations and improve segmentation eventually. We conduct experiments on four semantic segmentation datasets (i.e., Mapillary Vistas 2.0, Cityscapes, LIP, and PASCAL-Person-Part), with different class hierarchies, segmentation network architectures and backbones, showing the generalization and superiority of HsSN.",
        "Visual Programming: Compositional visual reasoning without training": "We present VisProg, a neuro-symbolic approach to solving complex and compositional visual tasks given natural language instructions.. VisProG avoids the need. for any task-specific training.. Instead, it uses the in-. context learning ability of large language models to gener-. ate python-like modular programs, which are then executed. to get both the solution and a comprehensive and inter-. pretable rationale. Each line of the generated program may invoke one of several off-the-shelf computer vision models, image processing subroutines, or python functions to produce intermediate outputs that may be consumed by subsequent parts of the program. We demonstrate the flexibility of VisPROG on 4 diverse tasks - compositional visual question answering, zero-shot reasoning on image pairs, factual knowledge object tagging, and language-guided image edit-. ing. We believe neuro-symbolic approaches like VisPROG are an exciting avenue to easily and effectively expand the scope of AI systems to serve the long tail of complex tasks that people may wish to perform..",
        "ViperGPT: Visual Inference via Python Execution for Reasoning": "Answering visual queries is a complex task that requires both visual processing and reasoning. End-to-end models, the dominant approach for this task, do not explicitly differentiate between the two, limiting interpretability and generalization. Learning modular programs presents a promising alternative, but has proven challenging due to the difficulty of learning both the programs and modules simultaneously. We introduce ViperGPT, a framework that leverages codegeneration models to compose vision-and-language models into subroutines to produce a result for any query. ViperGPT utilizes a provided API to access the available modules, and composes them by generating Python code that is later executed. This simple approach requires no further training, and achieves state-of-the-art results across various complex visual tasks.",
        "HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face.": "Solving complicated AI tasks with different domains and modalities is a key step toward artificial general intelligence. While there are numerous AI models available for various domains and modalities, they cannot handle complicated AI tasks autonomously. Considering large language models (LLMs) have exhibited exceptional abilities in language understanding, generation, interaction, and reasoning, we advocate that LLMs could act as a controller to manage existing AI models to solve complicated AI tasks, with language serving as a generic interface to empower this. Based on this philosophy, we present HuggingGPT, an LLM-powered agent that leverages LLMs (e.g., ChatGPT) to connect various AI models in machine learning communities (e.g., Hugging Face) to solve AI tasks. Specifically, we use ChatGPT to conduct task planning when receiving a user request, select models according to their function descriptions available in Hugging Face, execute each subtask with the selected AI model, and summarize the response according to the execution results. By leveraging the strong language capability of ChatGPT and abundant AI models in Hugging Face, HuggingGPT can tackle a wide range of sophisticated AI tasks spanning different modalities and domains and achieve impressive results in language, vision, speech, and other challenging tasks, which paves a new way towards the realization of artificial general intelligence.",
        "LoG1cSeG: Parsing Visual Semantics with Neural Logic Learning and Reasoning": "Current high-performance semantic segmentation models are purely data-driven sub-symbolic approaches and blind to the structured nature of the visual world. This is in stark contrast to human cognition which abstracts visual percep-. tions at multiple levels and conducts symbolic reasoning with such structured abstraction. To fill these fundamental gaps, we devise LoGicSeG, a holistic visual semantic parser that integrates neural inductive learning and logic reasoning with both rich data and symbolic knowledge. In particular, the semantic concepts of interest are structured as a hierarchy, from which a set of constraints are derived for describing the symbolic relations and formalized as first-order logic rules. After fuzzy logic-based continuous relaxation, logical formulae are grounded onto data and neural computational graphs, hence enabling logic-induced network training. During inference, logical constraints are packaged into an iterative process and injected into the network in a form of several matrix multiplications, so as to achieve hierarchy-coherent prediction with logic reasoning. These designs together make LoGicSEG a general and compact neural-logic machine that is readily integrated into existing segmentation models.. Extensive experiments over four datasets with various segmentation models and backbones verify the effectiveness and generality of LoGicSEG. We believe this study opens a new avenue for visual semantic parsing.",
        "Hierarchical Human Parsing with Typed Part-Relation Reasoning": "Human parsing is for pixel-wise human semantic understanding. As human bodies are underlying hierarchically structured, how to model human structures is the central theme in this task. Focusing on this, we seek to simultaneously exploit the representational capacity of deep graph networks and the hierarchical human structures.  In particular, we provide following two contributions. First, three kinds of part relations, i.e., decomposition, composition, and dependency, are, for the first time, completely and precisely described by three distinct rela tion networks. This is in stark contrast to previous parsers, which only focus on a portion of the relations and adopt a type-agnostic relation modeling strategy. More expressive relation information can be captured by explicitly imposing the parameters in the relation networks to satisfy the specific characteristics of different relations. Second, previous parsers largely ignore the need for an approximation algorithm over the loopy human hierarchy, while we instead address an iterative reasoning process, by assimilating generic message-passing networks with their edgetyped, convolutional counterparts. With these efforts, our parser lays the foundation for more sophisticated and flexible human relation patterns of reasoning. Comprehensive experiments on five datasets demonstrate that our parser sets a new state-of-the-art on each..",
        "Learning Compositional Neural Information Fusion for Human Parsing": "This work proposes to combine neural networks with the compositional hierarchy of human bodies for efficient and complete human parsing. We formulate the approach as a neural information fusion framework. Our model assembles the information from three inference processes over the. hierarchy: direct inference (directly predicting each part of. a human body using image information), bottom-up inference (assembling knowledge from constituent parts), and top-down inference (leveraging context from parent nodes). The bottom-up and top-down inferences explicitly model the compositional and decompositional relations in human. bodies, respectively. In addition, the fusion of multi-source information is conditioned on the inputs, i.e., by estimating and considering the confidence of the sources. The whole model is end-to-end differentiable, explicitly modeling information flows and structures. Our approach is extensively evaluated on four popular datasets, outperforming the state-of-the-arts in all cases, with a fast processing speed of 23fps. Our code and results have been released to help ease future research in this direction."
    }
}