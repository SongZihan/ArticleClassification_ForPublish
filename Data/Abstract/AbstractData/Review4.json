{
    "Explainability and Trustworthiness": {
        "Braid: Weaving Symbolic and Neural Knowledge into Coherent Logical Explanations": "Traditional symbolic reasoning engines, while attractive for their precision and explicability, have a few major drawbacks: the use of brittle inference procedures that rely on exact matching (unification) of logical terms, an inability to deal. with uncertainty, and the need for a precompiled rule-base of knowledge (the \"knowledge acquisition' problem). To address these issues, we devise a novel logical reasoner called Braid, that supports probabilistic rules, and uses the notion of custom unification functions and dynamic rule generation to overcome the brittle matching and knowledge-gap problem prevalent in traditional reasoners. In this paper, we describe the reasoning algorithms used in Braid, and their implementation in a distributed task-based framework that builds proof/- explanation graphs for an input query. We use a simple QA example from a children's story to motivate Braid's design and explain how the various components work together to produce a coherent logical explanation. Finally, we evaluate Braid on the ROC Story Cloze test and achieve close to stateof-the-art results while providing frame-based explanations.",
        "Structure-Aware Abstractive Conversation Summarization via Discourse and Action Graphs": "Abstractive conversation summarization has received much attention recently. However, these generated summaries often suffer from insufficient, redundant, or incorrect content, largely due to the unstructured and complex characteristics of human-human interactions. To this end, we propose to explicitly model the rich structures in conversations for more precise and accurate conversation summarization, by first incorporating discourse relations between utterances and action triples (\"wHODOING-wHAT\") in utterances through structured graphs to better encode conversations, and then designing a multi-granularity decoder to generate summaries by combining all levels of information. Experiments show that our proposed models outperform state-of-theart methods and generalize well in other domains in terms of both automatic evaluations and human judgments. We have publicly releasedour code at https: //github. com/ GT-SALT/Structure-Aware-BART.",
        "FAcTPEGASUS: Factuality-Aware Pre-training and Fine-tuning for Abstractive Summarization": "We present FAcTPEGASUS, an abstractive summarization model that addresses the problem of factuality during pre-training and finetuning: (1) We augment the sentence selec-. tion strategy of PEGASUS's (Zhang et al.,. 2020) pre-training objective to create pseudosummaries that are both important and factual; (2) We introduce three complementary components for fine-tuning. The corrector removes hallucinations present in the reference summary, the contrastor uses contrastive learning to better differentiate nonfactual summaries. from factual ones, and the connector bridges the gap between the pre-training and fine-. tuning for better transfer of knowledge. Exper-. iments on three downstream tasks demonstrate that FAcTPEGASUS substantially improves factuality evaluated by multiple automatic metrics and humans. Our thorough analysis suggests that FAcTPEGASUS is more factual than using the original pre-training objective in zero-shot and few-shot settings, retains factual behavior more robustly than strong baselines, and does not rely entirely on becoming more extractive to improve factuality.'",
        "Do Androids Laugh at Electric Sheep? Humor \"Understanding\"' Benchmarks from The New Yorker Caption Contest.": "Large neural networks can now generate jokes, but do they really \"understand\"' humor? We challenge AI models with three tasks derived from the New Yorker Cartoon Caption Contest: matching a joke to a cartoon, identifying a winning caption, and explaining why a winning caption is funny. These tasks encapsulate progressively more sophisticated aspects of \"understanding\" a cartoon; key elements are the complex, often surprising relationships between images and captions and the frequent inclusion of indirect and playful allusions to human experience and culture. We investigate both multimodal and language-only models: the former are challenged with the cartoon images directly, while the latter are given multifaceted descriptions of the visual scene to simulate human-level visual understanding. We find that both types of models struggle at all three tasks.  For example, our best multimodal models fall 30 accuracy points. behind human performance on the matching. task, and, even when provided ground-truth visual scene descriptors, human-authored explanations are preferred head-to-head over the best machine-authored ones (few-shot GPT-4) in more than 2/3 of cases. We release models, code, leaderboard, and corpus, which includes newly-gathered annotations describing the image's locations/entities, what's unusual in the scene, and an explanation of the joke.",
        "Enhancing Multi-Domain Automatic Short Answer Grading through an Explainable Neuro-Symbolic Pipeline": "Grading short answer questions automatically with interpretable reasoning behind the grading decision is a challenging goal for current transformer approaches. Justification cue detection, in combination with logical reasoners, has shown a promising direction for neurosymbolic architectures in Automatic Short Answer Grading (ASAG). But, one of the main challenges is the requirement of annotated justification cues in the students' responses, which only exist for a few ASAG data sets. To overcome this challenge, we contribute (1) a weakly supervised annotation procedure for justifica-. tion cues in ASAG datasets, and (2) a neurosymbolic model for explainable ASAG based on justification cues. Our approach improves upon the RMSE by 0.24 to 0.3 compared to the state-of-the-art on the Short Answer Feedback dataset in a bilingual, multi-domain, and multiquestion training setup. This result shows that our approach provides a promising direction for. generating high-quality grades and accompanying explanations for future research in ASAG and educational NLP."
    },
    "Knowledge Representation": {
        "(COMET-)ATOMIC: On Symbolic and Neural Commonsense Knowledge Graphs": "Recent years have brought about a renewed interest in commonsense representation and reasoning in the field of natural language understanding. The development of new commonsense knowledge graphs (CSKG) has been central to these. advances as their diverse facts can be used and referenced by machine learning models for tackling new and challeng-. ing tasks. At the same time, there remain questions about the quality and coverage of these resources due to the massive scale required to comprehensively encompass general commonsense knowledge.  \n\nIn this work, we posit that manually constructed CSKGs will never achieve the coverage necessary to be applicable in all situations encountered by NLP agents. Therefore, we propose a new evaluation framework for testing the utility of KGs based on how effectively implicit knowledge representations can be learned from them.  \n\nWith this new goal, we propose AromIC $^{20}_{\\cdot20}$ a new CSKG of general-purpose commonsense knowledge containing knowledge that is not readily available in pretrained language models. We evaluate its properties in comparison with other lead-. ing CSKGs, performing the first large-scale pairwise study of commonsense knowledge resources. Next, we show that ATOMIC $^{20}_{20}$ is better suited for training knowledge models. that can generate accurate, representative knowledge for new, unseen entities and events. Finally, through human evaluation, we show that the few-shot performance of GPT-3 (175B parameters), while impressive, remains. ${\\sim}12$ absolute points lower than a BART-based knowledge model trained on. ATOMIC $^{20}_{20}$ despite using over $430\\mathbf{x}$ fewer parameters.",
        "GLUCOSE: GeneraLized and COntextualized Story Explanations": "When humans read or listen, they make implicit commonsense inferences that frame their understanding of what happened and why. As a step toward AI systems that can build similar mental models, we introduce GLUCOSE, a large-scale dataset of implicit commonsense causal knowledge, encoded as causal minitheories about the world, each grounded in a narrative context.  To construct GLUCOSE, we drew on cognitive psychology to identify ten dimensions of causal explanation, focusing on events, states, motivations, and emotions. Each GLUCOSE entry includes a storyspecific causal statement paired with an inference rule generalized from the statement. This paper details two concrete contributions. First, we present our platform for effectively crowdsourcing GLUCOSE data at scale, which uses semi-structured templates to elicit causal explanations. Using this platform, we collected a total of $\\widetilde{\\mathrm{670K}}$ specific statements and general rules that capture implicit commonsense knowledge about everyday situations. Second, we show that existing knowledge resources and pretrained language models do not include or readily predict GLUCOSE's rich inferential content. However, when state-of-the-art neural models are trained on this knowledge, they can start to make commonsense inferences on unseen stories that match humans' mental models.",
        "? kogito: A Commonsense Knowledge Inference Toolkit": "In this paper, we present kogito, an opensource tool for generating commonsense inferences about situations described in text. kogito provides an intuitive and extensible interface to interact with natural language generation models that can be used for hypothesizing commonsense knowledge inference from a textual input. In particular, kogito offers several features for targeted, multi-granularity knowledge generation. These include a standardized API for training and evaluating knowledge models, and generating and filtering inferences from them. We also include helper functions for converting natural language texts into a format ingestible by knowledge models -- intermediate pipeline stages such as knowledge head extraction from text, heuristic and model-based knowledge head-relation matching, and an ability to define and use custom knowledge relations. We make the code for kogito available at https://github.com/epflnlp/kogito along with thorough documentation at https://kogito.readthedocs.io.",
        "QALD-9-plus: A Multilingual Dataset for Question Answering over DBpedia and Wikidata. Translated by Native Speakers.": "QALD-9-plus: A Multilingual Dataset for Question Answering over DBpedia and Wikidata. Translated by Native Speakers.  \n\nAleksandr Perevalov Department of Computer Science and Languages Anhalt University of Applied Sciences Kothen (Anhalt), Germany Email: aleksandr.perevalov $@$ hs-anhalt.de  \n\nDennis Diefenbach Laboratoire Hubert Curien CNRS UMR 5516 Universite de Lyon, France. Email: dennis.diefenbach $@$ univ-st-etienne.fr  \n\nRicardo Usbeck Department of Informatics University of Hamburg Hamburg, Germany Email: ricardo.usbeck @uni-hamburg.de  \n\nAndreas Both Department of Computer Science and Languages Anhalt University of Applied Sciences. Kothen (Anhalt), Germany. Email: andreas.both $@$ hs-anhalt.de  \n\nAbstract-The ability to have the same experience for different user groups (i.e., accessibility) is one of the most important characteristics of Web-based systems. The same is true for Knowledge Graph Question Answering (KGQA) systems that provide the access to Semantic Web data via natural language interface. While following our research agenda on the multilingual aspect of accessibility of KGQA systems, we identified several ongoing challenges. One of them is the lack of multilingual KGQA benchmarks. In this work, we extend one of the most popular KGQA benchmarks - QALD-9 by introducing highquality questions' translations to 8 languages provided by native speakers, and transferring the SPARQL queries of QALD-9 from DBpedia to Wikidata, s.t., the usability and relevance of the dataset is strongly increased. Five of the languages - Armenian, Ukrainian, Lithuanian, Bashkir and Belarusian - to our best knowledge were never considered in KGQA research community before. The latter two of the languages are considered as \"endangered' by UNESCO. We call the extended dataset QALD-9-plus and made it available online'..",
        "NeuroQL: A Neuro-Symbolic Language and Dataset for Inter-Subjective Reasoning": "We present a new AI task and baseline solution for Inter-Subjective Reasoning. We define inter-subjective information, to be a mixture of objective and subjective information possibly shared by different parties. Examples may include commodities and their objective properties as reported by IR (Information Retrieval) systems, that need to be cross-referenced with subjective user reviews from an online forum. For an AI system to successfully reason about both, it needs to be able to. combine symbolic reasoning of objective facts with the shared consensus found on subjective user reviews. To this end we introduce the NeuroQL dataset and DSL (Domain-specific Language) as a baseline solution for this problem. NeuroQL is a neuro-symbolic language that extends logical unification with neural primitives for extraction and retrieval. It can function as a target for automatic translation of inter-subjective questions (posed in natural language) into the neuro-symbolic code that can answer them.",
        "RECKoNInG: Reasoning through Dynamic Knowledge Encoding": "Recent studies on transformer-based language models show that they can answer. questions by reasoning over knowledge provided as part of the context (i.e., incontext reasoning). However, since the available knowledge is often not filtered for a particular question, in-context reasoning can be sensitive to distractor facts, additional content that is irrelevant to a question but that may be relevant for a different question (i.e., not necessarily random noise). In these situations, the model fails to. distinguish the necessary knowledge to answer the question, leading to spurious reasoning and degraded performance. This reasoning failure contrasts with the model's apparent ability to distinguish its contextual knowledge from all the knowl-. edge it has memorized during pre-training. Following this observation, we propose teaching the model to reason more robustly by folding the provided contextual knowledge into the model's parameters before presenting it with a question. Our method, REckoNING, is a bi-level learning algorithm that teaches language models to reason by updating their parametric knowledge through back-propagation, allowing them to answer questions using the updated parameters. During training, the inner loop rapidly adapts a copy of the model weights to encode contextual. knowledge into its parameters. In the outer loop, the model learns to use the updated weights to reproduce and answer reasoning questions about the memorized knowledge. Our experiments on three diverse multi-hop reasoning datasets show that RECkoNING's performance improves over the in-context reasoning baseline (by up to $4.5\\%$ ). We also find that compared to in-context reasoning, REckoNING. generalizes better to longer reasoning chains unseen during training, is more robust to distractors in the context, and is computationally more efficient when multiple questions are asked about the same knowledge.",
        "Combining Analogy with Language Models for Knowledge Extraction": "Learning structured knowledge from natural language text has been a long-standing. challenge. Previous work has focused on specific domains, mostly extracting knowledge about named entities (e.g. countries, companies, or persons) instead of general-purpose world knowledge (e.g. information about science or everyday objects). In this paper we combine the Companion Cognitive Architecture with the BERT Language Model to extract structured knowledge from text, with the goal of automatically inferring missing commonsense facts from an existing knowledge base. Using the principles of distant supervision, the system learns functions called query cases that map statements expressed in natural language into knowledge base relations. Afterwards, the system uses such query cases to extract structured knowledge using analogical reasoning. We run experiments on 2,679 Simple English Wikipedia articles, where the system is able to learn high precision facts about a variety of subjects from a few training examples, outperforming strong baselines."
    },
    "Learning and Inference": {
        "Generating Data to Mitigate Spurious Correlations in Natural Language Inference Datasets": "Natural language processing models often exploit spurious correlations between taskindependent features and labels in datasets to perform well only within the distributions they are trained on, while not generalising to different task distributions.We propose to tackle this problem by generating a debiased version of a dataset, which can then be used to train a debiased, off-the-shelf model,. by simply replacing its training data. Our approach consists of 1) a method for training data generators to generate high-quality, label-consistent data samples; and 2) a filtering mechanism for removing data points that. contribute to spurious correlations, measured in terms of. $z_{i}$ -statistics. We generate debiased. versions of the SNLI and MNLI datasets,' and we evaluate on a large suite of debiased, outof-distribution, and adversarial test sets. Results show that models trained on our debiased datasets generalise better than those trained on. the original datasets in all settings. On the ma-. jority of the datasets, our method outperforms or performs comparably to previous state-ofthe-art debiasing strategies, and when combined with an orthogonal technique, productof-experts, it improves further and outperforms previous best results of SNLI-hard and MNLI-hard.",
        "Tallor: Generating and Perturbing Text with Semantic Controls": "Controlled text perturbation is useful for evaluating and improving model generalizability. However, current techniques rely on training a model for every target perturbation, which is expensive and hard to generalize. We present TAor, a semantically-controlled text generation system. TAnor builds on a pretrained seq2seq model and produces textual outputs conditioned on control codes derived from semantic representations. We craft a set of operations to modify the control codes, which in turn steer generation towards targeted attributes. These operations can be further composed into higher-level ones, allowing for flexible perturbation strategies. We demonstrate the effectiveness of these perturbations in multiple applications. First, we use TAnor to automatically create high-quality contrast sets for four distinct natural language processing (NLP) tasks. These contrast sets contain fewer spurious artifacts and are complementary to manually annotated ones in their lexical diversity. Second, we show that TAnor perturbations can improve model generalization through data augmentation. Perturbing just ${\\sim}2\\%$ of training data leads to a 5.8-point gain on an NLI challenge set measuring reliance on syntactic heuristics.",
        "Hierarchical Motion Understanding via Motion Programs": "Current approaches to video analysis of human motion focus on raw pixels or keypoints as the basic units of reasoning. We posit that adding higher-level motion primitives, which can capture natural coarser units of motion such as \"backswing\" or \"follow-through\", can be used to improve downstream analysis tasks. This higher level of abstraction can also capture key features, such as loops of repeated primitives, that are currently inaccessible at lower levels of representation. We therefore introduce Motion Programs, a neuro-symbolic, program-like representation that expresses motions as a composition of high-level primitives. We also present a system for automatically inducing motion programs from videos of human motion and for leveraging motion programs in video synthesis. Experiments show that motion programs can accurately describe a diverse set of human motions and the inferred programs contain semantically meaningful motion primitives, such as arm swings and jumping jacks. Our representation also benefits downstream tasks such as video interpolation and video prediction and outperforms off-the-shelf models. We further demonstrate how these programs can detect diverse kinds of repetitive motion and facilitate interactive video editing.",
        "Scaling Up Models and Data with t5x and seqio": "Recent neural network-based language models have benefited greatly from scaling up the size of training datasets and the number of parameters in the models themselves. Scaling. can be complicated due to various factors including the need to distribute computation on. supercomputer clusters (e.g., TPUs), prevent bottlenecks when infeeding data, and ensure. reproducible results. In this work, we present two software libraries that ease these issues:. t5x simplifies the process of building and training large language models at scale while maintaining ease of use, and seqio provides a task-based API for simple creation of fast and reproducible training data and evaluation pipelines. These open-source libraries have been used to train models with hundreds of billions of parameters on datasets with multiple. terabytes of training data. Along with the libraries, we release configurations and instructions for T5-like encoder-decoder models as well as GPT-like decoder-only architectures..  \n\nt5x and seqio are open source and available at https: //github. com/google-research/ t5x and https://github. com/google/seqio, respectively..  \n\nKeywords: Large language models, data parallelism, model parallelism, data processing",
        "Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models": "Language models demonstrate both quantitative improvement and new qualitative capabilities with increasing scale. Despite their potentially transformative impact, these new capabilities are as yet poorly characterized. In order to inform future research, prepare for disruptive new model capabilities, and ameliorate socially harmful effects, it is vital that we understand the present and near-future capabilities and limitations of language models.  \n\nTo address this challenge, we introduce the Beyond the Imitation Game benchmark (BIGbench). BIG-bench currently consists of 204 tasks, contributed by 450 authors across 132. institutions. Task topics are diverse, drawing problems from linguistics, childhood development, math, common-sense reasoning, biology, physics, social bias, software development, and beyond. BIG-bench focuses on tasks that are believed to be beyond the capabilities of current language models. We evaluate the behavior of OpenAI's GPT models, Googleinternal dense transformer architectures, and Switch-style sparse transformers on BIG-bench,. across model sizes spanning millions to hundreds of billions of parameters. In addition, a team of human expert raters performed all tasks in order to provide a strong baseline. Findings include: model performance and calibration both improve with scale, but are poor in absolute terms (and when compared with rater performance); performance is remarkably similar across model classes, though with benefits from sparsity; tasks that improve gradually and predictably commonly involve a large knowledge or memorization component, whereas tasks that exhibit \"breakthrough\" behavior at a critical scale often involve multiple steps or components, or brittle metrics; social bias typically increases with scale in settings with ambiguous context, but this can be improved with prompting.",
        "Compositional diversity in visual concept learning": "Humans leverage compositionality to efficiently learn new concepts, understanding how familiar parts can combine together to form novel objects. In contrast, popular computer vision models struggle to make the same types of inferences, requiring more data and generalizing. less flexibly than people do. Here, we study these distinctively human abilities across a range of different types of visual composition, examining how people classify and generate \"alien figures\" with rich relational structure. We also develop a Bayesian program induction model which searches for the best programs for generating the candidate visual figures, utilizing a large program space containing different compositional mechanisms and abstractions. In few shot classification tasks, we find that people and the program induction model can make a range of meaningful compositional generalizations, with the model providing a strong account. of the experimental data as well as interpretable parameters that reveal human assumptions about the factors invariant to category membership (here, to rotation and changing part attachment). In few shot generation tasks, both people and the models are able to construct compelling novel examples, with people behaving in additional structured ways beyond the model capabilities, e.g. making choices that complete a set or reconfiguring existing parts in highly novel ways. To capture these additional behavioral patterns, we develop an alternative model based on neuro-symbolic program induction: this model also composes new concepts from existing parts yet, distinctively, it utilizes neural network modules to successfully capture residual statistical structure. Together, our behavioral and computational findings show how people and models can produce a rich variety of compositional behavior when classifying and generating visual objects.  \n\nKeywords: concept learning; Bayesian inference; few-shot learning; visual learning; compositionality; neuro-symbolic models.",
        "Exploiting Language Models as a Source of Knowledge for Cognitive Agents": "Large language models (LLMs) provide capabilities far beyond sentence completion, including question answering, summarization, and natural-language inference. While many. of these capabilities have potential application to cognitive systems, our research is exploiting language models as a. source of task knowledge for cognitive agents, that is, agents realized via a cognitive architecture. We identify challenges and opportunities for using language models as an external knowledge source for cognitive systems and possible ways to improve the effectiveness of knowledge extraction by integrating extraction with cognitive architecture capabilities, highlighting with examples from our recent work in this area.",
        "Learning Neuro-Symbolic World Models with Logical Neural Networks": "Model-based reinforcement learning has shown great results when using deep neural networks for learning world models. However, these results are not directly applicable to many real-world problems that require explainable models and where training data is limited. A more suitable problem setting that can address these issues is relational modelbased reinforcement learning where a logical world model is learned. In this setting, we propose to use Logical Neural Networks (LNN) which enable the scalable learning of logical rules. Our method builds around the LNN by creating a framework for learning lifted logical operator models. This is used together with object-centric perception modules and AI planners that reason about the learned logical world model. We first test our agent by comparing the LNN-learned models against the existing handcrafted models which are available in the PDDLGym environments. For these tests, we show that our agent performs optimally and is on-par with planning on expert-crafted models. We then further test our agent in a textbased game domain called TextWorld-Commonsense where expert-crafted models are not available. For this domain, deep reinforcement learning agents are the state-of-the-art and we showed that we significantly outperform all of the existing agents.",
        "A Proposal for a Language Model Based Cognitive Architecture": "Large Language Models (LLMs) have shown impressive performance on a wide variety of tasks. However, apparent limitations hinder their performance, especially on tasks that require multiple steps of reasoning or compositionality. Ar-. guably, the primary sources of these limitations are the decoding strategy and how the models are trained. We propose, and provide a general description of, an architecture that combines LLMs and cognitive architectures, called Language Model based Cognitive Architecture (LMCA), to overcome. these limitations. We draw an analogy between this architecture and \"fast\"' and \"slow\" thinking in human cognition..",
        "Active Learning Improves Performance on Symbolic Regression Tasks in StackGP": "This paper introduces an active learning method for symbolic regression using StackGP. The approach begins with a small number of data points for StackGP to model. To improve the model the. system incrementally adds the data point characterized by maxi-. mizing prediction uncertainty as measured by the model ensemble.. Symbolic regression is re-run with the larger data set. This cycle continues until the system satisfies a termination criterion. The Feynman AI benchmark set of equations is used to examine the. ability of the method to find appropriate models using as few data points as possible. The approach successfully rediscovered 72 of the 100 Feynman equations without the use of domain expertise or. data translation.",
        "Active Learning Informs Symbolic Regression Model Development in Genetic Programming.": "Active learning for genetic programming using model ensemble uncertainty was explored across a range of uncertainty metrics to determine if active learning can be used with GP to minimize training set sizes by selecting maximally informative samples to guide evolution. The choice of uncertainty metric was found to have a significant impact on the success of active learning to inform model development in genetic programming. Differential evolution was found to be an effective optimizer, likely due to the non-convex nature of the uncertainty space, while differential entropy was found to be an effective uncertainty metric. Uncertainty-based active learning was compared to two random sampling methods and the results show that active learning successfully identified informative samples and can be used with GP to reduce required training set sizes to arrive at a solution.",
        "P1an-soFAI: A Neuro-Symbolic Planning Architecture": "The notion of Artificial Intelligence (AI) has garnered sig-. nificant attention in recent years and AI-based tools have increasingly become integrated into our daily lives. As this strand of research is gaining traction, one of the central debates is whether end-to-end Machine Learning or symbolic AI approaches alone can lead to an effective AI model, or if these techniques need to be integrated into a synergistic system. We believe the integration route to be the most promising. To this end, we introduce a specialization of a neurosymbolic architecture, known as SOFAI (Slow and Fast AI), inspired by the cognitive framework popularized by D. Kahneman's book \"Thinking, Fast and Slow\". Our system, referred to as Plan-sOFAI, aims to tackle planning problems across a large spectrum of scenarios, with a specific focus on the classical setting. P1an-SOFAI leverages multiple planning approaches, each possessing distinct characteristics. and categorized as either fast or slow while incorporating a metacognitive process for governance. Finally, we evaluated the performance of this system against state-of-the-art planners, demonstrating that our exhibits a solid balance between solving speed and plans' optimality..",
        "Nessy: a Neuro-Symbolic System for Label Noise Reduction": "Nessy: a Neuro-Symbolic System for Label Noise Reduction  \n\nAlisa Smirnova, Jie Yang, Dingqi Yang and Philippe Cudre-Mauroux  \n\nAbstract-Noisy labels represent one of the key issues in supervised machine learning. Existing work for label noise reduction mainly. takes a probabilistic approach that infers true labels from data distributions in low-level feature spaces. Such an approach is not only. limited by its capability to learn high-quality data representations, but also by the low predictive power of data distributions in inferring. true classes. To address those problems, we introduce Nessy, a neuro-symbolic system that integrates deep probabilistic modeling and symbolic knowledge for label noise reduction. Our deep probabilistic model infers the true classes of data instances with noisy Iabels by exploiting data distributions in an underlying latent feature representation space. For data instances where inference is not reliable enough, Nessy extracts symbolic rules and ranks them according to several utility metrics. Top-ranking rules are injected into the deep probabilistic model via expectation regularization, i.e., via a posterior regularization term constraining the class distribution in. the objective function. In a real deployment over multiple relation extraction tasks, we demonstrate that Nessy is able to significantly. improve the state of the art, by $7\\%$ accuracy and $10.7\\%$ AUC on average.  \n\nIndex Terms-noise reduction, neuro-symbolic systems, deep probabilistic model, relation extraction, distant supervision",
        "Not All Memories are Created Equal: Learning to Forget by Expiring": "Attention mechanisms have shown promising results in sequence modeling tasks that require longterm memory. Recent work investigated mechanisms to reduce the computational cost of preserving and storing memories (Rae et al., 2020). However, not all content in the past is equally important to remember. We propose Expire-Span, a method that learns to retain the most important information and expire the irrelevant information. This forgetting of memories enables Transformers to scale to attend over tens of thousands of previous timesteps efficiently, as not all states from previous timesteps are preserved. We demonstrate that Expire-Span can help models identify and retain critical information and show it can achieve strong performance on reinforcement learning tasks specifically designed to challenge this functionality. Next, we show that Expire-Span can scale to memories that are tens of thousands in size, setting a new state of the art on incredibly long context tasks such as character-level language modeling and a frame-by-frame moving objects task. Finally, we analyze the efficiency of Expire-Span compared to existing approaches and demonstrate that it trains faster and uses less memory.  \n\nSukhbaatar et al., 2019a). However, a critical component of human memory is not just the ability to remember, but also forgetting irrelevant information to focus on the salient, relevant bits. Most studies of long-term memory in humans indicate that not everything is remembered (Murre & Dros, 2015; Bahrick et al., 2008) - instead, only vivid, remarkable memories are retained from the far past (Wixted, 2004).  \n\nStandard Transformer architectures lack the ability to search over extremely large memories, as the self-attention mechanism is computationally intensive and the storage cost of preserving the large memory grows quickly. Recent. work (Child et al., 2019; Rae et al., 2020) has proposed learning how to extend to greater context through sparse mechanisms or through compression, to more compactly represent the past. However, there exists a fundamental problem with large memories beyond strict computational concerns: as the amount of information stored increases, deciding which information is relevant becomes more challenging. Other work (Lample et al., 2019) approaches this by considering how to efficiently search large memories. We focus on an efficient way to learn what to forget, thereby reducing the computational burden of the model and easing the challenges of the search problem."
    },
    "Logic and Reasoning": {
        "Original software publication": "To date, logic-based technologies are either built on top or as extensions of the Prolog language, mostly working as monolithic solutions tailored upon specific inference procedures, unification mechanisms, or knowledge representation techniques. Instead, to maximise their impact, logic-based technologies should support and enable the general-purpose exploitation of all the manifold contributions from logic programming. Accordingly, we present 2P-Kr, a reboot of the tuProlog project offering a general, extensible, and interoperable ecosystem for logic programming and symbolic AI.  \n\n$\\mathbb{G}2021$ The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).",
        "Logical Credal Networks": "This paper introduces Logical Credal Networks, an expressive probabilistic logic that generalizes many prior models that combine logic and probability. Given imprecise information represented by probability bounds and conditional probability bounds of logic formulas, this logic specifies a set of probability distributions over all interpretations. On the one hand, our approach allows propositional and first-order logic formulas with few restrictions, e.g., without requiring. acyclicity. On the other hand, it has a Markov condition similar to Bayesian networks and Markov random fields that is critical in real-world applications. Having both these prop-. erties makes this logic unique, and we investigate its performance on maximum a posteriori inference tasks, including solving Mastermind games with uncertainty and detecting credit card fraud. The results show that the proposed method outperforms existing approaches, and its advantage lies in ag-. gregating multiple sources of imprecise information..",
        "NEURO-SYMBOLIC FORWARD REASONING": "Reasoning is an essential part of human intelligence and thus has been a long-. standing goal in artificial intelligence research. With the recent success of deep learning, incorporating reasoning with deep learning systems, i.e., neuro-symbolic AI has become a major field of interest. We propose the Neuro-Symbolic Forward Reasoner (NSFR), a new approach for reasoning tasks taking advantage of differentiable forward-chaining using first-order logic. The key idea is to combine differentiable forward-chaining reasoning with object-centric (deep) learning. Dif-. ferentiable forward-chaining reasoning computes logical entailments smoothly, i.e., it deduces new facts from given facts and rules in a differentiable manner. The object-centric learning approach factorizes raw inputs into representations in terms of objects. Thus, it allows us to provide a consistent framework to perform the forward-chaining inference from raw inputs. NSFR factorizes the raw inputs into the object-centric representations, converts them into probabilistic ground atoms, and finally performs differentiable forward-chaining inference using weighted rules for inference. Our comprehensive experimental evaluations on object-centric reasoning data sets, 2D Kandinsky patterns and 3D CLEVR-Hans, and a variety of tasks show the effectiveness and advantage of our approach.",
        "Large Language Models Are Neurosymbolic Reasoners": "A wide range of real-world applications is characterized by their symbolic nature, necessitating a strong capability for symbolic reasoning. This paper investigates the potential application of Large Language Models (LLMs) as symbolic reasoners. We focus on text-based games, significant benchmarks for agents with natural language capabilities, particularly in symbolic tasks like math, map reading, sorting, and applying common sense in text-based worlds. To facilitate these agents, we propose an LLM agent designed to tackle symbolic challenges and achieve in-game objectives. We begin by initializing the LLM agent and informing it of its role. The agent then receives observations and a set of valid actions from the text-based games, along with a specific symbolic module. With these inputs, the LLM agent chooses an action. and interacts with the game environments. Our experimental results demonstrate that our method significantly enhances the capability of LLMs as automated agents for symbolic reasoning, and our LLM agent is effective in text-based games involving symbolic tasks, achieving an average performance of $88\\%$ across all tasks.",
        "SPPL: Probabilistic Programming with Fast Exact Symbolic Inference": "We present the Sum-Product Probabilistic Language (SPPL), a new probabilistic programming language that automatically delivers exact solutions to a broad range of probabilistic inference queries. Spp1 translates probabilistic programs into sum-product expressions, a new symbolic representation and associated semantic domain that extends standard sumproduct networks to support mixed-type distributions, numeric transformations, logical formulas, and pointwise and set-valued constraints. We formalize SppL via a novel translation strategy from probabilistic programs to sum-product expressions and give sound exact algorithms for conditioning on and computing probabilities of events. Spp1 imposes a collection of restrictions on probabilistic programs to ensure they can be translated into sum-product expressions, which allow the system to leverage new techniques for improving the scalability of translation and inference by automatically exploiting probabilistic structure. We implement a prototype of Spp1 with a modular architecture and evaluate it on benchmarks the system targets, showing that it obtains up to $3500\\mathrm{x}$ speedups over state-of-the-art symbolic systems on tasks such as verifying the fairness of decision tree classifiers, smoothing hidden Markov models, conditioning transformed random variables, and computing rare event probabilities.  \n\nCCS Concepts: . Mathematics of computing $\\rightarrow P r o b a-$ bilistic representations; Probabilistic inference problems $\\bullet$ Software and its engineering $\\to$ Formal language definitions.  \n\nKeywords: probabilistic programming, symbolic execution",
        "SoISEE: A Source-Level Symbolic Execution Engine for Solidity": "Most of the existing smart contract symbolic execution tools perform analysis on bytecode, which loses high-level semantic information presented in source code. This makes interactive analysis. tasks--such as visualization and debugging--extremely challenging, and significantly limits the tool usability. In this paper, we present So1SEE, a source-level symbolic execution engine for So-. lidity smart contracts. We describe the design of So1SEE, highlight its key features, and demonstrate its usages through a Web-based. user interface. So1SEE demonstrates advantages over other existing source-level analysis tools in the advanced Solidity language features it supports and analysis flexibility. A demonstration video is available at: https://sites.google.com/view/solsee/.",
        "Toward Programming Languages for Reasoning: Humans, Symbolic Systems, and AI Agents": "Integration, composition, mechanization, and AI assisted development are the driving themes in the future of software development. At their core these concepts are rooted in the increasingly important role of computing in our world, the desire to deliver functionality faster, with higher quality,. and to empower more people to benefit from programmatic automation. These themes, and how they impact the human developers driving them, are the foundations for the next generation of programming languages. At first glance the needs of mechanization tools, AI agents, and human developers along with the various goals around development velocity, software quality, and software democratization are a broad and seemingly diverse set of needs. However, at their core is a single challenge that, once resolved, enables us to make radical progress in all of these areas..  \n\nOur hypothesis is that, fundamentally, software development is a problem of reasoning about code and semantics. This is true for human developers implementing a feature, symbolic tools building models of application behaviour, and even for language based AI agents as they perform tasks. While the particular aspects of reasoning that each agent struggles with varies to some degree, they share many common themes and, surprisingly, most mainstream languages extensively employ (anti)features that make this task harder or infeasible! This paper proposes a novel approach to this challenge - instead of new language features or logical constructs, that add more complexity to what is already a problem of complexity, we propose radical simplification in the. form of the Bosoue platform and language..",
        "ULKB Logic: A HOL-Based Framework for Reasoning over Knowledge Graphs": "ULKB Logic: A HOL-Based Framework for Reasoning over Knowledge Graphs  \n\nGuilherme Lima $1(\\boxtimes)$ , Alexandre Rademaker $^{1,2}$ , and Rosario Uceda-Sosa?  \n\n1 IBM Research Brazil, Rio de Janeiro, Brazil guilherme.lima@ibm. com, alexrad@br.ibm. com $^2$ Getulio Vargas Foundation, School of Applied Mathematics, Rio de Janeiro, Brazil $^3$ IBM TJ Watson Research Center, Yorktown Heights, NY, USA rosariou@us.ibm. com  \n\nAbstract. ULKB Logic is an open-source framework written in Python for reasoning over knowledge graphs. It provides an interactive theorem prover-like environment equipped with a higher-order language similar to the one used by HOL Light. The main goal of ULKB Logic is to ease the construction of applications that combine state-of-the-art computational logic tools with the knowledge available in knowledge graphs, such as Wikidata. To this end, the framework provides APIs for fetching. statements from SPARQL endpoints and operating over the constructed theories using automated theorem provers and SMT solvers (such as the $\\mathrm{E}$ prover and Z3). In this paper, we describe the design and implementation of ULKB Logic, its interfaces for querying knowledge graphs and. calling external provers, and plans for further development..  \n\nKeywords: HOL . Python . SPARQL : Wikidat:"
    }
}