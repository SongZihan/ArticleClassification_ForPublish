{"Explainability": {"EXplainable Neural-Symbolic Learning ( X-NeSyL ) methodology to fuse deep learning representations with expert knowledge graphs: The MonuMAI cultural heritage use case": "The latest Deep Learning (DL) models for detection and classification have achieved an unprecedented performance over classical machine learning algorithms. However, DL models are black-box methods hard to debug, interpret, and certify. DL alone cannot provide explanations that can be validated by a non technical audience such as end-users or domain experts. In contrast, symbolic AI systems that convert concepts into rules or symbols \u2013 such as knowledge graphs \u2013 are easier to explain. However, they present lower generalization and scaling capabilities. A very important challenge is to fuse DL representations with expert knowledge. One way to address this challenge, as well as the performance-explainability trade-off is by leveraging the best of both streams without obviating domain expert knowledge. In this paper, we tackle such problem by considering the symbolic knowledge is expressed in form"}, "KnowledgeProcessing": {"SCALABLE NEURAL METHODS FOR REASONING WITH A SYMBOLIC KNOWLEDGE BASE": "We describe a novel way of representing a symbolic knowledge base (KB) called a sparse-matrix rei\ufb01ed KB . This representation enables neural KB inference modules that are fully differentiable, faithful to the original semantics of the KB, expressive enough to model multi-hop inferences, and scalable enough to use with realistically large KBs. The sparse-matrix rei\ufb01ed KB can be distributed across multiple GPUs, can scale to tens of millions of entities and facts, and is orders of magnitude faster than naive sparse-matrix implementations. The rei\ufb01ed KB enables very simple end-to-end architectures to obtain competitive performance on several benchmarks representing two families of tasks: KB completion, and learning semantic parsers from denotations.", "Neuro-Symbolic Continual Learning: Knowledge, Reasoning Shortcuts and Concept Rehearsal": "We introduce Neuro-Symbolic Continual Learn- ing, where a model has to solve a sequence of neuro-symbolic tasks , that is, it has to map sub- symbolic inputs to high-level concepts and com- pute predictions by reasoning consistently with prior knowledge. Our key observation is that neuro-symbolic tasks, although different, often share concepts whose semantics remains stable over time. Traditional approaches fall short: ex- isting continual strategies ignore knowledge alto- gether, while stock neuro-symbolic architectures suffer from catastrophic forgetting. We show that leveraging prior knowledge by combining neuro- symbolic architectures with continual strategies does help avoid catastrophic forgetting, but also that doing so can yield models affected by rea- soning shortcuts . These undermine the seman- tics of the acquired concepts, even when detailed prior knowledge is provided upfront and infer- ence is exact, and in turn continual performance. To overcome these issues, we introduce COOL , a COncept-level c Ontinual Learning strategy tai- lored for neuro-symbolic continual problems that acquires high-quality concepts and remembers them over time. Our experiments on three novel benchmarks highlights how COOL attains sus- tained high performance on neuro-symbolic con- tinual learning tasks in which other strategies fail.", "Neural-Symbolic Relational Reasoning on Graph Models: E\ufb00ective Link Inference and Computation from Knowledge Bases": "The recent developments and growing interest in neural-symbolic models has shown that hybrid approaches can o\ufb00er richer models for Arti\ufb01cial Intelligence. The integration of e\ufb00ective relational learn-ing and reasoning methods is one of the key challenges in this direction, as neural learning and symbolic reasoning o\ufb00er complementary characteris-tics that can bene\ufb01t the development of AI systems. Relational labellingor link prediction on knowledge graphs has become one of the main prob-lems in deep learning-based natural language processing research. More-over, other \ufb01elds which make use of neural-symbolic techniques may alsobene\ufb01t from such research endeavours. There have been several e\ufb00orts towards the identi\ufb01cation of missing facts from existing ones in knowl-edge graphs. Two lines of research try and predict knowledge relations between two entities by considering all known facts connecting them or several paths of facts connecting them. We propose a neural-symbolicgraph neural network which applies learning over all the paths by feed-ing the model with the embedding of the minimal subset of the knowl-edge graph containing such paths. By learning to produce representationsfor entities and facts corresponding to word embeddings, we show how the model can be trained end-to-end to decode these representations and infer relations between entities in a multitask approach. Our con-tribution is two-fold: a neural-symbolic methodology leverages the res-olution of relational inference in large graphs, and we also demonstrate that such neural-symbolic model is shown more e\ufb00ective than path-basedapproaches."}, "LogicalReasoning": {"Unsupervised Neural-Symbolic Integration": "Symbolic has been long considered as a language of human intelligence while neural networks have advantages of robust computation and dealing with noisy data. The integration of neural - symbolic can offer better learning and reasoning while providing a means for interpretability through the representation of symbolic knowledge. Although previous works focus intensively on supervised feedforward neural networks, little has been done for the unsupervised counterparts. In this paper we show how to integrate symbolic knowledge into unsupervised neural networks. We exemplify our approach with knowledge in different forms, including propositional logic for DNA promoter prediction and \ufb01rst - order logic for understanding family relationship.", "NEURAL LOGIC MACHINES": "We propose the Neural Logic Machine (NLM), a neural-symbolic architecture for both inductive learning and logic reasoning. NLMs exploit the power of both neural networks\u2014as function approximators, and logic programming\u2014as a symbolic processor for objects with properties, relations, logic connectives, and quantifiers. After being trained on small-scale tasks (such as sorting short arrays), NLMs can recover lifted rules, and generalize to large-scale tasks (such as sorting longer arrays). In our experiments, NLMs achieve perfect generalization in a number of tasks, from relational reasoning tasks on the family tree and general graphs, to decision making tasks including sorting arrays, finding shortest paths, and playing the blocks world. Most of these tasks are hard to accomplish for neural networks or inductive logic programming alone.", "pix2rule: End-to-end Neuro-symbolic Rule Learning": "Humans have the ability to seamlessly combine low-level visual input with high-level symbolic reasoning often in the form of recognising objects, learning relations between them and applying rules. Neuro-symbolic systems aim to bring a unifying approach to connectionist and logic-based principles for visual processing and abstract reasoning respectively. This paper presents a complete neuro-symbolic method for processing images into objects, learning relations and logical rules in an end-to-end fashion. The main contribution is a di\ufb00erentiable layer in a deep learning architecture from which symbolic relations and rules can be extracted by pruning and thresholding. We evaluate our model using two datasets: subgraph isomorphism task for symbolic rule learning and an image classi/f_ication domain with compound relations for learning objects, relations and rules. We demonstrate that our model scales beyond state-of-the-art symbolic learners and outperforms deep relational neural network architectures.", "A Semantic Framework for Neuro-symbolic Computation": "The field of neuro-symbolic AI aims to benefit from the combination of neural networks and symbolic systems. A cornerstone of the field is the translation orencoding of symbolic knowledge into neural networks. Although many neuro-symbolic methods and approaches have been proposed, and with a large increase in recent years, no common definition of encoding exists that can enable a precise, theoretical comparison of neuro-symbolic methods. This paper addresses this problem by introducing a semantic framework for neuro-symbolic AI. We start by providing a formal definition of semantic encoding, specifying the components and conditions under which a knowledge-base can be encoded correctly by a neural network. We then show that many neuro-symbolic approaches are accounted for by this definition. We provide a number of examples and correspondence proofs applying the proposed framework to the neural encoding of various forms of knowledge representation. Many, at first sight disparate, neuro-symbolic methods, are shown to fall within the proposed formalization. This is expected to provide guidance to future neuro-symbolic encodings by placing them in the broader context of semantic encodings of entire families of existing neuro-symbolic systems. The paper hopes to help initiate a discussion around the provision of a theory for neuro-symbolic AI and a semantics for deep learning.", "The Neuro-Symbolic Inverse Planning Engine (NIPE): Modeling Probabilistic Social Inferences from Linguistic Inputs": "Human beings are social creatures. We routinely reason about other agents, and a crucial component of this social reasoning is inferring people\u2019s goals as we learn about their actions. In many settings, we can perform intuitive but reliable goal inference from language descriptions of agents, actions, and the background environments. In this paper, we study this process of language driving and influencing social reasoning in a probabilistic goal inference domain. We propose a neuro-symbolic model that carries out goal inference from linguistic inputs of agent scenarios. The \u201cneuro\u201d part is a large language model (LLM) that translates language descriptions to code representations, and the \u201csymbolic\u201d part is a Bayesian inverse planning engine. To test our model, we design and run a human experiment on a linguistic goal inference task. Our model closely matches human response patterns and better predicts human judgements than using an LLM alone.", "BRIDGING LOGIC AND LEARNING : A N EURAL -SYMBOLIC APPROACH FOR ENHANCED REASONING IN NEURAL MODELS (ASPER)": "Neural-symbolic learning, an intersection of neural networks and symbolic reasoning, aims to blend neural networks\u2019 learning capabilities with symbolic AI\u2019s interpretability and reasoning. This paper introduces an approach designed to improve the performance of neural models in learning reasoning tasks. It achieves this by integrating Answer Set Programming (ASP) solvers and domain-specific expertise, which is an approach that diverges from traditional complex neural-symbolic models. In this paper, a shallow artificial neural network (ANN) is specifically trained to solve Sudoku puzzles with minimal training data. The model has a unique loss function that integrates losses calculated using the ASP solver outputs, effectively enhancing its training efficiency. Most notably, the model shows a significant improvement in solving Sudoku puzzles using only 12 puzzles for training and testing without hyperparameter tuning. This advancement indicates that the model\u2019s enhanced reasoning capabilities have practical applications, extending well beyond Sudoku puzzles to potentially include a variety of other domains. The code can be found on GitHub: https://github.com/Fadi2200/ASPEN.", "Sandra - A Neuro-Symbolic Reasoner Based On Descriptions And Situations": "This paper presents sandra , a neuro-symbolic reasoner combining vectorial representations with deductive reasoning. Sandra builds a vector space constrained by an ontology and performs reasoning over it. The geometric nature of the reasoner allows its combination with neural networks, bridging the gap with symbolic knowledge representations. Sandra is based on the Description and Situation (DnS) ontology design pattern, a formalization of frame semantics. Given a set of facts (a situation) it allows to infer all possible perspectives (descriptions) that can provide a plausible interpretation for it, even in presence of incomplete information. We prove that our method is correct with respect to the DnS model. We experiment with two different tasks and their standard benchmarks, demonstrating that, without increasing complexity, sandra (i) outperforms all the baselines (ii) provides interpretability in the classification process, and (iii) allows control over the vector space, which is designed a priori.", "SOFTENED SYMBOL GROUNDING FOR NEURO - SYMBOLIC SYSTEMS": "Neuro-symbolic learning generally consists of two separated worlds, i.e., neural network training and symbolic constraint solving, whose success hinges on symbol grounding, a fundamental problem in AI. This paper presents a novel, softened symbol grounding process, bridging the gap between the two worlds, and resulting in an effective and efficient neuro-symbolic learning framework. Technically, the framework features (1) modeling of symbol solution states as a Boltzmann distribution, which avoids expensive state searching and facilitates mutually beneficial interactions between network training and symbolic reasoning; (2) a new MCMC technique leveraging projection and SMT solvers, which efficiently samples from disconnected symbol solution spaces; (3) an annealing mechanism that can escape from sub-optimal symbol groundings. Experiments with three representative neuro-symbolic learning tasks demonstrate that, owining to its superior symbol grounding capability, our framework successfully solves problems well beyond the frontier of the existing proposals.", "Reasoning in Non-probabilistic Uncertainty: Logic Programming and Neural-Symbolic Computing as Examples": "This article aims to achieve two goals: to show that probability is not the only way of dealing with uncertainty (and even more, that there are kinds of uncertainty which are for principled reasons not addressable with probabilistic means); and to provide evidence that logic-based methods can well support reasoning with uncertainty. For the latter claim, two paradigmatic examples are presented: logic programming with Kleene semantics for modelling reasoning from information in a discourse, to an interpretation of the state of affairs of the intended model, and a neural-symbolic implementation of input/output logic for dealing with uncertainty in dynamic normative contexts.", "Approximate Reasoning for Large-Scale ABox in OWL DL Based on Neural-Symbolic Learning": "The ontology knowledge base (KB) can be divided into two parts: TBox and ABox, where the former models schema-level knowledge within the domain, and the latter is a set of statements of assertions or facts about instances. ABox reasoning is a process of discovering implicit knowledge in ABox based on the existing KB, which is of great value in KB applications. ABox reasoning is influenced by both the complexity of TBox and scale of ABox. The traditional logic-based ontology reasoning methods are usually designed to be provably sound and complete but suffer from long algorithm runtimes and do not scale well for ontology KB represented by OWL DL (Description Logic). In some application scenarios, the soundness and completeness of reasoning results are not the key constraints, and it is acceptable to sacrifice them in exchange for the improvement of reasoning efficiency to some extent. Based on this view, an approximate reasoning method for large-scale ABox in OWL DL KBs was proposed, which is named the ChunfyReasoner (CFR). The CFR introduces neural-symbolic learning into ABox reasoning and integrates the advantages of symbolic systems and neural networks (NNs). By training the NN model, the CFR approximately compiles the logic deduction process of ontology reasoning, which can greatly improve the reasoning speed while ensuring higher reasoning quality. In this paper, we state the basic idea, framework, and construction process of the CFR in detail, and we conduct experiments on two open-source ontologies built on OWL DL.", "Semantic Probabilistic Layers for Neuro-Symbolic Learning": "We design a predictive layer for structured-output prediction (SOP) that can be plugged into any neural network guaranteeing its predictions are consistent with a set of prede\ufb01ned symbolic constraints. Our Semantic Probabilistic Layer ( SPL) can model intricate correlations, and hard constraints, over a structured output space all while being amenable to end-to-end learning via maximum likelihood. SPLs combine exact probabilistic inference with logical reasoning in a clean and modular way, learning complex distributions and restricting their support to solutions of the constraint. As such, they can faithfully, and ef\ufb01ciently, model complex SOP tasks beyond the reach of alternative neuro-symbolic approaches. We empirically demonstrate that SPLs outperform these competitors in terms of accuracy on challenging SOP tasks including hierarchical multi-label classi\ufb01cation, path\ufb01nding and preference learning, while retaining perfect constraint satisfaction. Our code is made publicly available on Github at github.com/KareemYousrii/SPL.", "TGR: Neural-symbolic ontological reasoner for domain-speci\ufb01c knowledge graphs": "Ontological reasoning has great prospects in applications based on domain-speci\ufb01c knowledge graphs (KG). However, it is dif\ufb01cult for existing logic reasoners to quickly perform inference over large-scale assertional boxes (ABoxes) in domain-speci\ufb01c KGs with complex ontologies. To address this challenge, a novel method named the \u201cneural-symbolic ontological reasoner\u201d is proposed. By incorporating neural-symbolic learning into ABox reasoning, a reasoner named the TimGangReasoner (TGR) is built. The TGR synthesizes graph data using an ontology, trains an ABox reasoning network (ABRN) model, and then approximately compiles the logic reasoning process of the ontology (represented by OWL+SWRL) into neural networks (NNs). The ABRN model encodes instances into vectors and then executes parallel vector computations to accelerate ABox reasoning. Experiments conducted on three open-source complex ontologies show that the TGR can achieve high-quality approximate deductive reasoning on ABoxes. The reasoning time consumption of the TGR increases linearly with the increase in the number of assertions, providing better scalability for large-scale ABoxes. Therefore, the TGR is able to reason quickly and accurately on domain-speci\ufb01c KGs that have complex underlying ontologies and contain large-scale ABoxes.", "SATNet: Bridging deep learning and logical reasoning using a differentiable satis\ufb01ability solver": "Integrating logical reasoning within deep learning architectures has been a major goal of modern AI systems. In this paper, we propose a new direction toward this goal by introducing a differentiable (smoothed) maximum satis\ufb01ability (MAXSAT) solver that can be integrated into the loop of larger deep learning systems. Our (approximate) solver is based upon a fast coordinate descent approach to solving the semide\ufb01nite program (SDP) associated with the MAXSAT problem. We show how to analytically differentiate through the solution to this SDP and ef\ufb01ciently solve the associated backward pass. We demonstrate that by integrating this solver into end-to-end learning systems, we can learn the logical structure of challenging problems in a minimally supervised fashion. In particular, we show that we can learn the parity function using single-bit supervision (a traditionally hard task for deep networks) and learn how to play9\u21e59Sudoku solely from examples. We also solve a \u201cvisual Sudoku\u201d problem that maps images of Sudoku puzzles to their associated logical solutions by combining our MAXSAT solver with a traditional convolutional architecture. Our approach thus shows promise in integrating logical structures within deep learning."}, "NeuralAutomata": {"Invariants for neural automata": "Computational modeling of neurodynamical systems often deploys neural networks and symbolic dynamics. One particular way for combining these approaches within a framework called vector symbolic architectures leads to neural automata. Speci\ufb01cally, neural automata result from the assignment of symbols and symbol strings to numbers, known as Go \u00a8del encoding. Under this assignment, symbolic computation becomes represented by trajectories of state vectors in a real phase space, that allows for statistical correlation analyses with real-world measurements and experimental data. However, these assignments are usually completely arbitrary. Hence, it makes sense to address the problem which aspects of the dynamicsobserved under a Go \u00a8del representation is intrinsic to the dynamics and which are not. In this study, we develop a formally rigorous mathematical framework for the investigation of symmetries and invariants of neural automata under different encodings. As a central concept we de\ufb01ne patterns of equality for such systems. We consider different macroscopic observables, such as the mean activation level of the neural network, and ask for their invariance properties. Our main result shows that only step functions that are de\ufb01ned over those patterns of equality are invariant under symbolic recodings, while the mean activation, e.g., is not. Our work could be of substantial importance for related regression studies of real-world measurements with neurosymbolic processors for avoiding confounding results that are dependant on a particular encoding and not intrinsic to the dynamics."}, "ProbabilisticReasoning": {"A Probabilistic Approximate Logic for Neuro-Symbolic Learning and Reasoning": "As witnessed by recent advances in deep learning technologies, neural network models of very high complexity have been successfully applied in many data-rich domains. Challenges remain, however, if the amount of training data is severely limited, which is often the case due to the cost of acquiring such data or due to interest in systems that are constantly evolving thereby imposing natural limits on how much data can be collected. The core hypothesis explored in this paper is that data (to some degree) can be substituted by domain knowledge, not only addressing the limited data problem but also offering potential improvements in data-rich settings. For the representation of suitable domain theories, we propose Probabilistic Approximate Logic (PALO) to deal with the natural uncertainty associated with such representations and also to serve as a foundation for a new class of neuro-symbolic architectures, in which both neural and symbolic computations can be peacefully and synergistically integrated. Utilizing TensorFlow and Maude as neural and symbolic frameworks, respectively, we discuss our prototypical implementation of PALO in what we call the Logical Imagination Engine (LIME). By means of a small toy example, we convey a glimpse of its capabilities, but we also briefly discuss some real-world applications and how it may serve as a prototypical framework to explore a broader range of neuro-symbolic strategies in the future.", "Neural-Symbolic Probabilistic Argumentation Machines": "Neural-symbolic systems combine the strengths of neural networks and symbolic formalisms. In this paper, we introduce a neural-symbolic system which combines restricted Boltzmann machines and probabilistic semi-abstract argumentation. We propose to train networks on argument labellings explaining the data, so that any sampled data outcome is associated with an argument labelling. Argument labellings are integrated as constraints within restricted Boltzmann machines, so that the neural networks are used to learn probabilistic dependencies amongst argument labels. Given a dataset and an argumentation graph as prior knowledge, for every example/case K in the dataset, we use a so - called K - maxconsistent labelling of the graph, and an explanation of case K refers to a K - maxconsistent labelling of the given argumentation graph. The abilities of the proposed system to predict correct labellings were evaluated and compared with standard machine learning techniques. Experiments revealed that such argumentation Boltzmann machines can outperform other classification models, especially in noisy settings.", "BAYESIAN CONVOLUTIONAL NEURAL NETWORKS WITH BERNOULLI APPROXIMATE VARIATIONAL INFERENCE": "Convolutional neural networks (CNNs) work well on large datasets. But labelled data is hard to collect, and in some applications larger amounts of data are not available. The problem then is how to use CNNs with small data \u2013 as CNNs over\ufb01t quickly. We present an ef\ufb01cient Bayesian CNN, offering better robustness to over - \ufb01tting on small data than traditional approaches. This is by placing a probability distribution over the CNN\u2019s kernels. We approximate our model\u2019s intractable posterior with Bernoulli variational distributions, requiring no additional model parameters. On the theoretical side, we cast dropout network training as approximate inference in Bayesian neural networks. This allows us to implement our model using existing tools in deep learning with no increase in time complexity, while highlighting a negative result in the \ufb01eld. We show a considerable improvement in classi\ufb01cation accuracy compared to standard techniques and improve on published state - of - the - art results for CIFAR - 10.", "bears MAKE NEURO -SYMBOLIC MODELS AWARE OF THEIR REASONING SHORTCUTS": "Neuro-Symbolic (NeSy) predictors that conform to symbolic knowledge \u2013 encoding, e.g., safety constraints \u2013 can be affected by Reasoning Shortcuts (RSs): They learn concepts consistent with the symbolic knowledge by exploiting unintended semantics. RSs compromise reliability and generalization and, as we show in this paper, they are linked to NeSy models being overconfident about the predicted concepts. Unfortunately, the only trustworthy mitigation strategy requires collecting costly dense supervision over the concepts. Rather than attempting to avoid RSs altogether, we propose to ensure NeSy models are aware of the semantic ambiguity of the concepts they learn , thus enabling their users to identify and distrust low-quality concepts. Starting from three simple desiderata, we derive bears (BE Aware of Reasoning Shortcuts), an ensembling technique that calibrates the model\u2019s concept-level confidence without compromising prediction accuracy, thus encouraging NeSy architectures to be uncertain about concepts affected by RSs. We show empirically that bears improves RS-awareness of several state-of-the-art NeSy models, and also facilitates acquiring informative dense annotations for mitigation purposes.", "Robust Neuro-Symbolic Goal and Plan Recognition": "Goal Recognition is the task of discerning the intended goal agent aims to achieve given a sequence of observations, whereas Plan Recognition consists of identifying the plan to achieve such intended goal. Regardless of the underlying techniques, most recognition approaches are directly affected by the quality of the available observations. In this paper, we develop neuro-symbolic recognition approaches that can combine learning and planning techniques, compensating for noise and missing observations using prior data. We evaluate our approaches in standard human-designed planning domains as well as domain models automatically learned from real-world data. Empirical experimentation shows that our approaches reliably infer goals and compute correct plans in the experimental datasets. An ablation study shows that we outperform existing approaches that rely exclusively on the domain model, or exclusively on machine learning, in problems with both noisy observations and low observability.", "Semantic Strengthening of Neuro-Symbolic Learning": "Numerous neuro-symbolic approaches have re- cently been proposed typically with the goal of adding symbolic knowledge to the output layer of a neural network. Ideally, such losses maximize the probability that the neural network\u2019s predic- tions satisfy the underlying domain. Unfortu- nately, this type of probabilistic inference is often computationally infeasible. Neuro-symbolic ap- proaches therefore commonly resort to fuzzy ap- proximations of this probabilistic objective, sac- rificing sound probabilistic semantics, or to sam- pling which is very seldom feasible. We ap- proach the problem by first assuming the con- straint decomposes conditioned on the features learned by the network. We iteratively strengthen our approximation, restoring the dependence be- tween the constraints most responsible for de- grading the quality of the approximation. This corresponds to computing the mutual informa- tion between pairs of constraints conditioned on the network\u2019s learned features, and may be con- strued as a measure of how well aligned the gra- dients of two distributions are. We show how to compute this efficiently for tractable circuits. We test our approach on three tasks: predicting a minimum-cost path in Warcraft, predicting a minimum-cost perfect matching, and solving Su- doku puzzles, observing that it improves upon the baselines while sidestepping intractability.", "Neural Markov Logic Networks": "We introduce neural Markov logic networks (NMLNs), a statistical relational learning system that borrows ideas from Markov logic. Like Markov logic networks (MLNs), NMLNs are an exponential-family model for modelling distributions over possible worlds, but unlike MLNs, they do not rely on explicitly speci\ufb01ed \ufb01rst-order logic rules. Instead, NMLNs learn an implicit representation of such rules as a neural network that acts as a potential function on fragments of the relational structure. Similarly to many neural symbolic methods, NMLNs can exploit embeddings of constants but, unlike them, NMLNs work well also in their absence. This is extremely important for predicting in settings other than the transductive one. We showcase the potential of NMLNs on knowledge-base completion, triple classi\ufb01cation and on generation of molecular (graph) data.", "Neural Variational Inference and Learning in Belief Networks": "Highly expressive directed latent variable mod- els, such as sigmoid belief networks, are dif\ufb01- cult to train on large datasets because exact in- ference in them is intractable and none of the approximate inference methods that have been applied to them scale well. We propose a fast non-iterative approximate inference method that uses a feedforward network to implement ef\ufb01- cient exact sampling from the variational poste- rior. The model and this inference network are trained jointly by maximizing a variational lower bound on the log-likelihood. Although the naive estimator of the inference network gradient is too high-variance to be useful, we make it practi- cal by applying several straightforward model- independent variance reduction techniques. Ap- plying our approach to training sigmoid belief networks and deep autoregressive networks, we show that it outperforms the wake-sleep algo- rithm on MNIST and achieves state-of-the-art re- sults on the Reuters RCV1 document dataset.", "A-N ESI: A Scalable Approximate Method for Probabilistic Neurosymbolic Inference": "We study the problem of combining neural networks with symbolic reasoning. Recently introduced frameworks for Probabilistic Neurosymbolic Learning (PNL), such as DeepProbLog, perform exponential-time exact inference, limiting the scalability of PNL solutions. We introduce Approximate Neurosymbolic Inference (A-N ESI): a new framework for PNL that uses neural networks for scalable approximate inference. A-N ESI1) performs approximate inference in polynomial time without changing the semantics of probabilistic logics; 2) is trained using data generated by the background knowledge; 3) can generate symbolic explanations of predictions; and 4) can guarantee the satisfaction of logical constraints at test time, which is vital in safety-critical applications. Our experiments show that A-N ESIis the \ufb01rst end-to-end method to solve three neurosymbolic tasks with exponential combinatorial scaling. Finally, our experiments show that A-N ESI achieves explainability and safety without a penalty in performance.", "Modelling neural probabilistic computation using vector symbolic architectures": "Distributed vector representations are a key bridging point between connectionist and symbolic representations in cog-nition. It is unclear how uncertainty should be modelled in systems using such representations. In this paper we discuss how bundles of symbols in certain Vector Symbolic Architectures (VSAs) can be understood as de\ufb01ning an object that has a relationship to a probability distribution, and how statements in VSAs can be understood as being analogous to proba-bilistic statements. The aim of this paper is to show how (spiking) neural implementations of VSAs can be used to implement probabilistic operations that are useful in building cognitive models. We show how similarity operators between continuous values represented as Spatial Semantic Pointers (SSPs), an example of a technique known as fractional binding,induces a quasi-kernel function that can be used in density estimation. Further, we sketch novel designs for networks that compute entropy and mutual information of VSA-represented distributions and demonstrate their performance when implemented as networks of spiking neurons. We also discuss the relationship between our technique and quantumprobability, another technique proposed for modelling uncertainty in cognition. While we restrict ourselves to operators proposed for Holographic Reduced Representations, and for representing real-valued data. We suggest that the methods presented in this paper should translate to any VSA where the dot product between fractionally bound symbols induces avalid kernel."}}