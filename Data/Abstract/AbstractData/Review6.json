{
    "Explainability": {
        "Full length article": "Keywords:   \nExplainable artificial intelligence   \nDeep learning   \nNeural-symbolic learning   \nExpert knowledge graphs   \nCompositionality   \nPart-based object detection and classification  \n\nThe latest Deep Learning (DL) models for detection and classification have achieved an unprecedented performance over classical machine learning algorithms. However, DL models are black-box methods hard to. debug, interpret, and certify. DL alone cannot provide explanations that can be validated by a non technical audience such as end-users or domain experts. In contrast, symbolic AI systems that convert concepts into rules or symbols - such as knowledge graphs - are easier to explain. However, they present lower generalization and scaling capabilities. A very important challenge is to fuse DL representations with expert knowledge. One way to address this challenge, as well as the performance-explainability trade-off is by leveraging the best of both streams without obviating domain expert knowledge. In this paper, we tackle such problem by considering the symbolic knowledge is expressed in form of a domain expert knowledge graph. We present. the eXplainable Neural-symbolic learning (X-NeSyL) methodology, designed to learn both symbolic and deep. representations, together with an explainability metric to assess the level of alignment of machine and human expert explanations. The ultimate objective is to fuse DL representations with expert domain knowledge during the learning process so it serves as a sound basis for explainability. In particular, X-NeSyL methodology involves the concrete use of two notions of explanation, both at inference and training time respectively: (1) ExPLANet:. Expert-aligned eXplainable Part-based cLAssifier NETwork Architecture, a compositional convolutional neural network that makes use of symbolic representations, and (2) SHAP-Backprop, an explainable AI-informed. training procedure that corrects and guides the DL process to align with such symbolic representations in form of knowledge graphs. We showcase X-NeSyL methodology using MonuMAI dataset for monument facade image classification, and demonstrate that with our approach, it is possible to improve explainability at the same time as performance."
    },
    "KnowledgeProcessing": {
        "SCALABLE NEURAL METHODS FOR REASONING WITH A SYMBOLIC KNOWLEDGE BASE": "We describe a novel way of representing a symbolic knowledge base (KB) called a sparse-matrix reified KB. This representation enables neural KB inference modules that are fully differentiable, faithful to the original semantics of the KB, expressive. enough to model multi-hop inferences, and scalable enough to use with realistically large KBs. The sparse-matrix reified KB can be distributed across multiple GPUs, can scale to tens of millions of entities and facts, and is orders of magnitude faster than naive sparse-matrix implementations. The reified KB enables very simple end-to-end architectures to obtain competitive performance on several benchmarks representing two families of tasks: KB completion, and learning semantic parsers from denotations.",
        "Neuro-Symbolic Continual Learning: Knowledge, Reasoning Shortcuts and Concept Rehearsal": "We introduce Neuro-Symbolic Continual Learning, where a model has to solve a sequence of neuro-symbolic tasks, that is, it has to map sub-symbolic inputs to high-level concepts and compute predictions by reasoning consistently with prior knowledge. Our key observation is that neuro-symbolic tasks, although different, often share concepts whose semantics remains stable over time. Traditional approaches fall short: existing continual strategies ignore knowledge altogether, while stock neuro-symbolic architectures suffer from catastrophic forgetting. We show that leveraging prior knowledge by combining neuro-symbolic architectures with continual strategies does help avoid catastrophic forgetting, but also that doing so can yield models affected by reasoning shortcuts. These undermine the semantics of the acquired concepts, even when detailed prior knowledge is provided upfront and inference is exact, and in turn continual performance. To overcome these issues, we introduce COOL, a COncept-level cOntinual Learning strategy tailored for neuro-symbolic continual problems that acquires high-quality concepts and remembers them over time. Our experiments on three novel benchmarks highlights how COOL attains sustained high performance on neuro-symbolic continual learning tasks in which other strategies fail.",
        "Neural-Symbolic Relational Reasoning on Graph Models: Effective Link Inference and Computation from Knowledge Bases": "Neural-Symbolic Relational Reasoning on Graph Models: Effective Link Inference and Computation from Knowledge Bases  \n\nHenrique Lemos $1(\\boxtimes)_{\\oplus}$ , Pedro Avelar $^1\\oplus$ , Marcelo Prates $^1\\oplus$ , Artur Garcez $^{2}\\mathbb{O}$ and Luis Lamb $\\mathbf{\\Pi}^{1}\\oplus$  \n\n1 Institute of Informatics, UFRGS, Porto Alegre, Brazil {hlsantos,morprates,phcavelar,lamb}@inf.ufrgs.br 2 Department of Computer Science, City, University of London, London, UK a.garcez@city.ac.uk  \n\nAbstract. The recent developments and growing interest in neuralsymbolic models has shown that hybrid approaches can offer richer models for Artificial Intelligence. The integration of effective relational learn-. ing and reasoning methods is one of the key challenges in this direction, as neural learning and symbolic reasoning offer complementary characteristics that can benefit the development of AI systems. Relational labelling or link prediction on knowledge graphs has become one of the main problems in deep learning-based natural language processing research. Moreover, other fields which make use of neural-symbolic techniques may also benefit from such research endeavours. There have been several efforts. towards the identification of missing facts from existing ones in knowl-. edge graphs. Two lines of research try and predict knowledge relations between two entities by considering all known facts connecting them or. several paths of facts connecting them. We propose a neural-symbolic graph neural network which applies learning over all the paths by feeding the model with the embedding of the minimal subset of the knowledge graph containing such paths. By learning to produce representations. for entities and facts corresponding to word embeddings, we show how the model can be trained end-to-end to decode these representations and infer relations between entities in a multitask approach. Our contribution is two-fold: a neural-symbolic methodology leverages the resolution of relational inference in large graphs, and we also demonstrate that such neural-symbolic model is shown more effective than path-based approaches.  \n\nKeywords: Neural-symbolic computing : Graph neural networks : Relational learning"
    },
    "LogicalReasoning": {
        "Unsupervised Neural-Symbolic Integration": "Symbolic has been long considered as a language of human intelligence while neural networks have advantages of robust computation and dealing with noisy data. The integration of neural-symbolic can. offer better learning and reasoning while providing a means for interpretability through the representation of symbolic knowledge. Although previous works focus intensively on supervised feedforward neural networks, little has been done for the unsupervised counterparts. In this paper we show how. to integrate symbolic knowledge into unsupervised neural networks. We exemplify our approach with knowledge in different forms, including propositional logic for DNA promoter prediction and firstorder logic for understanding family relationship.",
        "NEURAL LOGIC MACHINES": "We propose the Neural Logic Machine (NLM), a neural-symbolic architecture for. both inductive learning and logic reasoning. NLMs exploit the power of both neural. networks-as function approximators, and logic programming-as a symbolic processor for objects with properties, relations, logic connectives, and quantifiers. After being trained on small-scale tasks (such as sorting short arrays), NLMs can recover lifted rules, and generalize to large-scale tasks (such as sorting longer arrays). In our experiments, NLMs achieve perfect generalization in a number of. tasks, from relational reasoning tasks on the family tree and general graphs, to decision making tasks including sorting arrays, finding shortest paths, and playing the blocks world. Most of these tasks are hard to accomplish for neural networks. or inductive logic programming alone. 1.",
        "pix2rule: End-to-end Neuro-symbolic Rule Learning": "Humans have the ability to seamlessly combine low-level visual input with high-level symbolic reasoning often in the form of recognising objects, learning relations between them and applying rules. Neurosymbolic systems aim to bring a unifying approach to connectionist and logic-based principles for visual processing and abstract reasoning respectively. This paper presents a complete neuro-symbolic method for processing images into objects, learning relations and logical rules in an end-to-end fashion. The main contribution is a differentiable layer in a deep learning architecture from which symbolic relations and rules can be extracted by pruning and thresholding. We evaluate our model using two datasets: subgraph isomorphism task for symbolic rule learning and an image classification domain with compound relations for learning objects, relations and rules. We demonstrate that our model scales beyond state-of-the-art symbolic learners and outperforms deep relational neural network architectures.",
        "A Semantic Framework for Neuro-symbolic Computation": "The field of neuro-symbolic AI aims to benefit from the combination of neural networks and symbolic systems. A cornerstone of the field is the translation or encoding of symbolic knowledge into neural networks. Although many. neuro-symbolic methods and approaches have been proposed, and with a large increase in recent years, no common definition of encoding exists that can enable a precise, theoretical comparison of neuro-symbolic methods. This paper addresses this problem by introducing a semantic framework for neurosymbolic AI. We start by providing a formal definition of semantic encoding,. specifying the components and conditions under which a knowledge-base can be encoded correctly by a neural network. We then show that many neurosymbolic approaches are accounted for by this definition. We provide a number of examples and correspondence proofs applying the proposed framework. to the neural encoding of various forms of knowledge representation. Many,. at first sight disparate, neuro-symbolic methods, are shown to fall within the proposed formalization. This is expected to provide guidance to future. neuro-symbolic encodings by placing them in the broader context of semantic encodings of entire families of existing neuro-symbolic systems. The paper hopes to help initiate a discussion around the provision of a theory for neurosymbolic AI and a semantics for deep learning. Keywords: Neuro-symbolic Integration, Reasoning, Neural Encoding, Neural Networks, Symbolic Logic.",
        "The Neuro-Symbolic Inverse Planning Engine (NIPE): Modeling Probabilistic Social Inferences from Linguistic Inputs": "Human beings are social creatures. We routinely reason about other agents, and a crucial component of this social reasoning is inferring people's goals as we learn about their actions. In many settings, we can perform intuitive but reliable goal. inference from language descriptions of agents, actions, and the background environments. In this paper, we study this process of language driving and influencing social reasoning in a probabilis-. tic goal inference domain. We propose a neurosymbolic model that carries out goal inference. from linguistic inputs of agent scenarios. The. \"neuro\" part is a large language model (LLM) that translates language descriptions to code representations, and the \"symbolic\" part is a Bayesian inverse planning engine. To test our model, we design and run a human experiment on a linguistic goal inference task. Our model closely matches human response patterns and better predicts human judgements than using an LLM alone.  \n\nbroadly, is abstract (we can observe someone's actions in the world, but cannot directly see what they think or want) and relies on a fine grained knowledge of distinct but highly interrelated mental states within others (we know that someone's beliefs, desires, and goals relative to the world itself all collectively influence what they might choose to do.)  \n\nThis paper considers how language can inform social reasoning, with a particular focus on understanding language about people's actions, plans, and goals. Language is an especially powerful means of conveying the abstract, interrelated nature of concepts about agents in the world--we can talk about someone's actions (I saw Annie heading into the living room), directly convey their mental states (Annie desperately wants a toy in there), describe relevant but abstract aspects of the world in which they act (that cupboard Annie is trying to open is locked inside), or even pose the questions we want others to reason about (which toy do you think she wants the most?). Language about any one of these aspects informs how we might reason about someone else in holistic ways, changing our understanding and downstream predictions about what they might know, want, or do.",
        "BRIDGING LOGIC AND LEARNING: A NEURAL-SYMBOLICAPPROACH FOR ENHANCED REASONING IN NEURAL MODELS(ASPER)": "Neural-symbolic learning, an intersection of neural networks and symbolic reasoning, aims to blend neural networks' learning capabilities with symbolic AI's interpretability and reasoning. This paper introduces an approach designed to improve the performance of neural models in learning reasoning tasks. It achieves this by integrating Answer Set Programming (ASP) solvers and domain-specific expertise, which is an approach that diverges from traditional complex neural-symbolic models. In this paper, a shallow artificial neural network (ANN) is specifically trained to solve Sudoku puzzles with minimal training data. The model has a unique loss function that integrates losses calculated using the ASP solver outputs, effectively enhancing its training efficiency. Most notably, the model shows a significant improvement in solving Sudoku puzzles using only 12 puzzles for training and testing without hyperparameter tuning. This advancement indicates that the model's enhanced reasoning capabilities have practical applications, extending well beyond Sudoku puzzles to potentially include a variety of other domains. The code can be found on GitHub: https://github.com/Fadi2200/ASPEN.",
        "Sandra - A Neuro-Symbolic Reasoner Based On Descriptions And Situations": "This paper presents sandra, a neuro-symbolic reasoner combining vectorial representations with deductive reasoning. Sandra builds a vector space constrained by an ontology and performs reasoning over it. The geometric nature of the reasoner allows its combination with neural networks, bridging the gap with symbolic knowledge representations. Sandra is based on the Description and Situation (DnS) ontology design pattern, a formalization of frame semantics. Given a set of facts (a situation) it allows to infer all possible perspectives (descriptions) that can provide a plausible interpretation for it, even in presence of incomplete information. We prove that our method is correct with respect to the DnS model. We experiment with two different tasks and their standard benchmarks, demonstrating that, without increasing complexity, sandra (i) outperforms all the baselines (ii) provides interpretability in the classification process, and (ii) allows control over the vector space, which is designed a priori.",
        "SOFTENED SYMBOL GROUNDING FOR NEURO-SYMBOLIC SYSTEMS": "Neuro-symbolic learning generally consists of two separated worlds, i.e., neural network training and symbolic constraint solving, whose success hinges on symbol grounding, a fundamental problem in AI. This paper presents a novel, softened symbol grounding process, bridging the gap between the two worlds, and resulting in an effective and efficient neuro-symbolic learning framework. Technically, the framework features (1) modeling of symbol solution states as a Boltzmann distribution, which avoids expensive state searching and facilitates mutually beneficial interactions between network training and symbolic reasoning; (2) a new MCMC technique leveraging projection and SMT solvers, which efficiently samples from disconnected symbol solution spaces; (3) an annealing mechanism that can escape from sub-optimal symbol groundings. Experiments with three representative neuro-symbolic learning tasks demonstrate that, owining to its superior symbol grounding capability, our framework successfully solves problems well beyond the frontier of the existing proposals.",
        "Reasoning in Non-probabilistic Uncertainty: Logic Programming and Neural-Symbolic Computing as Examples": "Reasoning in Non-probabilistic Uncertainty: Logic Programming and Neural-Symbolic Computing as Examples  \n\nTarek R. Besold1 $\\bullet$ Artur d'Avila Garcez? . Keith Stenning3 $\\bullet$ Leendert van der Torre' . Michiel van Lambalgen  \n\nReceived: 15 August 2016/ Accepted: 28 February 2017   \n$\\copyright$ Springer Science+Business Media Dordrecht 2017  \n\nAbstract This article aims to achieve two goals: to show that probability is not the only way of dealing with uncertainty (and even more, that there are kinds of uncertainty which are for principled reasons not addressable with probabilistic means); and to provide evidence that logic-based methods can well support rea-. soning with uncertainty. For the latter claim, two paradigmatic examples are presented: logic programming with Kleene semantics for modelling reasoning from. information in a discourse, to an interpretation of the state of affairs of the intended model, and a neural-symbolic implementation of input/output logic for dealing with. uncertainty in dynamic normative contexts..  \n\nKeywords Uncertainty in reasoning $\\cdot$ Interpretation $\\cdot$ Logic programming $\\cdot$ Dynamic norms $\\cdot$ Neural-symbolic integration",
        "Article Approximate Reasoning for Large-Scale ABox in OwL DL Based on Neural-Symbolic Learning": "The ontology knowledge base (KB) can be divided into two parts: TBox and ABox, where the former models schema-level knowledge within the domain, and the latter is a set of statements of assertions or facts about instances. ABox reasoning is a process of discovering implicit knowledge in ABox based on the existing KB, which is of great value in KB applications. ABox reasoning is influenced by both the complexity of TBox and scale of ABox. The traditional logic-based ontology reasoning methods are usually designed to be provably sound and complete but suffer from long algorithm runtimes and do not scale well for ontology KB represented by OWL DL (Description Logic). In some application scenarios, the soundness and completeness of reasoning results are not the key constraints, and it is acceptable to sacrifice them in exchange for the improvement of reasoning efficiency to some extent. Based on this view, an approximate reasoning method for large-scale ABox in OWL DL KBs was proposed, which is named the ChunfyReasoner (CFR). The CFR introduces neural-symbolic learning into ABox reasoning and integrates the advantages of symbolic systems and neural networks (NNs). By training the NN model, the CFR approximately compiles the logic deduction process of ontology reasoning, which can greatly improve the reasoning speed while ensuring higher reasoning quality. In this paper, we state the basic idea, framework, and construction process of the CFR in detail, and we conduct experiments on two open-source ontologies built on OWL DL. The experimental results verify the effectiveness of our method and show that the CFR can support the applications of large-scale ABox reasoning of OWL DL KBs.",
        "Semantic Probabilistic Layers for Neuro-Symbolic Learning": "We design a predictive layer for structured-output prediction (SOP) that can be. plugged into any neural network guaranteeing its predictions are consistent with a set of predefined symbolic constraints. Our Semantic Probabilistic Layer (SPL) can model intricate correlations, and hard constraints, over a structured output space all while being amenable to end-to-end learning via maximum likelihood. SPLs combine exact probabilistic inference with logical reasoning in a clean. and modular way, learning complex distributions and restricting their support to. solutions of the constraint. As such, they can faithfully, and efficiently, model complex SOP tasks beyond the reach of alternative neuro-symbolic approaches.. We empirically demonstrate that SPLs outperform these competitors in terms of accuracy on challenging SOP tasks including hierarchical multi-label classification, pathfinding and preference learning, while retaining perfect constraint satisfaction. Our code is made publicly available on Github at github.com/KareemYousrii/SPL.",
        "TGR: Neural-symbolic ontological reasoner for domain-specific knowledge graphs": "Ontological reasoning has great prospects in applications based on domain-specific knowledge graphs (KG). However, it is difficult for existing logic reasoners to quickly perform inference over large-scale assertional boxes (ABoxes) in domainspecific KGs with complex ontologies. To address this challenge, a novel method named the \"neural-symbolic ontological. reasoner' is proposed. By incorporating neural-symbolic learning into ABox reasoning, a reasoner named the TimGangRea-. soner (TGR) is built. The TGR synthesizes graph data using an ontology, trains an ABox reasoning network (ABRN) model, and then approximately compiles the logic reasoning process of the ontology (represented by. $\\mathrm{OWL+SWRL}$ ) into neural networks (NNs). The ABRN model encodes instances into vectors and then executes parallel vector computations to accel-. erate ABox reasoning. Experiments conducted on three open-source complex ontologies show that the TGR can achieve high-quality approximate deductive reasoning on ABoxes. The reasoning time consumption of the TGR increases linearly with the increase in the number of assertions, providing better scalability for large-scale ABoxes. Therefore, the TGR is able to reason quickly and accurately on domain-specific KGs that have complex underlying ontologies and contain large-scale ABoxes.  \n\nKeywords Domain-specific knowledge graph $\\cdot$ Ontology $\\cdot$ Deep learning $\\cdot$ Neural-symbolic $\\cdot$ Parallel reasoning $\\cdot$ Assertional box",
        "SATNet: Bridging deep learning and logical reasoning using a differentiable satisfiability solver": "Integrating logical reasoning within deep learning architectures has been a major goal of modern AI systems. In this paper, we propose a new direction toward this goal by introducing a differentiable (smoothed) maximum satisfiability (MAXSAT) solver that can be integrated into the loop of larger deep learning systems. Our (approximate) solver is based upon a fast coordinate descent approach to solving the semidefinite program (SDP) associated with the MAXSAT problem. We show how to analytically differentiate through the solution to this SDP and efficiently solve the associated backward pass. We demonstrate that by integrating this solver into end-to-end learning systems, we can learn the logical structure of challenging problems in a minimally supervised fashion. In particular, we show that we can learn the parity function using single-bit supervision (a traditionally hard task for deep networks) and learn how to play 9x9 Sudoku solely from examples. We also solve a visual Sudok problem that maps images of Sudoku puzzles to their associated logical solutions by combining our MAXSAT solver with a traditional convolutional architecture. Our approach thus shows promise in integrating logical structures within deep learning."
    },
    "NeuralAutomata": {
        "Invariants for neural automata": "Computational modeling of neurodynamical systems often deploys neural networks and symbolic dynamics. One particular way for combining these approaches within a framework called vector symbolic architectures leads to neural automata. Specifically, neural automata result from the assignment of symbols and symbol strings to numbers, known as Godel. encoding. Under this assignment, symbolic computation becomes represented by trajectories of state vectors in a real phase space, that allows for statistical correlation analyses with real-world measurements and experimental data. However, these assignments are usually completely arbitrary. Hence, it makes sense to address the problem which aspects of the dynamics observed under a Godel representation is intrinsic to the dynamics and which are not. In this study, we develop a formally rigorous mathematical framework for the investigation of symmetries and invariants of neural automata under different encodings. As a central concept we define patterns of equality for such systems. We consider different macroscopic. observables, such as the mean activation level of the neural network, and ask for their invariance properties. Our main. result shows that only step functions that are defined over those patterns of equality are invariant under symbolic recodings, while the mean activation, e.g., is not. Our work could be of substantial importance for related regression studies of realworld measurements with neurosymbolic processors for avoiding confounding results that are dependant on a particular encoding and not intrinsic to the dynamics.  \n\nKeywords Computational cognitive neurodynamics $\\cdot$ Symbolic dynamics $\\cdot$ Neural automata $\\cdot$ Observables : Invariants $\\cdot$ Language processing"
    },
    "ProbabilisticReasoning": {
        "A Probabilistic Approximate Logic for Neuro-Symbolic Learning and Reasoning": "As witnessed by recent advances in deep learning technologies, neural network models of very high complexity have been successfully applied in many data-rich domains. Challenges remain, however, if the amount of training data is severely limited, which is often the case due to the cost of acquiring such data or due to interest in systems that are constantly evolving thereby imposing natural limits on how much data can be collected. The core hypothesis explored in this paper is that data (to some degree) can be substituted by domain knowledge, not only addressing the limited data problem but also offering potential improvements in data-rich settings. For the representation of suitable domain theories, we propose Probabilistic Approximate Logic (PALO) to deal with the natural uncertainty associated with such representations and also to serve as a foundation for a new class of neuro-symbolic architectures, in which both neural and symbolic computations can be peacefully and synergistically integrated. Utilizing TensorFlow and Maude as neural and symbolic frameworks, respectively, we discuss our prototypical implementation of PALO in what we call the Logical Imagination Engine (LIME). By means of a small toy example, we convey a glimpse of its capabilities, but we also briefly discuss some real-world applications and how it may serve as a prototypical framework to explore a broader range of neuro-symbolic strategies in the future.  \n\nKeywords:  Neuro-Symbolic Architecture, First-Order Logic, Probabilistic Logic, Machine Learning. Neural Networks.",
        "Neural-Symbolic Probabilistic Argumentation Machines\\*": "Neural-symbolic systems combine the strengths of neural networks and symbolic formalisms. In this paper, we in-. troduce a neural-symbolic system which combines restricted Boltzmann machines and probabilistic semi-abstract argu-. mentation. We propose to train networks on argument labellings explaining the data, so that any sampled data outcome is associated with an argument labelling. Argument labellings are integrated as constraints within restricted Boltzmann machines, so that the neural networks are used to learn probabilistic dependencies amongst argument labels. Given a dataset and an argumentation graph as prior knowledge, for every example/case $K$ in the dataset, we use a so-called. $K$ maxconsistent labelling of the graph, and an explanation of case $K$ refers to a $K$ -maxconsistent labelling of the given argumentation graph. The abilities of the proposed system to. predict correct labellings were evaluated and compared with standard machine learning techniques. Experiments revealed that such argumentation Boltzmann machines can outperform. other classification models, especially in noisy settings.",
        "BAYESIAN CONVOLUTIONAL NEURAL NETWORKSWITH BERNOULLI APPROXIMATE VARIATIONALINFERENCE": "Convolutional neural networks (CNNs) work well on large datasets. But labelled. data is hard to collect, and in some applications larger amounts of data are not. available. The problem then is how to use CNNs with small data - as CNNs overfit quickly. We present an efficient Bayesian CNN, offering better robustness to over-fitting on small data than traditional approaches. This is by placing a probability distribution over the CNN's kernels. We approximate our model's in-. tractable posterior with Bernoulli variational distributions, requiring no additional. model parameters.  \n\nOn the theoretical side, we cast dropout network training as approximate inference. in Bayesian neural networks. This allows us to implement our model using existing tools in deep learning with no increase in time complexity, while highlighting a negative result in the field. We show a considerable improvement in classification. accuracy compared to standard techniques and improve on published state-of-the-. art results for CIFAR-10.",
        "Robust Neuro-Symbolic Goal and Plan Recognition": "Goal Recognition is the task of discerning the intended goal agent aims to achieve given a sequence of observations, whereas Plan Recognition consists of identifying the plan to achieve such intended goal. Regardless of the underlying techniques, most recognition approaches are directly affected by the quality of the available observations. In this paper, we develop neuro-symbolic recognition approaches that can combine learning and planning techniques, compensating for noise and missing observations using prior data. We evaluate our approaches in standard human-designed planning domains as well as domain models automatically learned from real-world data. Empirical experimentation shows that our approaches reliably infer goals and compute correct plans in the experimental datasets. An ablation study shows that we outperform existing approaches that rely exclusively on the domain model, or exclusively on machine learning, in problems with both noisy observations and low observability.",
        "Semantic Strengthening of Neuro-Symbolic Learning": "Numerous neuro-symbolic approaches have recently been proposed typically with the goal of adding symbolic knowledge to the output layer of a neural network. Ideally, such losses maximize the probability that the neural network's predictions satisfy the underlying domain. Unfortunately, this type of probabilistic inference is often computationally infeasible. Neuro-symbolic approaches therefore commonly resort to fuzzy approximations of this probabilistic objective, sacrificing sound probabilistic semantics, or to sampling which is very seldom feasible.We approach the problem by first assuming the constraint decomposes conditioned on the features learned by the network. We iteratively strengthen our approximation, restoring the dependence between the constraints most responsible for degrading the quality of the approximation. This corresponds to computing the mutual information between pairs of constraints conditioned on the network's learned features, and may be construed as a measure of how well aligned the gradients of two distributions are. We show how to compute this efficiently for tractable circuits. We test our approach on three tasks: predicting a minimum-cost path in Warcraft, predicting a minimum-cost perfect matching, and solving Sudoku puzzles, observing that it improves upon the baselines while sidestepping intractability.  \n\nfrom large datasets. However, without a notion of the sym-.   \nbolic rules underlying any given problem domain, neural.   \nnetworks are often only able to achieve decent label-level accuracy, with a complete disregard to the structure jointly.   \nencoded by the individual labels. These structures may en-.   \ncode, for example, a path in a graph, a matching of users to.   \ntheir preferences, or even the solution to a Sudoku puzzle.  \n\nNeuro-symbolic approaches (De Raedt et al., 2020) hope to remedy the problem by injecting into the training process knowledge regarding the underlying problem domain, e.g. a Sudoku puzzle is characterized by the uniqueness of the elements of every row, column, and. $3\\times3$ square. This is achieved by maximizing the probability allocated by the neural network to outputs satisfying the rules of the. underlying domain. Computing this quantity is, in general, a #P-hard problem (Valiant, 1979), which while tractable for a range of practical problems (Xu et al., 2018; Ahmed. et al., 2022c), precludes many problems of interest.  \n\nA common approach is to side step the hardness of computing the probability exactly by replacing logical operators with their fuzzy t-norms, and logical implications with simple inequalities (Medina Grespan et al., 2021; van Krieken et al., 2020). This, however, does not preserve the sound. probabilistic semantics of the underlying logical statement: equivalent logic statements no longer correspond to the same set of satisfying assignments, to different probability distributions, and consequently, vastly different constraint probabilities. On the other hand, obtaining a Monte Carlo estimate of the probability (Ahmed et al., 2022a) is infeasible in exponentially-sized output spaces where the valid outputs represent only a sliver of the distribution's support.",
        "Neural Markov Logic Networks": "We introduce neural Markov logic networks (NMLNs), a statistical relational learning system that borrows ideas from Markov logic. Like Markov logic networks (MLNs), NMLNs are an exponential-family model for modelling distributions over possible worlds, but unlike MLNs, they do not rely on explicitly specified first-order logic rules. Instead, NMLNs learn an implicit representation of such rules as a neural network that acts as a potential function on fragments of the relational structure. Similarly to many neural symbolic methods, NMLNs can exploit embeddings of constants but, unlike them, NMLNs work well also in their absence. This is extremely important for predicting in settings other than the transductive one. We showcase the potential of NMLNs on knowledgebase completion, triple classification and on generation of molecular (graph) data.  \n\nDomingos, 2006]. In classical MLNs, however, either domain experts are required to design some useful statistics about the domain of interest by hand (i.e. logical rules) or they need to be learned by structure learning based on combinatorial search. Recently, many authors have tried to improve relational learning by integrating it with neural computation [Rocktaschel and Riedel, 2017, Kazemi and Poole, 2018, Sourek et al., 2018]. However, these hybrid approaches usually relax (or drop) the goal of modeling the joint probability distribution, preventing them from being applied to more complex learning and reasoning tasks.  \n\nIn this paper, we propose neural Markov logic networks (NMLN). Here, the statistics (or features), which are used to model the probability distribution, are not known in advance, but are modelled as neural networks trained together with the probability distribution model. NMLNs overcome several limitations of existing approaches. In particular, (i) they can be used as an out-of-the-box tool in heterogeneous domains; (ii) they allow expressing and learning joint probability distributions of complete relational structures."
    }
}